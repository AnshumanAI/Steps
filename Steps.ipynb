{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPPae+32RihjjufYAHdxu6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bc3dce6f1f641adb50100a64627fa7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_704f908649744e1c99bfd018b5dbfee3",
              "IPY_MODEL_f0e009f1360844d49719549f262b544a",
              "IPY_MODEL_65654d9397f8428faf3c2552b1107a66"
            ],
            "layout": "IPY_MODEL_1ce16d0bccad45599e4630f2ee1a0b42"
          }
        },
        "704f908649744e1c99bfd018b5dbfee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127f93d6dbc94ba799a6c812e83c61e4",
            "placeholder": "​",
            "style": "IPY_MODEL_73ee7cebde8347559a6320ea1dded9a5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f0e009f1360844d49719549f262b544a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee60e7cd4694c14a35c4dcf4c58a69a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ab069c69a2847c5aa1acf00b0a9cf44",
            "value": 28
          }
        },
        "65654d9397f8428faf3c2552b1107a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0a6baa8a824df49b1883d2b94cde5b",
            "placeholder": "​",
            "style": "IPY_MODEL_118eac7f5b964f6283d6ccb1f2aeb4b3",
            "value": " 28.0/28.0 [00:00&lt;00:00, 847B/s]"
          }
        },
        "1ce16d0bccad45599e4630f2ee1a0b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127f93d6dbc94ba799a6c812e83c61e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ee7cebde8347559a6320ea1dded9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee60e7cd4694c14a35c4dcf4c58a69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab069c69a2847c5aa1acf00b0a9cf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c0a6baa8a824df49b1883d2b94cde5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118eac7f5b964f6283d6ccb1f2aeb4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d631bb8052419382d261409fc1a34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_315a57c63d0e45d6af123e5450679a3a",
              "IPY_MODEL_56bc005594584888894b0dc85c1ad924",
              "IPY_MODEL_7d7477d01370427389672081ebe52a83"
            ],
            "layout": "IPY_MODEL_bc73ae852c8547c18a32428ec0899f99"
          }
        },
        "315a57c63d0e45d6af123e5450679a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8792dadd0ffe4da2a19feae310030d96",
            "placeholder": "​",
            "style": "IPY_MODEL_226ee214047e40d7a5fb917c44974893",
            "value": "vocab.txt: 100%"
          }
        },
        "56bc005594584888894b0dc85c1ad924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_640afff7b14f453f8887161a5537ab53",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61950895e4a94883823f9cbcc4256d8b",
            "value": 231508
          }
        },
        "7d7477d01370427389672081ebe52a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b60be01e66746ca9d7e0c18f643eac3",
            "placeholder": "​",
            "style": "IPY_MODEL_fe0e11d9a73f438189f48e662fddde5a",
            "value": " 232k/232k [00:00&lt;00:00, 2.44MB/s]"
          }
        },
        "bc73ae852c8547c18a32428ec0899f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8792dadd0ffe4da2a19feae310030d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226ee214047e40d7a5fb917c44974893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "640afff7b14f453f8887161a5537ab53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61950895e4a94883823f9cbcc4256d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b60be01e66746ca9d7e0c18f643eac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0e11d9a73f438189f48e662fddde5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ea92e692d0e47bd93003f7d73515272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f065a88fbeb84060a5671fe8e1045ac5",
              "IPY_MODEL_f3303c3890894c9086d301169fce13cb",
              "IPY_MODEL_10797d35675742538caa043735f2493f"
            ],
            "layout": "IPY_MODEL_1e7e94fb05844bbe886a2912f220f2dd"
          }
        },
        "f065a88fbeb84060a5671fe8e1045ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44418593de1640d6aecc3667e9d572ca",
            "placeholder": "​",
            "style": "IPY_MODEL_c6fbb5f49025401da1079772c0dd89d6",
            "value": "tokenizer.json: 100%"
          }
        },
        "f3303c3890894c9086d301169fce13cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22e54f9e12a4edba90a7a80b4883491",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_187d35b065c04737aa52533feb463e73",
            "value": 466062
          }
        },
        "10797d35675742538caa043735f2493f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df4ae7c5dd6419ca805bab53badc98a",
            "placeholder": "​",
            "style": "IPY_MODEL_de02d63dab7d477f8de36c13a8412928",
            "value": " 466k/466k [00:00&lt;00:00, 4.27MB/s]"
          }
        },
        "1e7e94fb05844bbe886a2912f220f2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44418593de1640d6aecc3667e9d572ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fbb5f49025401da1079772c0dd89d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f22e54f9e12a4edba90a7a80b4883491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187d35b065c04737aa52533feb463e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2df4ae7c5dd6419ca805bab53badc98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de02d63dab7d477f8de36c13a8412928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e20c5a39a4c14dd9b0837642cdcc1521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4555aded1dc1466f978a693d7bbaaa3a",
              "IPY_MODEL_213b4d07672346c0a51aafa8f3f41029",
              "IPY_MODEL_ec7232dbdb2d43c9af3d5ee766e68f3b"
            ],
            "layout": "IPY_MODEL_27aca1de3f5f441cba6d50aca0cf95ea"
          }
        },
        "4555aded1dc1466f978a693d7bbaaa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1111b5a342304154b0d761681e0eca62",
            "placeholder": "​",
            "style": "IPY_MODEL_c3cbcc42062b4fdd83d0997048b8f74f",
            "value": "config.json: 100%"
          }
        },
        "213b4d07672346c0a51aafa8f3f41029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f9fbd976fe7427c8d045541f5feb67e",
            "max": 493,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a76d22598bdf4aa597e885f538a02921",
            "value": 493
          }
        },
        "ec7232dbdb2d43c9af3d5ee766e68f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba29d816e5424a439e3f62b3fcd8e60b",
            "placeholder": "​",
            "style": "IPY_MODEL_2c71d02a9d8240c7bcdbd4c0e536b84a",
            "value": " 493/493 [00:00&lt;00:00, 4.49kB/s]"
          }
        },
        "27aca1de3f5f441cba6d50aca0cf95ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1111b5a342304154b0d761681e0eca62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cbcc42062b4fdd83d0997048b8f74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f9fbd976fe7427c8d045541f5feb67e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76d22598bdf4aa597e885f538a02921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba29d816e5424a439e3f62b3fcd8e60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c71d02a9d8240c7bcdbd4c0e536b84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e2b23d55be4449b20aa4a2ef2da39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5dbec0e2def4cf79849c8abbcca73ee",
              "IPY_MODEL_28d16cb7c4ea43f381b791d5760858c5",
              "IPY_MODEL_972638a76c824a15a3d355ec60048f36"
            ],
            "layout": "IPY_MODEL_d0affec5f6b44e6da5ea9b5bca7867ab"
          }
        },
        "c5dbec0e2def4cf79849c8abbcca73ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3985edecaa9849b8bf9e2944d8bac08a",
            "placeholder": "​",
            "style": "IPY_MODEL_c9c50320057c42b5a0b0162da2b04f58",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "28d16cb7c4ea43f381b791d5760858c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1dc70e7f5cc452da4b9d532763f747a",
            "max": 437986065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d37fa0e0be946ba8aca909537bb0a9c",
            "value": 437986065
          }
        },
        "972638a76c824a15a3d355ec60048f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba05bec7f8e4855832fbcc6ce1de6f4",
            "placeholder": "​",
            "style": "IPY_MODEL_82f52cfbd9094f13a0b6978bd2b2bacf",
            "value": " 438M/438M [00:02&lt;00:00, 199MB/s]"
          }
        },
        "d0affec5f6b44e6da5ea9b5bca7867ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3985edecaa9849b8bf9e2944d8bac08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c50320057c42b5a0b0162da2b04f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1dc70e7f5cc452da4b9d532763f747a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d37fa0e0be946ba8aca909537bb0a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ba05bec7f8e4855832fbcc6ce1de6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f52cfbd9094f13a0b6978bd2b2bacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshumanAI/Steps/blob/main/Steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation of packages"
      ],
      "metadata": {
        "id": "bv0PDLwrWyhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install frontend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RTpt1XVpZBl",
        "outputId": "5a8cb947-494a-4388-99f3-6bcb4964dc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.8-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.8 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.8-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.8 PyMuPDFb-1.24.8\n",
            "Collecting frontend\n",
            "  Downloading frontend-0.0.3-py3-none-any.whl (32 kB)\n",
            "Collecting starlette>=0.12.0 (from frontend)\n",
            "  Downloading starlette-0.38.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn>=0.7.1 (from frontend)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from frontend) (2.2.0)\n",
            "Collecting aiofiles (from frontend)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.12.0->frontend) (3.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.7.1->frontend) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.7.1->frontend)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.7.1->frontend) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.2.2)\n",
            "Installing collected packages: h11, aiofiles, uvicorn, starlette, frontend\n",
            "Successfully installed aiofiles-24.1.0 frontend-0.0.3 h11-0.14.0 starlette-0.38.1 uvicorn-0.30.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGvpNnlEsU6Q",
        "outputId": "c04895ea-dc49-4652-bb80-98e66fef1a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHg4KyabpEfD"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    pdf_document = fitz.open(file_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        page = pdf_document[page_num]\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "#Used the books I had, they might be pirated idk\n",
        "textbook_paths = [\n",
        "    \"/content/drive/MyDrive/Hands-On Machine Learning with Scikit-Lear - Aurelien Geron.pdf\",\n",
        "    \"/content/drive/MyDrive/DeepLearningBook.pdf\",\n",
        "    \"/content/drive/MyDrive/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf\"\n",
        "]\n",
        "\n",
        "# Extracting text from each textbook\n",
        "textbook_texts = [extract_text_from_pdf(path) for path in textbook_paths]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjHg4AnMupZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of Tree"
      ],
      "metadata": {
        "id": "zuS1YdtxY258"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "# Definition of the structure of a node\n",
        "class TreeNode:\n",
        "    def __init__(self, identifier, content=\"\"):\n",
        "        self.identifier = identifier\n",
        "        self.content = content\n",
        "        self.children = []\n",
        "\n",
        "#  Hierarchical tree-based index\n",
        "def create_tree_index(text, title_pattern, section_pattern, subsection_pattern):\n",
        "    root = TreeNode(\"Root\")\n",
        "    current_chapter = None\n",
        "    current_section = None\n",
        "    current_subsection = None\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if re.match(title_pattern, line):\n",
        "            current_chapter = TreeNode(line)\n",
        "            root.children.append(current_chapter)\n",
        "            current_section = None\n",
        "            current_subsection = None\n",
        "        elif re.match(section_pattern, line):\n",
        "            if current_chapter is not None:\n",
        "                current_section = TreeNode(line)\n",
        "                current_chapter.children.append(current_section)\n",
        "                current_subsection = None\n",
        "            else:\n",
        "                print(f\"Warning: Section '{line}' found before any chapter. Skipping.\")\n",
        "        elif re.match(subsection_pattern, line):\n",
        "            if current_section is not None:\n",
        "                current_subsection = TreeNode(line)\n",
        "                current_section.children.append(current_subsection)\n",
        "            else:\n",
        "                print(f\"Warning: Subsection '{line}' found before any section. Skipping.\")\n",
        "        else:\n",
        "            if current_subsection:\n",
        "                current_subsection.content += line + \" \"\n",
        "            elif current_section:\n",
        "                current_section.content += line + \" \"\n",
        "            elif current_chapter:\n",
        "                current_chapter.content += line + \" \"\n",
        "            else:\n",
        "                print(f\"Warning: Text found before any chapter, section, or subsection: '{line}'\")\n",
        "\n",
        "    return root\n",
        "\n",
        "# Patterns to match chapters, sections, and subsections\n",
        "title_pattern = r\"^Chapter \\d+: .*$\"\n",
        "section_pattern = r\"^\\d+\\.\\d+ .*$\"\n",
        "subsection_pattern = r\"^\\d+\\.\\d+\\.\\d+ .*$\"\n",
        "\n",
        "# Indexes for each textbook\n",
        "tree_indexes = [create_tree_index(text, title_pattern, section_pattern, subsection_pattern) for text in textbook_texts]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgH3xLo57oXx",
        "outputId": "913eb2d1-8633-4a76-e70b-7a1979d0be9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Warning: Text found before any chapter, section, or subsection: '[FL90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Fahlman and C. Lebiere. The cascade-correlation learning algorithm. In Technical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Report CMU-CS-90-100, Computer Sciences Department, Carnegie Mellon University,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FL95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Faloutsos and K.-I. Lin. FastMap: A fast algorithm for indexing, data-mining and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visualization of traditional and multimedia datasets. In Proc. 1995 ACM-SIGMOD Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Management of Data (SIGMOD’95), pp. 163–174, San Jose, CA, May 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Fle87]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Fletcher. Practical Methods of Optimization. John Wiley & Sons, 1987.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FMMT96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Fukuda, Y. Morimoto, S. Morishita, and T. Tokuyama. Data mining using two-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional optimized association rules: Scheme, algorithms, and visualization. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’96), pp. 13–23,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Montreal, Quebec, Canada, June 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FP05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Friedman and B. E. Popescu. Predictive learning via rule ensembles. In Technical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Report, Department of Statistics, Stanford University, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FPP07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Freedman, R. Pisani, and R. Purves. Statistics (4th ed.). W. W. Norton & Co., 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FPSS+96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy (eds.). Advances in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery and Data Mining. AAAI/MIT Press, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FP97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Fawcett and F. Provost. Adaptive fraud detection. Data Mining and Knowledge'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Discovery, 1:291–316, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FR02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Fraley and A. E. Raftery. Model-based clustering, discriminant analysis, and density'\n",
            "Warning: Text found before any chapter, section, or subsection: 'estimation. J. American Statistical Association, 97:611–631, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '645'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Fri77]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. H. Friedman. A recursive partitioning decision rule for nonparametric classiﬁers. IEEE'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Trans. Computer, 26:404–408, 1977.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Fri01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. H. Friedman. Greedy function approximation: A gradient boosting machine. Ann.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Statistics, 29:1189–1232, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Fri03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. Friedman. Pcluster: Probabilistic agglomerative clustering of gene expression proﬁles.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Technical Report 2003-80, Hebrew University, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FRM94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast subsequence matching in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series databases. In Proc. 1994 ACM-SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’94), pp. 419–429, Minneapolis, MN, May 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FS93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'U. Fayyad and P. Smyth. Image database exploration: Progress and challenges. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AAAI’93 Workshop Knowledge Discovery in Databases (KDD’93), pp. 14–27, Washington,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DC, July 1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FS97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'an application to boosting. J. Computer and System Sciences, 55:119–139, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FS06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Feldman and J. Sanger. The Text Mining Handbook: Advanced Approaches in Analyzing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Unstructured Data. Cambridge University Press, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FSGM+98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Fang, N. Shivakumar, H. Garcia-Molina, R. Motwani, and J. D. Ullman. Computing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg queries efﬁciently. In Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 299–310, New York, NY, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FW94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Furnkranz and G. Widmer. Incremental reduced error pruning. In Proc. 1994 Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Machine Learning (ICML’94), pp. 70–77, New Brunswick, NJ, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FWFY10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. C. M. Fung, K. Wang, A. W.-C. Fu, and P. S. Yu. Introduction to Privacy-Preserving'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Publishing: Concepts and Techniques. Chapman & Hall/CRC, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[FYM05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Fujimaki, T. Yairi, and K. Machida. An approach to spacecraft anomaly detec-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion problem using kernel feature space. In Proc. 2005 Int. Workshop Link Discovery'\n",
            "Warning: Text found before any chapter, section, or subsection: '(LinkKDD’05), pp. 401–410, Chicago, IL, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Gal93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. I. Gallant. Neural Network Learning and Expert Systems. Cambridge, MA: MIT Press,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Gat00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Gates. Business @ the Speed of Thought: Succeeding in the Digital Economy. Warner'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Books, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GCB+97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Gray, S. Chaudhuri, A. Bosworth, A. Layman, D. Reichart, M. Venkatrao, F. Pellow,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and H. Pirahesh. Data cube: A relational aggregation operator generalizing group-by,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cross-tab and sub-totals. Data Mining and Knowledge Discovery, 1:29–54, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GFKT01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. Getoor, N. Friedman, D. Koller, and B. Taskar. Learning probabilistic models of rela-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tional structure. In Proc. 2001 Int. Conf. Machine Learning (ICML’01), pp. 170–177,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Williamstown, MA, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GFS+01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Galhardas, D. Florescu, D. Shasha, E. Simon, and C.-A. Saita. Declarative data clean-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing: Language, model, and algorithms. In Proc. 2001 Int. Conf. Very Large Data Bases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(VLDB’01), pp. 371–380, Rome, Italy, Sept. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GG92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Gersho and R. M. Gray. Vector Quantization and Signal Compression. Kluwer'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Academic, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GG98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Gaede and O. G¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unther. Multidimensional access methods. ACM Computing Surveys,'\n",
            "Warning: Text found before any chapter, section, or subsection: '30:170–231, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '646'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GGR99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Ganti, J. E. Gehrke, and R. Ramakrishnan. CACTUS—clustering categorical data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'using summaries. In Proc. 1999 Int. Conf. Knowledge Discovery and Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’99), pp. 73–83, San Diego, CA, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GGRL99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Gehrke, V. Ganti, R. Ramakrishnan, and W.-Y. Loh. BOAT—optimistic decision'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tree construction. In Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’99), pp. 169–180, Philadelphia, PA, June 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GHL06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Gonzalez, J. Han, and X. Li. Flowcube: Constructuing RFID ﬂowcubes for multi-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional analysis of commodity ﬂows. In Proc. 2006 Int. Conf. Very Large Data Bases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(VLDB’06), pp. 834–845, Seoul, Korea, Sept. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GHLK06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Gonzalez, J. Han, X. Li, and D. Klabjan. Warehousing and analysis of massive RFID'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data sets. In Proc. 2006 Int. Conf. Data Engineering (ICDE’06), p. 83, Atlanta, GA, Apr.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GKK+01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. L. Grossman, C. Kamath, P. Kegelmeyer, V. Kumar, and R. R. Namburu. Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for Scientiﬁc and Engineering Applications. Kluwer Academic, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GKR98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Gibson, J. M. Kleinberg, and P. Raghavan. Clustering categorical data: An approach'\n",
            "Warning: Text found before any chapter, section, or subsection: 'based on dynamical systems. In Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 311–323, New York, NY, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GM99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Gupta and I. S. Mumick. Materialized Views: Techniques, Implementations, and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Applications. Cambridge, MA: MIT Press, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GMMO00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Guha, N. Mishra, R. Motwani, and L. O’Callaghan. Clustering data streams. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2000 Symp. Foundations of Computer Science (FOCS’00), pp. 359–366, Redondo Beach,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CA, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GMP+09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Ginsberg, M. H. Mohebbi, R. S. Patel, L. Brammer, M. S. Smolinski, and L. Brilliant.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Detecting inﬂuenza epidemics using search engine query data. Nature, 457:1012–1014,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Feb. 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GMUW08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Garcia-Molina, J. D. Ullman, and J. Widom. Database Systems: The Complete Book'\n",
            "Warning: Text found before any chapter, section, or subsection: '(2nd ed.). Prentice Hall, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GMV96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. Guyon, N. Matic, and V. Vapnik. Discoverying informative patterns and data cleaning.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy (eds.), Advances in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery and Data Mining, pp. 181–203. AAAI/MIT Press, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Gol89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Goldberg. Genetic Algorithms in Search, Optimization, and Machine Learning. Read-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing, MA: Addison-Wesley, 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GR04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. A. Grossman and O. Frieder. Information Retrieval: Algorithms and Heuristics. New'\n",
            "Warning: Text found before any chapter, section, or subsection: 'York: Springer, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GR07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. D. Grunwald and J. Rissanen. The Minimum Description Length Principle. Cambridge,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MA: MIT Press, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GRG98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Gehrke, R. Ramakrishnan, and V. Ganti. RainForest: A framework for fast decision tree'\n",
            "Warning: Text found before any chapter, section, or subsection: 'construction of large datasets. In Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 416–427, New York, NY, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GRS98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Guha, R. Rastogi, and K. Shim. CURE: An efﬁcient clustering algorithm for large'\n",
            "Warning: Text found before any chapter, section, or subsection: 'databases. In Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 73–84, Seattle, WA, June 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '647'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GRS99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Guha, R. Rastogi, and K. Shim. ROCK: A robust clustering algorithm for categorical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attributes. In Proc. 1999 Int. Conf. Data Engineering (ICDE’99), pp. 512–521, Sydney,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Australia, Mar. 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Gru69]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. E. Grubbs. Procedures for detecting outlying observations in samples. Technometrics,'\n",
            "Warning: Text found before any chapter, section, or subsection: '11:1–21, 1969.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Gup97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Gupta. Selection of views to materialize in a data warehouse. In Proc. 7th Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Database Theory (ICDT’97), pp. 98–112, Delphi, Greece, Jan. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Gut84]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Guttman. R-Tree: A dynamic index structure for spatial searching. In Proc. 1984'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’84), pp. 47–57, Boston, MA,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'June 1984.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GW07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. C. Gonzalez and R. E. Woods. Digital Image Processing (3rd ed.). Prentice Hall, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GZ03a]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Goethals and M. Zaki. An introduction to workshop frequent itemset mining imple-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mentations. In Proc. ICDM’03 Int. Workshop Frequent Itemset Mining Implementations'\n",
            "Warning: Text found before any chapter, section, or subsection: '(FIMI’03), pp. 1–13, Melbourne, FL, Nov. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[GZ03b]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Grahne and J. Zhu. Efﬁciently using preﬁx-trees in mining frequent itemsets. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. ICDM’03 Int. Workshop on Frequent Itemset Mining Implementations (FIMI’03),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Melbourne, FL, Nov. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HA04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. J. Hodge, and J. Austin. A survey of outlier detection methodologies. Artiﬁcial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence Review, 22:85–126, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HAC+99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. M. Hellerstein, R. Avnur, A. Chou, C. Hidber, C. Olston, V. Raman, T. Roth, and P. J.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Haas. Interactive data analysis: The control project. IEEE Computer, 32:51–59, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Ham94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Hamilton. Time Series Analysis. Princeton University Press, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Han98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han. Towards on-line analytical mining in large databases. SIGMOD Record,'\n",
            "Warning: Text found before any chapter, section, or subsection: '27:97–107, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Har68]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. E. Hart. The condensed nearest neighbor rule. IEEE Trans. Information Theory,'\n",
            "Warning: Text found before any chapter, section, or subsection: '14:515–516, 1968.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Har72]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Hartigan. Direct clustering of a data matrix. J. American Stat. Assoc., 67:123–129, 1972.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Har75]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. A. Hartigan. Clustering Algorithms. John Wiley & Sons, 1975.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hay99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. S. Haykin. Neural Networks: A Comprehensive Foundation. Prentice-Hall, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hay08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Haykin. Neural Networks and Learning Machines. Prentice-Hall, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HB87]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. J. Hanson and D. J. Burr. Minkowski-r back-propagation: Learning in connection-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ist models with non-euclidian error signals. In Neural Information Proc. Systems Conf.,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 348–357, Denver, CO, 1987.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HBV01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Halkidi, Y. Batistakis, and M. Vazirgiannis. On clustering validation techniques.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Intelligent Information Systems, 17:107–145, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HCC93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han, Y. Cai, and N. Cercone. Data-driven discovery of quantitative rules in relational'\n",
            "Warning: Text found before any chapter, section, or subsection: 'databases. IEEE Trans. Knowledge and Data Engineering, 5:29–40, 1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HCD94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. B. Holder, D. J. Cook, and S. Djoko. Substructure discovery in the subdue system. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. AAAI’94 Workshop on Knowledge Discovery in Databases (KDD’94), pp. 169–180,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Seattle, WA, July 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hec96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Heckerman.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian networks for knowledge discovery.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In U. M. Fayyad,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy (eds.), Advances in Knowledge'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Discovery and Data Mining, pp. 273–305. Cambridge, MA: MIT Press, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '648'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HF94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han and Y. Fu. Dynamic generation and reﬁnement of concept hierarchies for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge discovery in databases. In Proc. AAAI’94 Workshop Knowledge Discovery in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Databases (KDD’94), pp. 157–168, Seattle, WA, July 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HF95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han and Y. Fu. Discovery of multiple-level association rules from large databases. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95), pp. 420–431, Zurich, Switzerland,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Sept. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HF96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han and Y. Fu. Exploration of the power of attribute-oriented induction in data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining. In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy (eds.),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Advances in Knowledge Discovery and Data Mining, pp. 399–421. AAAI/MIT Press, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HFLP01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. S. Horn, L. Feng, Y. Li, and A. J. Pesce. Effect of outliers and nonhealthy individuals'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on reference interval estimation. Clinical Chemistry, 47:2137–2145, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HG05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. A. Heller and Z. Ghahramani. Bayesian hierarchical clustering. In Proc. 22nd Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Machine Learning (ICML’05), pp. 297–304, Bonn, Germany, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HG07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Hinneburg and H.-H. Gabriel. DENCLUE 2.0: Fast clustering based on kernel den-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sity estimation. In Proc. 2007 Int. Conf. Intelligent Data Analysis (IDA’07), pp. 70–80,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Ljubljana, Slovenia, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HGC95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Heckerman, D. Geiger, and D. M. Chickering. Learning Bayesian networks:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'The combination of knowledge and statistical data. Machine Learning, 20:197–243,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HH01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. J. Hilderman and H. J. Hamilton. Knowledge Discovery and Measures of Interest.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Kluwer Academic, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HHW97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Hellerstein, P. Haas, and H. Wang. Online aggregation. In Proc. 1997 ACM-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SIGMOD Int. Conf. Management of Data (SIGMOD’97), pp. 171–182, Tucson, AZ, May'\n",
            "Warning: Text found before any chapter, section, or subsection: '1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hig08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. C. Higgins. Analysis for Financial Management with S&P Bind-In Card. Irwin/'\n",
            "Warning: Text found before any chapter, section, or subsection: 'McGraw-Hill, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HK91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. Hoschka and W. Kl¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'osgen. A support system for interpreting statistical data. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Piatetsky-Shapiro and W. J. Frawley (eds.), Knowledge Discovery in Databases,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 325–346. AAAI/MIT Press, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HK98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Hinneburg and D. A. Keim. An efﬁcient approach to clustering in large multimedia'\n",
            "Warning: Text found before any chapter, section, or subsection: 'databases with noise. In Proc. 1998 Int. Conf. Knowledge Discovery and Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’98), pp. 58–65, New York, NY, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HKGT03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Hadjieleftheriou, G. Kollios, D. Gunopulos, and V. J. Tsotras. Online discovery of'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dense areas in spatio-temporal databases. In Proc. 2003 Int. Symp. Spatial and Temporal'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Databases (SSTD’03), pp. 306–324, Santorini Island, Greece, July 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HKKR99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. H¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'oppner, F. Klawonn, R. Kruse, and T. Runkler. Fuzzy Cluster Analysis: Methods for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Classiﬁcation, Data Analysis and Image Recognition. Wiley, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HKP91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Hertz, A. Krogh, and R. G. Palmer. Introduction to the Theory of Neural Computation.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Reading, MA: Addison-Wesley, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HLW07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Hsu, M. L. Lee, and J. Wang. Temporal and Spatio-Temporal Data Mining. IGI'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Publishing, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HLZ02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Hsu, M. L. Lee, and J. Zhang. Image mining: Trends and developments. J. Intelligent'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Information Systems, 19:7–23, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '649'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HMM86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Hong, I. Mozetic, and R. S. Michalski. Incremental learning of attribute-based'\n",
            "Warning: Text found before any chapter, section, or subsection: 'descriptions from examples, the method and user’s guide. In Report ISG 85-5,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'UIUCDCS-F-86-949, Department of Computer Science, University of Illinois at'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Urbana-Champaign, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HMS66]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. B. Hunt, J. Marin, and P. T. Stone. Experiments in Induction. Academic Press, 1966.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HMS01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. J. Hand, H. Mannila, and P. Smyth. Principles of Data Mining (Adaptive Computation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Machine Learning). Cambridge, MA: MIT Press, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HN90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Hecht-Nielsen. Neurocomputing. Reading, MA: Addison-Wesley, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hor08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Horak. Telecommunications and Data Communications Handbook (2nd ed.). Wiley-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Interscience, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HP07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Hua and J. Pei. Cleaning disguised missing data: A heuristic approach. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2007 ACM SIGKDD Intl. Conf. Knowledge Discovery and Data Mining (KDD’07),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 950–958, San Jose, CA, Aug. 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HPDW01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han, J. Pei, G. Dong, and K. Wang. Efﬁcient computation of iceberg cubes with'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex measures. In Proc. 2001 ACM-SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’01), pp. 1–12, Santa Barbara, CA, May 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HPS97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Hosking, E. Pednault, and M. Sudan. A statistical perspective on data mining. Future'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Generation Computer Systems, 13:117–134, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HPY00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2000 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’00), pp. 1–12,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Dallas, TX, May 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HRMS10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boosting the accuracy of differentially-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'private queries through consistency. In Proc. 2010 Int. Conf. Very Large Data Bases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(VLDB’10), pp. 1021–1032, Singapore, Sept. 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HRU96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Harinarayan, A. Rajaraman, and J. D. Ullman. Implementing data cubes efﬁciently. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’96), pp. 205–216,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Montreal, Quebec, Canada, June 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HS05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. M. Hellerstein and M. Stonebraker. Readings in Database Systems (4th ed.). Cam-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bridge, MA: MIT Press, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HSG90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. A. Harp, T. Samad, and A. Guha. Designing application-speciﬁc neural networks'\n",
            "Warning: Text found before any chapter, section, or subsection: 'using the genetic algorithm. In D. S. Touretzky (ed.), Advances in Neural Information'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Processing Systems II, pp. 447–454. Morgan Kaufmann, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HT98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Hastie and R. Tibshirani. Classiﬁcation by pairwise coupling. Ann. Statistics, 26:451–'\n",
            "Warning: Text found before any chapter, section, or subsection: '471, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HTF09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning: Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining, Inference, and Prediction (2nd ed.). Springer Verlag, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hua98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Huang. Extensions to the k-means algorithm for clustering large data sets with'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categorical values. Data Mining and Knowledge Discovery, 2:283–304, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hub94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. H. Huberty. Applied Discriminant Analysis. Wiley-Interscience, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Hub96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. B. Hubbard. The World According to Wavelets. A. K. Peters, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HWB+04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Huan, W. Wang, D. Bandyopadhyay, J. Snoeyink, J. Prins, and A. Tropsha. Min-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing spatial motifs from protein structure graphs. In Proc. 8th Int. Conf. Research in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Computational Molecular Biology (RECOMB), pp. 308–315, San Diego, CA, Mar. 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '650'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[HXD03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. He, X. Xu, and S. Deng. Discovering cluster-based local outliers. Pattern Recognition'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Lett., 24:1641–1650, June, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[IGG03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Imhoff, N. Galemmo, and J. G. Geiger. Mastering Data Warehouse Design: Relational'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Dimensional Techniques. John Wiley & Sons, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[IKA02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Imielinski, L. Khachiyan, and A. Abdulghani. Cubegrades: Generalizing association'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rules. Data Mining and Knowledge Discovery, 6:219–258, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[IM96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Commu-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nications of the ACM, 39:58–64, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Inm96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. H. Inmon. Building the Data Warehouse. John Wiley & Sons, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[IWM98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Inokuchi, T. Washio, and H. Motoda. An apriori-based algorithm for mining frequent'\n",
            "Warning: Text found before any chapter, section, or subsection: 'substructures from graph data. In Proc. 2000 European Symp. Principles of Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Knowledge Discovery (PKDD’00), pp. 13–23, Lyon, France, Sept. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Jac88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Jacobs. Increased rates of convergence through learning rate adaptation. Neural'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Networks, 1:295–307, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Jai10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. K. Jain. Data clustering: 50 years beyond k-means. Pattern Recognition Lett.,'\n",
            "Warning: Text found before any chapter, section, or subsection: '31(8):651–666, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Jam85]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. James. Classiﬁcation Algorithms. John Wiley & Sons, 1985.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JBD05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Ji, J. Bailey, and G. Dong. Mining minimal distinguishing subsequence patterns with'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gap constraints. In Proc. 2005 Int. Conf. Data Mining (ICDM’05), pp. 194–201, Houston,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'TX, Nov. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JD88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. K. Jain and R. C. Dubes. Algorithms for Clustering Data. Prentice-Hall, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Jen96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. V. Jensen. An Introduction to Bayesian Networks. Springer Verlag, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JL96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. H. John and P. Langley. Static versus dynamic sampling for data mining. In Proc. 1996'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Int. Conf. Knowledge Discovery and Data Mining (KDD’96), pp. 367–370, Portland, OR,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Aug. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JMF99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: A survey. ACM Computing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Surveys, 31:264–323, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Joh97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. H. John. Enhancements to the Data Mining Process. Ph.D. Thesis, Computer Science'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Department, Stanford University, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Joh99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. H. John. Behind-the-scenes data mining: A report on the KDD-98 panel. SIGKDD'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Explorations, 1:6–8, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JP04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. C. Jones and P. A. Pevzner. An Introduction to Bioinformatics Algorithms. Cambridge,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MA: MIT Press, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JSD+10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Ji, Y. Sun, M. Danilevsky, J. Han, and J. Gao. Graph regularized transductive'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation on heterogeneous information networks. In Proc. 2010 European Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Machine Learning and Principles and Practice of Knowledge Discovery in Databases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(ECMLPKDD’10), pp. 570–586, Barcelona, Spain, Sept. 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JTH01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Jin, K. H. Tung, and J. Han. Mining top-n local outliers in large databases. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2001 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’01), pp. 293–298,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'San Fransisco, CA, Aug. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JTHW06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Jin, A. K. H. Tung, J. Han, and W. Wang. Ranking outliers using symmetric neigh-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'borhood relationship. In Proc. 2006 Paciﬁc-Asia Conf. Knowledge Discovery and Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining (PAKDD’06), Singapore, Apr. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JW92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. A. Johnson and D. A. Wichern. Applied Multivariate Statistical Analysis (3rd ed.).'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Prentice-Hall, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '651'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JW02a]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Jeh and J. Widom. SimRank: A measure of structural-context similarity. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2002 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’02),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 538–543, Edmonton, Alberta, Canada, July 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[JW02b]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. A. Johnson and D. A. Wichern. Applied Multivariate Statistical Analysis (5th ed.).'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Prentice Hall, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kam09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Kamath. Scientiﬁc Data Mining: A Practical Perspective. Society for Industrial and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Applied Mathematic (SIAM), 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kas80]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. V. Kass. An exploratory technique for investigating large quantities of categorical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data. Applied Statistics, 29:119–127, 1980.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KBDM09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Kulis, S. Basu, I. Dhillon, and R. Mooney. Semi-supervised graph clustering: A kernel'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approach. Machine Learning, 74:1–22, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kec01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Kecman. Learning and Soft Computing. Cambridge, MA: MIT Press, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kei97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. A. Keim. Visual techniques for exploring databases. In Tutorial Notes, 3rd Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery and Data Mining (KDD’97), Newport Beach, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Ker92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Kerber. ChiMerge: Discretization of numeric attributes. In Proc. 1992 Nat. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Artiﬁcial Intelligence (AAAI’92), pp. 123–128, San Jose, CA, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KF09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Cambridge, MA: MIT Press, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KH95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Koperski and J. Han. Discovery of spatial association rules in geographic informa-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion databases. In Proc. 1995 Int. Symp. Large Spatial Databases (SSD’95), pp. 47–66,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Portland, ME, Aug. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KH97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. Kononenko and S. J. Hong. Attribute selection for modeling. Future Generation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Computer Systems, 13:181–195, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KH09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M.-S. Kim and J. Han. A particle-and-density based evolutionary clustering method for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dynamic networks. In Proc. 2009 Int. Conf. Very Large Data Bases (VLDB’09), Lyon,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'France, Aug. 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KHC97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Kamber, J. Han, and J. Y. Chiang. Metarule-guided mining of multi-dimensional'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rules using data cubes. In Proc. 1997 Int. Conf. Knowledge Discovery and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Mining (KDD’97), pp. 207–210, Newport Beach, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KHK99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Karypis, E.-H. Han, and V. Kumar. CHAMELEON: A hierarchical clustering algo-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rithm using dynamic modeling. COMPUTER, 32:68–75, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KHY+08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Kargupta, J. Han, P. S. Yu, R. Motwani, and V. Kumar. Next Generation of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining. Chapman & Hall/CRC, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KJ97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Kohavi and G. H. John. Wrappers for feature subset selection. Artiﬁcial Intelligence,'\n",
            "Warning: Text found before any chapter, section, or subsection: '97:273–324, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KJSY04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Kargupta, A. Joshi, K. Sivakumar, and Y. Yesha. Data Mining: Next Generation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Challenges and Future Directions. Cambridge, MA: AAAI/MIT Press, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KK01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Kuramochi and G. Karypis. Frequent subgraph discovery. In Proc. 2001 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Mining (ICDM’01), pp. 313–320, San Jose, CA, Nov. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KKW+10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. S. Kim, S. Kim, T. Weninger, J. Han, and T. Abdelzaher. NDPMine: Efﬁciently min-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing discriminative numerical features for pattern-based classiﬁcation. In Proc. 2010'\n",
            "Warning: Text found before any chapter, section, or subsection: 'European Conf. Machine Learning and Principles and Practice of Knowledge Discovery'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in Databases (ECMLPKDD’10), Barcelona, Spain, Sept. 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KKZ09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H.-P. Kriegel, P. Kroeger, and A. Zimek. Clustering high-dimensional data: A survey on'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace clustering, pattern-based clustering, and correlation clustering. ACM Trans.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery from Data (TKDD), 3(1):1–58, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '652'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KLA+08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Khan, H. Le, H. Ahmadi, T. Abdelzaher, and J. Han. DustMiner: Troubleshooting'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interactive complexity bugs in sensor networks. In Proc. 2008 ACM Int. Conf. Embedded'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Networked Sensor Systems (SenSys’08), pp. 99–112, Raleigh, NC, Nov. 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kle99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. M. Kleinberg. Authoritative sources in a hyperlinked environment. J. ACM, 46:'\n",
            "Warning: Text found before any chapter, section, or subsection: '604–632, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KLV+98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. L. Kennedy, Y. Lee, B. Van Roy, C. D. Reed, and R. P. Lippman. Solving Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Problems Through Pattern Recognition. Prentice-Hall, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KM90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Kodratoff and R. S. Michalski. Machine Learning, An Artiﬁcial Intelligence Approach,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Vol. 3. Morgan Kaufmann, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KM94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Kivinen and H. Mannila. The power of sampling in knowledge discovery. In Proc. 13th'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM Symp. Principles of Database Systems, pp. 77–85, Minneapolis, MN, May 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KMN+02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko, R. Silverman, and A. Y. Wu.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'An efﬁcient k-means clustering algorithm: Analysis and implementation. IEEE Trans.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pattern Analysis and Machine Intelligence (PAMI), 24:881–892, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KMR+94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A. I. Verkamo. Finding'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interesting rules from large sets of discovered association rules. In Proc. 3rd Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Information and Knowledge Management, pp. 401–408, Gaithersburg, MD, Nov. 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KMS03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Kubica, A. Moore, and J. Schneider. Tractable group detection on large link data sets.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 2003 Int. Conf. Data Mining (ICDM’03), pp. 573–576, Melbourne, FL, Nov.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KN97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. Knorr and R. Ng. A uniﬁed notion of outliers: Properties and computation. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97), pp. 219–222, Newport'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Beach, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KNNL04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. H. Kutner, C. J. Nachtsheim, J. Neter, and W. Li. Applied Linear Statistical Models'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with Student CD. Irwin, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KNT00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. M. Knorr, R. T. Ng, and V. Tucakov. Distance-based outliers: Algorithms and appli-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cations. The VLDB J., 8:237–253, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Koh95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Kohavi. A study of cross-validation and bootstrap for accuracy estimation and model'\n",
            "Warning: Text found before any chapter, section, or subsection: 'selection. In Proc. 14th Joint Int. Conf. Artiﬁcial Intelligence (IJCAI’95), Vol. 2, pp. 1137–'\n",
            "Warning: Text found before any chapter, section, or subsection: '1143, Montreal, Quebec, Canada, Aug. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kol93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. L. Kolodner. Case-Based Reasoning. Morgan Kaufmann, 1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kon95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. Kononenko. On biases in estimating multi-valued attributes. In Proc. 14th Joint Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Artiﬁcial Intelligence (IJCAI’95), Vol. 2, pp. 1034–1040, Montreal, Quebec, Canada,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Aug. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kot88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. Koton. Reasoning about evidence in causal explanation. In Proc. 7th Nat. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Artiﬁcial Intelligence (AAAI’88), pp. 256–263, St. Paul, MN, Aug. 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KPR98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. M. Kleinberg, C. Papadimitriou, and P. Raghavan. A microeconomic view of data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining. Data Mining and Knowledge Discovery, 2:311–324, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KPS03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. M. Karp, C. H. Papadimitriou, and S. Shenker. A simple algorithm for ﬁnding'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent elements in streams and bags. ACM Trans. Database Systems, 28:51–55, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KR90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. Kaufman and P. J. Rousseeuw. Finding Groups in Data: An Introduction to Cluster'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Analysis. John Wiley & Sons, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KR02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Kimball and M. Ross. The Data Warehouse Toolkit: The Complete Guide to Dimen-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sional Modeling (2nd ed.). John Wiley & Sons, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '653'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KR03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Krane and R. Raymer. Fundamental Concepts of Bioinformatics. Benjamin Cummings,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Kre02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Krebs. Mapping networks of terrorist cells. Connections, 24:43–52 (Winter), 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KRR+00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Kumar, P. Raghavan, S. Rajagopalan, D. Sivakumar, A. Tomkins, and E. Upfal.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Stochastic models for the web graph. In Proc. 2000 IEEE Symp. Foundations of Computer'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Science (FOCS’00), pp. 57–65, Redondo Beach, CA, Nov. 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KRTM08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Kimball, M. Ross, W. Thornthwaite, and J. Mundy. The Data Warehouse Lifecycle'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Toolkit. Hoboken, NJ: John Wiley & Sons, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KSZ08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H.-P. Kriegel, M. Schubert, and A. Zimek. Angle-based outlier detection in high-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional data. In Proc. 2008 ACM SIGKDD Int. Conf. Knowledge Discovery and Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining (KDD’08), pp. 444–452, Las Vegas, NV, Aug. 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KT99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. M. Kleinberg and A. Tomkins. Application of linear algebra in information retrieval'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and hypertext analysis. In Proc. 18th ACM Symp. Principles of Database Systems'\n",
            "Warning: Text found before any chapter, section, or subsection: '(PODS’99), pp. 185–193, Philadelphia, PA, May 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[KYB03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. Korf, M. Yandell, and J. Bedell. BLAST. Sebastopol, CA: O’Reilly Media, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Lam98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Lam. Bayesian network reﬁnement via machine learning approach. IEEE Trans.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pattern Analysis and Machine Intelligence, 20:240–252, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Lau95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. L. Lauritzen. The EM algorithm for graphical association models with missing data.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Computational Statistics and Data Analysis, 19:191–201, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LCH+09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Lo, H. Cheng, J. Han, S. Khoo, and C. Sun. Classiﬁcation of software behaviors'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for failure detection: A discriminative pattern mining approach. In Proc. 2009 ACM'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’09), pp. 557–566, Paris,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'France, June 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LDH+08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. X. Lin, B. Ding, J. Han, F. Zhu, and B. Zhao. Text cube: Computing IR measures'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for multidimensional text database analysis. In Proc. 2008 Int. Conf. Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(ICDM’08), pp. 905–910, Pisa, Italy, Dec. 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LDH+10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Li, B. Ding, J. Han, R. Kays, and P. Nye. Mining periodic behaviors for moving objects.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 2010 ACM SIGKDD Conf. Knowledge Discovery and Data Mining (KDD’10),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 1099–1108, Washington, DC, July 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LDR00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Li, G. Dong, and K. Ramamohanrarao. Making use of the most expressive jumping'\n",
            "Warning: Text found before any chapter, section, or subsection: 'emerging patterns for classiﬁcation. In Proc. 2000 Paciﬁc-Asia Conf. Knowledge Discovery'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Data Mining (PAKDD’00), pp. 220–232, Kyoto, Japan, Apr. 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LDS90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Le Cun, J. S. Denker, and S. A. Solla. Optimal brain damage. In D. Touretzky (ed.),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Advances in Neural Information Processing Systems. Morgan Kaufmann, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Lea96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. B. Leake. CBR in context: The present and future. In D. B. Leake (ed.), Cased-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Based Reasoning: Experiences, Lessons, and Future Directions, pp. 3–30. AAAI Press,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LGT97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Lawrence, C. L. Giles, and A. C. Tsoi. Symbolic conversion, grammatical inference'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and rule extraction for foreign exchange rate prediction. In Y. Abu-Mostafa, A. S.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Weigend, and P. N. Refenes (eds.), Neural Networks in the Capital Markets. London:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'World Scientiﬁc, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHC97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Liu, W. Hsu, and S. Chen. Using general impressions to analyze discovered classiﬁ-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cation rules. In Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 31–36, Newport Beach, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '654'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHF98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Lu, J. Han, and L. Feng. Stock movement and n-dimensional inter-transaction asso-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ciation rules. In Proc. 1998 SIGMOD Workshop Research Issues on Data Mining and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery (DMKD’98), pp. 12:1–12:7, Seattle, WA, June 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHG04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Li, J. Han, and H. Gonzalez. High-dimensional OLAP: A minimal cubing approach.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 2004 Int. Conf. Very Large Data Bases (VLDB’04), pp. 528–539, Toronto,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Ontario, Canada, Aug. 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHKG07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Li, J. Han, S. Kim, and H. Gonzalez. Roam: Rule- and motif-based anomaly detec-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion in massive moving object data sets. In Proc. 2007 SIAM Int. Conf. Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SDM’07), Minneapolis, MN, Apr. 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHM98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Liu, W. Hsu, and Y. Ma. Integrating classiﬁcation and association rule mining. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 1998 Int. Conf. Knowledge Discovery and Data Mining (KDD’98), pp. 80–86,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'New York, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHP01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Li, J. Han, and J. Pei. CMAR: Accurate and efﬁcient classiﬁcation based on multiple'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class-association rules. In Proc. 2001 Int. Conf. Data Mining (ICDM’01), pp. 369–376,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'San Jose, CA, Nov. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHTD02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Liu, F. Hussain, C. L. Tan, and M. Dash. Discretization: An enabling technique. Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining and Knowledge Discovery, 6:393–423, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHW07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J.-G. Lee, J. Han, and K. Whang. Clustering trajectory data. In Proc. 2007 ACM-SIGMOD'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Int. Conf. Management of Data (SIGMOD’07), Beijing, China, June 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHXS06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Liu, J. Han, D. Xin, and Z. Shao. Mining frequent patterns on very high dimen-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sional data: A top-down row enumeration approach. In Proc. 2006 SIAM Int. Conf. Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining (SDM’06), Bethesda, MD, Apr. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LHY+08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Li, J. Han, Z. Yin, J.-G. Lee, and Y. Sun. Sampling Cube: A framework for statistical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP over sampling data. In Proc. 2008 ACM SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’08), pp. 779–790, Vancouver, British Columbia, Canada, June 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Liu06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data. New York:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Springer, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LJK00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Laurikkala, M. Juhola, and E. Kentala. Informal identiﬁcation of outliers in med-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ical data. In Proc. 5th Int. Workshop on Intelligent Data Analysis in Medicine and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pharmacology, Berlin, Germany, Aug. 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LKCH03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y.-K. Lee, W.-Y. Kim, Y. D. Cai, and J. Han. CoMine: Efﬁcient mining of correlated'\n",
            "Warning: Text found before any chapter, section, or subsection: 'patterns. In Proc. 2003 Int. Conf. Data Mining (ICDM’03), pp. 581–584, Melbourne, FL,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Nov. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LKF05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs over time: Densiﬁcation laws,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shrinking diameters and possible explanations. In Proc. 2005 ACM SIGKDD Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery and Data Mining (KDD’05), pp. 177–187, Chicago, IL, Aug. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LLLY03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Liu, H. Lu, W. Lou, and J. X. Yu. On computing, storing and querying frequent'\n",
            "Warning: Text found before any chapter, section, or subsection: 'patterns. In Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’03), pp. 607–612, Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LLMZ04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Li, S. Lu, S. Myagmar, and Y. Zhou. CP-Miner: A tool for ﬁnding copy-paste and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'related bugs in operating system code. In Proc. 2004 Symp. Operating Systems Design'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Implementation (OSDI’04), pp. 20–22, San Francisco, CA, Dec. 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Llo57]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. P. Lloyd. Least squares quantization in PCM. IEEE Trans. Information Theory,'\n",
            "Warning: Text found before any chapter, section, or subsection: '28:128–137, 1982 (original version: Technical Report, Bell Labs, 1957).'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '655'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LLS00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T.-S. Lim, W.-Y. Loh, and Y.-S. Shih. A comparison of prediction accuracy, complex-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ity, and training time of thirty-three old and new classiﬁcation algorithms. Machine'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Learning, 40:203–228, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LM97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Laskey and S. Mahoney. Network fragments: Representing knowledge for construct-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing probabilistic models. In Proc. 13th Annual Conf. Uncertainty in Artiﬁcial Intelligence,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 334–341, San Francisco, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LM98a]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Liu and H. Motoda. Feature Selection for Knowledge Discovery and Data Mining.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Kluwer Academic, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LM98b]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Liu and H. Motoda (eds.). Feature Extraction, Construction, and Selection: A Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining Perspective. Kluwer Academic, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LNHP99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. V. S. Lakshmanan, R. Ng, J. Han, and A. Pang. Optimization of constrained fre-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quent set queries with 2-variable constraints. In Proc. 1999 ACM-SIGMOD Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Management of Data (SIGMOD’99), pp. 157–168, Philadelphia, PA, June 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[L-NK03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Liben-Nowell and J. Kleinberg. The link prediction problem for social networks. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2003 Int. Conf. Information and Knowledge Management (CIKM’03), pp. 556–559,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'New Orleans, LA, Nov. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Los01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Loshin. Enterprise Knowledge Management: The Data Quality Approach. Morgan'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Kaufmann, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LP97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Lenarcik and Z. Piasta. Probabilistic rough classiﬁers with mixture of discrete and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'continuous variables. In T. Y. Lin and N. Cercone (eds.), Rough Sets and Data Mining:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Analysis for Imprecise Data, pp. 373–383, Kluwer Academic, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LPH02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. V. S. Lakshmanan, J. Pei, and J. Han. Quotient cube: How to summarize the semantics'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of a data cube. In Proc. 2002 Int. Conf. Very Large Data Bases (VLDB’02), pp. 778–789,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Hong Kong, China, Aug. 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LPWH02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Liu, Y. Pan, K. Wang, and J. Han. Mining frequent itemsets by opportunistic projec-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion. In Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’02),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 239–248, Edmonton, Alberta, Canada, July 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LPZ03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. V. S. Lakshmanan, J. Pei, and Y. Zhao. QC-Trees: An efﬁcient summary structure'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for semantic OLAP. In Proc. 2003 ACM-SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’03), pp. 64–75, San Diego, CA, June 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LS95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Liu and R. Setiono. Chi2: Feature selection and discretization of numeric attributes.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 1995 IEEE Int. Conf. Tools with AI (ICTAI’95), pp. 388–391, Washington, DC,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Nov. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LS97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Y. Loh and Y. S. Shih. Split selection methods for classiﬁcation trees. Statistica Sinica,'\n",
            "Warning: Text found before any chapter, section, or subsection: '7:815–840, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LSBZ87]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. Langley, H. A. Simon, G. L. Bradshaw, and J. M. Zytkow. Scientiﬁc Discovery:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Computational Explorations of the Creative Processes. Cambridge, MA: MIT Press, 1987.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LSL95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Lu, R. Setiono, and H. Liu. Neurorule: A connectionist approach to data mining. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95), pp. 478–489, Zurich, Switzerland,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Sept. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LSW97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Lent, A. Swami, and J. Widom. Clustering association rules. In Proc. 1997 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Engineering (ICDE’97), pp. 220–231, Birmingham, England, Apr. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Lux07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'U. Luxburg. A tutorial on spectral clustering. Statistics and Computing, 17:395–416,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '656'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LV88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Y. Loh and N. Vanichsetakul. Tree-structured classiﬁcaiton via generalized discrimi-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nant analysis. J. American Statistical Association, 83:715–728, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[LZ05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Li and Y. Zhou. PR-Miner: Automatically extracting implicit programming rules'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and detecting violations in large software code. In Proc. 2005 ACM SIGSOFT Symp.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Foundations of Software Engineering (FSE’05), Lisbon, Portugal, Sept. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MA03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Mitra and T. Acharya. Data Mining: Multimedia, Soft Computing, and Bioinformatics.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'John Wiley & Sons, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MAE05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Metwally, D. Agrawal, and A. El Abbadi. Efﬁcient computation of frequent and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k elements in data streams. In Proc. 2005 Int. Conf. Database Theory (ICDT’05),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 398–412, Edinburgh, Scotland, Jan. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mac67]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. MacQueen. Some methods for classiﬁcation and analysis of multivariate observations.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 5th Berkeley Symp. Math. Stat. Prob., 1:281–297, Berkeley, CA, 1967.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mag94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Magidson. The CHAID approach to segmentation modeling: CHI-squared automatic'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interaction detection. In R. P. Bagozzi (ed.), Advanced Methods of Marketing Research,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 118–159. Blackwell Business, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Man00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Mannila. Theoretical frameworks of data mining. SIGKDD Explorations, 1:30–32,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MAR96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Mehta, R. Agrawal, and J. Rissanen. SLIQ: A fast scalable classiﬁer for data mining.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 1996 Int. Conf. Extending Database Technology (EDBT’96), pp. 18–32, Avignon,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'France, Mar. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mar09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Marsland. Machine Learning: An Algorithmic Perspective. Chapman & Hall/CRC, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MB88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. J. McLachlan and K. E. Basford. Mixture Models: Inference and Applications to'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Clustering. John Wiley & Sons, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MC03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. V. Mahoney and P. K. Chan. Learning rules for anomaly detection of hostile net-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'work trafﬁc. In Proc. 2003 Int. Conf. Data Mining (ICDM’03), Melbourne, FL, Nov.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MCK+04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. Mamoulis, H. Cao, G. Kollios, M. Hadjieleftheriou, Y. Tao, and D. Cheung. Min-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing, indexing, and querying historical spatiotemporal data. In Proc. 2004 ACM SIGKDD'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Int. Conf. Knowledge Discovery in Databases (KDD’04), pp. 236–245, Seattle, WA, Aug.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MCM83]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. S. Michalski, J. G. Carbonell, and T. M. Mitchell. Machine Learning, An Artiﬁcial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence Approach, Vol. 1. Morgan Kaufmann, 1983.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MCM86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. S. Michalski, J. G. Carbonell, and T. M. Mitchell. Machine Learning, An Artiﬁcial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence Approach, Vol. 2. Morgan Kaufmann, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MD88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Muralikrishna and D. J. DeWitt. Equi-depth histograms for extimating selectiv-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ity factors for multi-dimensional queries. In Proc. 1988 ACM-SIGMOD Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Management of Data (SIGMOD’88), pp. 28–36, Chicago, IL, June 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mei03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Meilˇ'\n",
            "Warning: Text found before any chapter, section, or subsection: 'a. Comparing clusterings by the variation of information. In Proc. 16th Annual'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Computational Learning Theory (COLT’03), pp. 173–187, Washington, DC, Aug.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mei05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Meilˇ'\n",
            "Warning: Text found before any chapter, section, or subsection: 'a. Comparing clusterings: An axiomatic view. In Proc. 22nd Int. Conf. Machine'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Learning (ICML’05), pp. 577–584, Bonn, Germany, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Men03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Mena. Investigative Data Mining with Security and Criminal Detection. Butterworth-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Heinemann, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '657'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MFS95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Malerba, E. Floriana, and G. Semeraro. A further comparison of simpliﬁcation meth-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ods for decision tree induction. In D. Fisher and H. Lenz (eds.), Learning from Data: AI'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Statistics. Springer Verlag, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MH95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. K. Martin and D. S. Hirschberg. The time complexity of decision tree induction. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Technical Report ICS-TR 95-27, pp. 1–27, Department of Information and Computer'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Science, University of California, Irvine, CA, Aug. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MH09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Miller and J. Han. Geographic Data Mining and Knowledge Discovery (2nd ed.).'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chapman & Hall/CRC, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mic83]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. S. Michalski. A theory and methodology of inductive learning. In R. S. Michalski,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. G. Carbonell, and T. M. Mitchell (eds.), Machine Learning: An Artiﬁcial Intelligence'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Approach, Vol. 1, pp. 83–134. Morgan Kaufmann, 1983.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mic92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Michalewicz. Genetic Algorithms + Data Structures = Evolution Programs. Springer'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Verlag, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mil98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. G. Miller. Survival Analysis. Wiley-Interscience, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Min89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Mingers. An empirical comparison of pruning methods for decision-tree induction.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Machine Learning, 4:227–243, 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mir98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Mirkin. Mathematical classiﬁcation and clustering. J. Global Optimization, 12:105–'\n",
            "Warning: Text found before any chapter, section, or subsection: '108, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mit96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Mitchell. An Introduction to Genetic Algorithms. Cambridge, MA: MIT Press, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mit97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. M. Mitchell. Machine Learning. McGraw-Hill, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MK91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Manago and Y. Kodratoff. Induction of decision trees from complex structured data.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In G. Piatetsky-Shapiro and W. J. Frawley (eds.), Knowledge Discovery in Databases,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 289–306. AAAI/MIT Press, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MLSZ06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Q. Mei, C. Liu, H. Su, and C. Zhai. A probabilistic approach to spatiotemporal theme'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern mining on weblogs. In Proc. 15th Int. Conf. World Wide Web (WWW’06),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 533–542, Edinburgh, Scotland, May 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MM95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Major and J. Mangano. Selecting among rules induced from a hurricane database.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Intelligent Information Systems, 4:39–52, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MM02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Manku and R. Motwani. Approximate frequency counts over data streams. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2002 Int. Conf. Very Large Data Bases (VLDB’02), pp. 346–357, Hong Kong, China, Aug.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MN89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. M´'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ezard and J.-P. Nadal. Learning in feedforward layered networks: The tiling'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm. J. Physics, 22:2191–2204, 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MO04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. C. Madeira and A. L. Oliveira. Biclustering algorithms for biological data analysis: A'\n",
            "Warning: Text found before any chapter, section, or subsection: 'survey. IEEE/ACM Trans. Computational Biology and Bioinformatics, 1(1):24–25, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MP69]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. L. Minsky and S. Papert. Perceptrons: An Introduction to Computational Geometry.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Cambridge, MA: MIT Press, 1969.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MRA95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Metha, J. Rissanen, and R. Agrawal. MDL-based decision tree pruning. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1995 Int. Conf. Knowledge Discovery and Data Mining (KDD’95), pp. 216–221, Montreal,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Quebec, Canada, Aug. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MRS08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. D. Manning, P. Raghavan, and H. Schutze. Introduction to Information Retrieval.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Cambridge University Press, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MS03a]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Markou and S. Singh. Novelty detection: A review—part 1: Statistical approaches.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Signal Processing, 83:2481–2497, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '658'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MS03b]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Markou and S. Singh. Novelty detection: A review—part 2: Neural network based'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approaches. Signal Processing, 83:2499–2521, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MST94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Michie, D. J. Spiegelhalter, and C. C. Taylor. Machine Learning, Neural and Statistical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Classiﬁcation. Chichester, England: Ellis Horwood, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MT94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. S. Michalski and G. Tecuci. Machine Learning, A Multistrategy Approach, Vol. 4.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Morgan Kaufmann, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MTV94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Mannila, H. Toivonen, and A. I. Verkamo. Efﬁcient algorithms for discovering asso-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ciation rules. In Proc. AAAI’94 Workshop Knowledge Discovery in Databases (KDD’94),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 181–192, Seattle, WA, July 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MTV97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Mannila, H. Toivonen, and A. I. Verkamo. Discovery of frequent episodes in event'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequences. Data Mining and Knowledge Discovery, 1:259–289, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mur98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. K. Murthy. Automatic construction of decision trees from data: A multi-disciplinary'\n",
            "Warning: Text found before any chapter, section, or subsection: 'survey. Data Mining and Knowledge Discovery, 2:345–389, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Mut05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Muthukrishnan. Data Streams: Algorithms and Applications. Now Publishers, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MXC+07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Q. Mei, D. Xin, H. Cheng, J. Han, and C. Zhai. Semantic annotation of frequent patterns.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM Trans. Knowledge Discovery from Data (TKDD), 15:321–348, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MY97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. J. Miller and Y. Yang. Association rules over interval data. In Proc. 1997 ACM-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SIGMOD Int. Conf. Management of Data (SIGMOD’97), pp. 452–461, Tucson, AZ, May'\n",
            "Warning: Text found before any chapter, section, or subsection: '1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[MZ06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Q. Mei and C. Zhai. A mixture model for contextual text mining. In Proc. 2006'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’06), pp. 649–655,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Philadelphia, PA, Aug. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NB86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Niblett and I. Bratko. Learning decision rules in noisy domains. In M. A. Brammer'\n",
            "Warning: Text found before any chapter, section, or subsection: '(ed.), Expert Systems ’86: Research and Development in Expert Systems III, pp. 25–34.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'British Computer Society Specialist Group on Expert Systems, Dec. 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NBW06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Newman, A.-L. Barabasi, and D. J. Watts. The Structure and Dynamics of Networks.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Princeton University Press, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NC03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. C. Noble and D. J. Cook. Graph-based anomaly detection. In Proc. 2003 ACM'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03), pp. 631–636,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[New10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Newman. Networks: An Introduction. Oxford University Press, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NG04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. E. J. Newman and M. Girvan. Finding and evaluating community structure in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networks. Physical Rev. E, 69:113–128, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NGE-R09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Neville, B. Gallaher, and T. Eliassi-Rad. Evaluating statistical tests for within-network'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁers of relational data. In Proc. 2009 Int. Conf. Data Mining (ICDM’09), pp. 397–'\n",
            "Warning: Text found before any chapter, section, or subsection: '406, Miami, FL, Dec. 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NH94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Ng and J. Han. Efﬁcient and effective clustering method for spatial data mining. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 1994 Int. Conf. Very Large Data Bases (VLDB’94), pp. 144–155, Santiago, Chile,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Sept. 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NJW01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In T. G. Dietterich, S. Becker, and Z. Ghahramani (eds.), Advances in Neural Information'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Processing Systems 14. pp. 849–856, Cambridge, MA: MIT Press, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NK04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Nijssen and J. Kok. A quick start in frequent structure mining can make a difference.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 2004 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’04),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 647–652, Seattle, WA, Aug. 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '659'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NKNW96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Neter, M. H. Kutner, C. J. Nachtsheim, and L. Wasserman. Applied Linear Statistical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Models (4th ed.). Irwin, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NLHP98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang. Exploratory mining and pruning'\n",
            "Warning: Text found before any chapter, section, or subsection: 'optimizations of constrained associations rules. In Proc. 1998 ACM-SIGMOD Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Management of Data (SIGMOD’98), pp. 13–24, Seattle, WA, June 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NRS99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Natsev, R. Rastogi, and K. Shim. Walrus: A similarity retrieval algorithm for image'\n",
            "Warning: Text found before any chapter, section, or subsection: 'databases. In Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 395–406, Philadelphia, PA, June 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[NW99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Nocedal'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Wright.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Numerical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Optimization.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Springer'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Verlag,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[OFG97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. Osuna, R. Freund, and F. Girosi. An improved training algorithm for support vec-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tor machines. In Proc. 1997 IEEE Workshop Neural Networks for Signal Processing'\n",
            "Warning: Text found before any chapter, section, or subsection: '(NNSP’97), pp. 276–285, Amelia Island, FL, Sept. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[OG95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. O’Neil and G. Graefe. Multi-table joins through bitmapped join indices. SIGMOD'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Record, 24:8–11, Sept. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Ols03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. E. Olson. Data Quality: The Accuracy Dimension. Morgan Kaufmann, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Omi03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. Omiecinski. Alternative interest measures for mining associations. IEEE Trans.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge and Data Engineering, 15:57–69, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[OMM+02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. O’Callaghan, A. Meyerson, R. Motwani, N. Mishra, and S. Guha. Streaming-data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithms for high-quality clustering. In Proc. 2002 Int. Conf. Data Engineering'\n",
            "Warning: Text found before any chapter, section, or subsection: '(ICDE’02), pp. 685–696, San Fransisco, CA, Apr. 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[OQ97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. O’Neil and D. Quass. Improved query performance with variant indexes. In Proc. 1997'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97), pp. 38–49, Tucson, AZ,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'May 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ORS98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. ¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Ozden, S. Ramaswamy, and A. Silberschatz. Cyclic association rules. In Proc. 1998 Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Data Engineering (ICDE’98), pp. 412–421, Orlando, FL, Feb. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Pag89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Pagallo. Learning DNF by decision trees. In Proc. 1989 Int. Joint Conf. Artiﬁcial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence (IJCAI’89), pp. 639–644, San Francisco, CA, 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Paw91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Pawlak. Rough Sets, Theoretical Aspects of Reasoning about Data. Kluwer Academic,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PB00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. C. Pinheiro and D. M. Bates. Mixed Effects Models in S and S-PLUS. Springer Verlag,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PBTL99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for association rules. In Proc. 7th Int. Conf. Database Theory (ICDT’99), pp. 398–416,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Jerusalem, Israel, Jan. 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PCT+03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Pan, G. Cong, A. K. H. Tung, J. Yang, and M. Zaki. CARPENTER: Finding closed'\n",
            "Warning: Text found before any chapter, section, or subsection: 'patterns in long biological datasets. In Proc. 2003 ACM SIGKDD Int. Conf. Knowledge'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Discovery and Data Mining (KDD’03), pp. 637–642, Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PCY95a]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. S. Park, M. S. Chen, and P. S. Yu. An effective hash-based algorithm for mining associ-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ation rules. In Proc. 1995 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’95),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 175–186, San Jose, CA, May 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PCY95b]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. S. Park, M. S. Chen, and P. S. Yu. Efﬁcient parallel mining for association rules. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 4th Int. Conf. Information and Knowledge Management, pp. 31–36, Baltimore, MD,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Nov. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Pea88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '660'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PHL01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Pei, J. Han, and L. V. S. Lakshmanan. Mining frequent itemsets with convertible con-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'straints. In Proc. 2001 Int. Conf. Data Engineering (ICDE’01), pp. 433–442, Heidelberg,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Germany, Apr. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PHL+01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Pei, J. Han, H. Lu, S. Nishio, S. Tang, and D. Yang, H-Mine: Hyper-Structure Mining of'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Frequent Patterns in Large Databases. In Proc. 2001 Int. Conf. Data Mining (ICDM’01),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 441–448, San Jose, CA, Nov. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PHL04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. Parsons, E. Haque, and H. Liu. Subspace clustering for high dimensional data: A'\n",
            "Warning: Text found before any chapter, section, or subsection: 'review. SIGKDD Explorations, 6:90–105, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PHM00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Pei, J. Han, and R. Mao. CLOSET: An efﬁcient algorithm for mining frequent closed'\n",
            "Warning: Text found before any chapter, section, or subsection: 'itemsets. In Proc. 2000 ACM-SIGMOD Int. Workshop Data Mining and Knowledge'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Discovery (DMKD’00), pp. 11–20, Dallas, TX, May 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PHM-A+01] J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu. PreﬁxSpan:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining sequential patterns efﬁciently by preﬁx-projected pattern growth. In Proc. 2001'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Int. Conf. Data Engineering (ICDE’01), pp. 215–224, Heidelberg, Germany, Apr. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PHM-A+04] J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining sequential patterns by pattern-growth: The preﬁxSpan approach. IEEE Trans.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge and Data Engineering, 16:1424–1440, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PI97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Poosala and Y. Ioannidis.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Selectivity estimation without the attribute value'\n",
            "Warning: Text found before any chapter, section, or subsection: 'independence assumption. In Proc. 1997 Int. Conf. Very Large Data Bases (VLDB’97),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 486–495, Athens, Greece, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PKGF03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Papadimitriou, H. Kitagawa, P. B. Gibbons, and C. Faloutsos. Loci: Fast outlier detec-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion using the local correlation integral. In Proc. 2003 Int. Conf. Data Engineering'\n",
            "Warning: Text found before any chapter, section, or subsection: '(ICDE’03), pp. 315–326, Bangalore, India, Mar. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PKMT99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Pfeffer, D. Koller, B. Milch, and K. Takusagawa. SPOOK: A system for probabilistic'\n",
            "Warning: Text found before any chapter, section, or subsection: 'object-oriented knowledge representation. In Proc. 15th Annual Conf. Uncertainty in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Artiﬁcial Intelligence (UAI’99), pp. 541–550, Stockholm, Sweden, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PKZT01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Papadias, P. Kalnis, J. Zhang, and Y. Tao. Efﬁcient OLAP operations in spatial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data warehouses. In Proc. 2001 Int. Symp. Spatial and Temporal Databases (SSTD’01),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 443–459, Redondo Beach, CA, July 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PL07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Pang and L. Lee. Opinion mining and sentiment analysis. Foundations and Trends in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Information Retrieval, 2:1–135, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Pla98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. C. Platt. Fast training of support vector machines using sequential minimal'\n",
            "Warning: Text found before any chapter, section, or subsection: 'optimization. In B. Sch¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'olkopf, C. J. C. Burges, and A. Smola (eds.), Advances in Kernel'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Methods—Support Vector Learning, pp. 185–208. Cambridge, MA: MIT Press, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PP07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Patcha, and J.-M. Park. An overview of anomaly detection techniques: Existing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'solutions and latest technological trends. Computer Networks, 51(12):3448–3470, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PS85]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. P. Preparata and M. I. Shamos. Computational Geometry: An Introduction. Springer'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Verlag, 1985.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[P-S91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Piatetsky-Shapiro. Notes AAAI’91 Workshop Knowledge Discovery in Databases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’91). Anaheim, CA, July 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[P-SF91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Piatetsky-Shapiro and W. J. Frawley. Knowledge Discovery in Databases. AAAI/MIT'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Press, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PTCX04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Pan, A. K. H. Tung, G. Cong, and X. Xu. COBBLER: Combining column and row'\n",
            "Warning: Text found before any chapter, section, or subsection: 'enumeration for closed pattern discovery. In Proc. 2004 Int. Conf. Scientiﬁc and Statistical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Database Management (SSDBM’04), pp. 21–30, Santorini Island, Greece, June 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '661'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PTVF07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. H. Press, S. A. Teukolosky, W. T. Vetterling, and B. P. Flannery. Numerical Recipes:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'The Art of Scientiﬁc Computing. Cambridge: Cambridge University Press, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PY10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Trans. Knowledge and Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Engineering, 22:1345–1359, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Pyl99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Pyle. Data Preparation for Data Mining. Morgan Kaufmann, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[PZC+03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Pei, X. Zhang, M. Cho, H. Wang, and P. S. Yu. Maple: A fast algorithm for maximal'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-based clustering. In Proc. 2003 Int. Conf. Data Mining (ICDM’03), pp. 259–266,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Melbourne, FL, Dec. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[QC-J93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan and R. M. Cameron-Jones. FOIL: A midterm report. In Proc. 1993'\n",
            "Warning: Text found before any chapter, section, or subsection: 'European Conf. Machine Learning (ECML’93), pp. 3–20, Vienna, Austria, 1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[QR89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan and R. L. Rivest. Inferring decision trees using the minimum description'\n",
            "Warning: Text found before any chapter, section, or subsection: 'length principle. Information and Computation, 80:227–248, Mar. 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. Induction of decision trees. Machine Learning, 1:81–106, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui87]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. Simplifying decision trees. Int. J. Man-Machine Studies, 27:221–234, 1987.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. An empirical comparison of genetic and decision-tree classiﬁers. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1988 Int. Conf. Machine Learning (ICML’88), pp. 135–141, Ann Arbor, MI, June 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. Unknown attribute values in induction. In Proc. 1989 Int. Conf. Machine'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Learning (ICML’89), pp. 164–168, Ithaca, NY, June 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. Learning logic deﬁnitions from relations. Machine Learning, 5:139–166,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann, 1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Qui96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. R. Quinlan. Bagging, boosting, and C4.5. In Proc. 1996 Nat. Conf. Artiﬁcial Intelligence'\n",
            "Warning: Text found before any chapter, section, or subsection: '(AAAI’96), Vol. 1, pp. 725–730, Portland, OR, Aug. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RA87]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. L. Rissland and K. Ashley. HYPO: A case-based system for trade secret law. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1st Int. Conf. Artiﬁcial Intelligence and Law, pp. 60–66, Boston, MA, May 1987.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Rab89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recognition. Proc. IEEE, 77:257–286, 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RBKK95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Russell, J. Binder, D. Koller, and K. Kanazawa. Local learning in probabilistic networks'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with hidden variables. In Proc. 1995 Joint Int. Conf. Artiﬁcial Intelligence (IJCAI’95),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 1146–1152, Montreal, Quebec, Canada, Aug. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RC07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Ramakrishnan and B.-C. Chen. Exploratory mining in cube space. Data Mining and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery, 15:29–54, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Red92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Redman. Data Quality: Management and Technology. Bantam Books, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Red01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Redman. Data Quality: The Field Guide. Digital Press (Elsevier), 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RG03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Ramakrishnan and J. Gehrke. Database Management Systems (3rd ed.). McGraw-Hill,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RGN10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. De Raedt, T. Guns, and S. Nijssen. Constraint programming for data mining and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'machine learning. In Proc. 2010 AAAI Conf. Artiﬁcial Intelligence (AAAI’10), pp. 1671–'\n",
            "Warning: Text found before any chapter, section, or subsection: '1675, Atlanta, GA, July 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RH01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. Raman and J. M. Hellerstein. Potter’s wheel: An interactive data cleaning system. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2001 Int. Conf. Very Large Data Bases (VLDB’01), pp. 381–390, Rome, Italy, Sept.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RH07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Rosenberg and J. Hirschberg. V-measure: A conditional entropy-based external'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster evaluation measure. In Proc. 2007 Joint Conf. Empirical Methods in Natural Lan-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'guage Processing and Computational Natural Language Learning (EMNLP-CoNLL’07),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 410–420, Prague, Czech Republic, June 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '662'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RHS01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. F. Roddick, K. Hornsby, and M. Spiliopoulou. An updated bibliography of tempo-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ral, spatial, and spatio-temporal data mining research. In J. F. Roddick and K. Hornsby'\n",
            "Warning: Text found before any chapter, section, or subsection: '(eds.), TSDM 2000, Lecture Notes in Computer Science 2007, pp. 147–163. New York:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Springer, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RHW86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning internal representations by'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error propagation. In D. E. Rumelhart and J. L. McClelland (eds.), Parallel Distributed'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Processing. Cambridge, MA: MIT Press, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Rip96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. D. Ripley. Pattern Recognition and Neural Networks. Cambridge University Press,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RM86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. E. Rumelhart and J. L. McClelland. Parallel Distributed Processing. Cambridge, MA:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MIT Press, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RMS98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Ramaswamy, S. Mahajan, and A. Silberschatz. On the discovery of interesting pat-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'terns in association rules. In Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 368–379, New York, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RN95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Russell and P. Norvig. Artiﬁcial Intelligence: A Modern Approach. Prentice-Hall, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RNI09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Radovanovi´'\n",
            "Warning: Text found before any chapter, section, or subsection: 'c, A. Nanopoulos, and M. Ivanovi´'\n",
            "Warning: Text found before any chapter, section, or subsection: 'c. Nearest neighbors in high-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional data: The emergence and inﬂuence of hubs. In Proc. 2009 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Machine Learning (ICML’09), pp. 865–872, Montreal, Quebec, Canada, June 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Ros58]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Rosenblatt. The perceptron: A probabilistic model for information storage and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'organization in the brain. Psychological Rev., 65:386–498, 1958.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RS89]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Riesbeck and R. Schank. Inside Case-Based Reasoning. Lawrence Erlbaum, 1989.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RS97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Ross and D. Srivastava. Fast computation of sparse datacubes. In Proc. 1997 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Very Large Data Bases (VLDB’97), pp. 116–125, Athens, Greece, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RS98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Rastogi and K. Shim. Public: A decision tree classifer that integrates building and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pruning. In Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98), pp. 404–415,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'New York, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RS01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Ramsey and D. Schafer. The Statistical Sleuth: A Course in Methods of Data Analysis.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Duxbury Press, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[RSC98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. A. Ross, D. Srivastava, and D. Chatziantoniou. Complex aggregation at multiple gran-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ularities. In Proc. Int. Conf. Extending Database Technology (EDBT’98), pp. 263–277,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Valencia, Spain, Mar. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Rus06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. C. Russ. The Image Processing Handbook (5th ed.). CRC Press, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SA95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Srikant and R. Agrawal. Mining generalized association rules. In Proc. 1995 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Very Large Data Bases (VLDB’95), pp. 407–419, Zurich, Switzerland, Sept. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SA96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Srikant and R. Agrawal. Mining sequential patterns: Generalizations and perfor-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mance improvements. In Proc. 5th Int. Conf. Extending Database Technology (EDBT’96),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 3–17, Avignon, France, Mar. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SAM96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Shafer, R. Agrawal, and M. Mehta. SPRINT: A scalable parallel classiﬁer for data min-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing. In Proc. 1996 Int. Conf. Very Large Data Bases (VLDB’96), pp. 544–555, Bombay,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'India, Sept. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SAM98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Sarawagi, R. Agrawal, and N. Megiddo. Discovery-driven exploration of OLAP data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cubes. In Proc. Int. Conf. Extending Database Technology (EDBT’98), pp. 168–182,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Valencia, Spain, Mar. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '663'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SBSW99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Sch¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'olkopf, P. L. Bartlett, A. Smola, and R. Williamson. Shrinking the tube: A new'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support vector regression algorithm. In M. S. Kearns, S. A. Solla, and D. A. Cohn (eds.),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Advances in Neural Information Processing Systems 11, pp. 330–336. Cambridge, MA:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MIT Press, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SC03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Shekhar and S. Chawla. Spatial Databases: A Tour. Prentice-Hall, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Sch86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. C. Schlimmer. Learning and representation change. In Proc. 1986 Nat. Conf. Artiﬁcial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence (AAAI’86), pp. 511–515, Philadelphia, PA, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Sch07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. E. Schaeffer. Graph clustering. Computer Science Rev., 1:27–64, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SCZ98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Sheikholeslami, S. Chatterjee, and A. Zhang. WaveCluster: A multi-resolution clus-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tering approach for very large spatial databases. In Proc. 1998 Int. Conf. Very Large Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bases (VLDB’98), pp. 428–439, New York, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SD90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. W. Shavlik and T. G. Dietterich. Readings in Machine Learning. Morgan Kaufmann,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SD02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Soukup and I. Davidson. Visual Data Mining: Techniques and Tools for Data Visual-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ization and Mining. Wiley, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SDJL96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Srivastava, S. Dar, H. V. Jagadish, and A. V. Levy. Answering queries with aggregation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'using views. In Proc. 1996 Int. Conf. Very Large Data Bases (VLDB’96), pp. 318–329,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bombay, India, Sept. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SDN98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Shukla, P. M. Deshpande, and J. F. Naughton. Materialized view selection for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional datasets. In Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 488–499, New York, Aug. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SE10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Seni and J. F. Elder. Ensemble Methods in Data Mining: Improving Accuracy Through'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Combining Predictions. Morgan and Claypool, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Set10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Settles. Active learning literature survey. In Computer Sciences Technical Report 1648,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'University of Wisconsin–Madison, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SF86]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. C. Schlimmer and D. Fisher. A case study of incremental concept induction. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1986 Nat. Conf. Artiﬁcial Intelligence (AAAI’86), pp. 496–501, Philadelphia, PA, 1986.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SFB99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Shanmugasundaram, U. M. Fayyad, and P. S. Bradley. Compressed data cubes for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP aggregate query approximation on continuous dimensions. In Proc. 1999 Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Knowledge Discovery and Data Mining (KDD’99), pp. 223–232, San Diego, CA,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Aug. 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SG92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. Smyth and R. M. Goodman. An information theoretic approach to rule induction.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IEEE Trans. Knowledge and Data Engineering, 4:301–316, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[She31]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. A. Shewhart. Economic Control of Quality of Manufactured Product. D. Van Nostrand,'\n",
            "Warning: Text found before any chapter, section, or subsection: '1931.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Shi99]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y.-S. Shih. Families of splitting criteria for classiﬁcation trees. Statistics and Computing,'\n",
            "Warning: Text found before any chapter, section, or subsection: '9:309–315, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SHK00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. Stefanovic, J. Han, and K. Koperski. Object-based selective materialization for efﬁ-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cient implementation of spatial data cubes. IEEE Trans. Knowledge and Data Engi-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neering, 12:938–958, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Sho97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Shoshani. OLAP and statistical databases: Similarities and differences. In Proc. 16th'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM Symp. Principles of Database Systems, pp. 185–196, Tucson, AZ, May 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Shu88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. H. Shumway. Applied Statistical Time Series Analysis. Prentice-Hall, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '664'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SHX04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Shao, J. Han, and D. Xin. MM-Cubing: Computing iceberg cubes by factorizing the'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lattice space. In Proc. 2004 Int. Conf. Scientiﬁc and Statistical Database Management'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SSDBM’04), pp. 213–222, Santorini Island, Greece, June 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SHZ+09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Sun, J. Han, P. Zhao, Z. Yin, H. Cheng, and T. Wu. RankClus: Integrating clustering'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with ranking for heterogeneous information network analysis. In Proc. 2009 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Extending Data Base Technology (EDBT’09), pp. 565–576, Saint Petersburg, Russia, Mar.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Sil10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Silvestri. Mining query logs: Turning search usage data into knowledge. Foundations'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Trends in Information Retrieval, 4:1–174, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SK08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Shieh and E. Keogh. iSAX: Indexing and mining terabyte sized time series. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2008 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’08), pp. 623–'\n",
            "Warning: Text found before any chapter, section, or subsection: '631, Las Vegas, NV, Aug. 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SKS10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Silberschatz, H. F. Korth, and S. Sudarshan. Database System Concepts (6th ed.).'\n",
            "Warning: Text found before any chapter, section, or subsection: 'McGraw-Hill, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SLT+01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Shekhar, C.-T. Lu, X. Tan, S. Chawla, and R. R. Vatsavai. Map cube: A visualiza-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion tool for spatial data warehouses. In H. J. Miller and J. Han (eds.), Geographic Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining and Knowledge Discovery, pp. 73–108. Taylor and Francis, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SM97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. C. Setubal and J. Meidanis. Introduction to Computational Molecular Biology. PWS'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Publishing Co., 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SMT91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. W. Shavlik, R. J. Mooney, and G. G. Towell. Symbolic and neural learning algorithms:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'An experimental comparison. Machine Learning, 6:111–144, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SN88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Saito and R. Nakano. Medical diagnostic expert system based on PDP model. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1988 IEEE Int. Conf. Neural Networks, pp. 225–262, San Mateo, CA, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SOMZ96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Shen, K. Ong, B. Mitbander, and C. Zaniolo. Metaqueries for data mining. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy (eds.), Advances in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery and Data Mining, pp. 375–398. AAAI/MIT Press, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SON95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Savasere, E. Omiecinski, and S. Navathe. An efﬁcient algorithm for mining associa-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion rules in large databases. In Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 432–443, Zurich, Switzerland, Sept. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SON98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Savasere, E. Omiecinski, and S. Navathe. Mining for strong negative associations in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'a large database of customer transactions. In Proc. 1998 Int. Conf. Data Engineering'\n",
            "Warning: Text found before any chapter, section, or subsection: '(ICDE’98), pp. 494–502, Orlando, FL, Feb. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SR81]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Sokal and F. Rohlf. Biometry. Freeman, 1981.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SR92]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Skowron and C. Rauszer. The discernibility matrices and functions in information'\n",
            "Warning: Text found before any chapter, section, or subsection: 'systems. In R. Slowinski (ed.), Intelligent Decision Support, Handbook of Applications'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Advances of the Rough Set Theory, pp. 331–362. Kluwer Academic, 1992.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SS88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Siedlecki and J. Sklansky. On automatic feature selection. Int. J. Pattern Recognition'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Artiﬁcial Intelligence, 2:197–220, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SS94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Sarawagi and M. Stonebraker. Efﬁcient organization of large multidimensional arrays.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 1994 Int. Conf. Data Engineering (ICDE’94), pp. 328–336, Houston, TX, Feb.'\n",
            "Warning: Text found before any chapter, section, or subsection: '1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SS01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. Sathe and S. Sarawagi. Intelligent rollups in multidimensional OLAP data. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2001 Int. Conf. Very Large Data Bases (VLDB’01), pp. 531–540, Rome, Italy, Sept.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '665'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SS05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. H. Shumway and D. S. Stoffer. Time Series Analysis and Its Applications. New York:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Springer, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ST96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Silberschatz and A. Tuzhilin. What makes patterns interesting in knowledge discovery'\n",
            "Warning: Text found before any chapter, section, or subsection: 'systems. IEEE Trans. Knowledge and Data Engineering, 8:970–974, Dec. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[STA98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Sarawagi, S. Thomas, and R. Agrawal. Integrating association rule mining with rela-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tional database systems: Alternatives and implications. In Proc. 1998 ACM-SIGMOD Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Management of Data (SIGMOD’98), pp. 343–354, Seattle, WA, June 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[STH+10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Sun, J. Tang, J. Han, M. Gupta, and B. Zhao. Community evolution detection in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dynamic heterogeneous information networks. In Proc. 2010 KDD Workshop Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Learning with Graphs (MLG’10), Washington, DC, July 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Ste72]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Stefansky. Rejecting outliers in factorial designs. Technometrics, 14:469–479, 1972.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Sto74]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Stone. Cross-validatory choice and assessment of statistical predictions. J. Royal'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Statistical Society, 36:111–147, 1974.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SVA97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97), pp. 67–73,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Newport Beach, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SW49]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. E. Shannon and W. Weaver. The Mathematical Theory of Communication. University'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of Illinois Press, 1949.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Swe88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Swets. Measuring the accuracy of diagnostic systems. Science, 240:1285–1293, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Swi98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Swiniarski. Rough sets and principal component analysis and their applications in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'feature extraction and selection, data model building and classiﬁcation. In S. K. Pal'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and A. Skowron (eds.), Rough Fuzzy Hybridization: A New Trend in Decision-Making,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Springer Verlag, Singapore, 1999.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SWJR07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Song, M. Wu, C. Jermaine, and S. Ranka. Conditional anomaly detection. IEEE Trans.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on Knowledge and Data Engineering, 19(5):631–645, 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[SZ04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Shasha and Y. Zhu. High Performance Discovery in Time Series: Techniques and Case'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Studies. New York: Springer, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TD02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. M. J. Tax and R. P. W. Duin. Using two-class classiﬁers for multiclass classiﬁcation. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 16th Intl. Conf. Pattern Recognition (ICPR’2002), pp. 124–127, Montreal, Quebec,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Canada, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TFPL04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Tao, C. Faloutsos, D. Papadias, and B. Liu. Prediction and indexing of moving objects'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with unknown motion patterns. In Proc. 2004 ACM-SIGMOD Int. Conf. Management of'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data (SIGMOD’04), pp. 611–622, Paris, France, June 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TG01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. Tsoukatos and D. Gunopulos. Efﬁcient mining of spatiotemporal patterns. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2001 Int. Symp. Spatial and Temporal Databases (SSTD’01), pp. 425–442, Redondo'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Beach, CA, July 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[THH01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. K. H. Tung, J. Hou, and J. Han. Spatial clustering in the presence of obstacles. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2001 Int. Conf. Data Engineering (ICDE’01), pp. 359–367, Heidelberg, Germany,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apr. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[THLN01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. K. H. Tung, J. Han, L. V. S. Lakshmanan, and R. T. Ng. Constraint-based clustering'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in large databases. In Proc. 2001 Int. Conf. Database Theory (ICDT’01), pp. 405–419,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'London, Jan. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[THP08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Tian, R. A. Hankins, and J. M. Patel. Efﬁcient aggregation for graph summariza-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tion. In Proc. 2008 ACM SIGMOD Int. Conf. Management of Data (SIGMOD’08),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 567–580, Vancouver, British Columbia, Canada, June 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '666'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Thu04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Thuraisingham. Data mining for counterterrorism. In H. Kargupta, A. Joshi,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Sivakumar, and Y. Yesha (eds.), Data Mining: Next Generation Challenges and Future'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Directions, pp. 157–183. AAAI/MIT Press, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TK08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Theodoridis and K. Koutroumbas. Pattern Recognition (4th ed.) Academic Press, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TKS02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P.-N. Tan, V. Kumar, and J. Srivastava. Selecting the right interestingness measure for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association patterns. In Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Databases (KDD’02), pp. 32–41, Edmonton, Alberta, Canada, July 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TLZN08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. Tang, H. Liu, J. Zhang, and Z. Nazeri. Community evolution in dynamic multi-mode'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networks. In Proc. 2008 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’08), pp. 677–685, Las Vegas, NV, Aug. 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Toi96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Toivonen. Sampling large databases for association rules. In Proc. 1996 Int. Conf. Very'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Large Data Bases (VLDB’96), pp. 134–145, Bombay, India, Sept. 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TS93]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. G. Towell and J. W. Shavlik. Extracting reﬁned rules from knowledge-based neural'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networks. Machine Learning, 13:71–101, Oct. 1993.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TSK05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. N. Tan, M. Steinbach, and V. Kumar. Introduction to Data Mining. Boston: Addison-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Wesley, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TSS04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Tanay, R. Sharan, and R. Shamir. Biclustering algorithms: A survey. In S. Aluru (ed.),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Handbook of Computational Molecular Biology, pp. 26:1–26:17. London: Chapman &'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Hall, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Tuf83]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. R. Tufte. The Visual Display of Quantitative Information. Graphics Press, 1983.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Tuf90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. R. Tufte. Envisioning Information. Graphics Press, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Tuf97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. R. Tufte. Visual Explanations: Images and Quantities, Evidence and Narrative. Graphics'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Press, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Tuf01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E. R. Tufte. The Visual Display of Quantitative Information (2nd ed.). Graphics Press,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[TXZ06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Tao, X. Xiao, and S. Zhou. Mining distance-based outliers from large databases in any'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metric space. In Proc. 2006 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’06), pp. 394–403, Philadelphia, PA, Aug. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[UBC97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. E. Utgoff, N. C. Berkman, and J. A. Clouse. Decision tree induction based on efﬁcient'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tree restructuring. Machine Learning, 29:5–44, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[UFS91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Uthurusamy, U. M. Fayyad, and S. Spangler. Learning useful rules from inconclusive'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data. In G. Piatetsky-Shapiro and W. J. Frawley (eds.), Knowledge Discovery in Databases,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 141–157. AAAI/MIT Press, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Utg88]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. E. Utgoff. An incremental ID3. In Proc. Fifth Int. Conf. Machine Learning (ICML’88),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 107–120, San Mateo, CA, 1988.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Val87]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. Valduriez. Join indices. ACM Trans. Database Systems, 12:218–246, 1987.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Vap95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. N. Vapnik. The Nature of Statistical Learning Theory. Springer Verlag, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Vap98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. N. Vapnik. Statistical Learning Theory. John Wiley & Sons, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VC71]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative fre-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quencies of events to their probabilities. Theory of Probability and Its Applications,'\n",
            "Warning: Text found before any chapter, section, or subsection: '16:264–280, 1971.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VC03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Vaidya and C. Clifton. Privacy-preserving k-means clustering over vertically parti-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tioned data. In Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mining (KDD’03), Washington, DC, Aug 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '667'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VC06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Vuk and T. Curk. ROC curve, lift chart and calibration plot. Metodoloˇ'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ski zvezki,'\n",
            "Warning: Text found before any chapter, section, or subsection: '3:89–108, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VCZ10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Vaidya, C. W. Clifton, and Y. M. Zhu. Privacy Preserving Data Mining. New York:'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Springer, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VGK02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Vlachos, D. Gunopulos, and G. Kollios. Discovering similar multidimensional trajec-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tories. In Proc. 2002 Int. Conf. Data Engineering (ICDE’02), pp. 673–684, San Fransisco,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CA, Apr. 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VMZ06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A. Veloso, W. Meira, and M. Zaki. Lazy associative classiﬁcaiton. In Proc. 2006 Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Mining (ICDM’06), pp. 645–654, Hong Kong, China, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[vR90]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. J. van Rijsbergen. Information Retrieval. Butterworth, 1990.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[VWI98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. S. Vitter, M. Wang, and B. R. Iyer. Data cube approximation and histograms via'\n",
            "Warning: Text found before any chapter, section, or subsection: 'wavelets. In Proc. 1998 Int. Conf. Information and Knowledge Management (CIKM’98),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 96–104, Washington, DC, Nov. 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Wat95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. S. Waterman. Introduction to Computational Biology: Maps, Sequences, and Genomes'\n",
            "Warning: Text found before any chapter, section, or subsection: '(Interdisciplinary Statistics). CRC Press, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Wat03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. J. Watts. Six Degrees: The Science of a Connected Age. W. W. Norton & Company, 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WB98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Westphal and T. Blaxton. Data Mining Solutions: Methods and Tools for Solving Real-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'World Problems. John Wiley & Sons, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WCH10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Wu, Y. Chen, and J. Han. Re-examination of interestingness measures in pattern'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining: A uniﬁed framework. Data Mining and Knowledge Discovery, 21(3):371–397,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WCRS01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Wagstaff, C. Cardie, S. Rogers, and S. Schr¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'odl. Constrained k-means clustering with'\n",
            "Warning: Text found before any chapter, section, or subsection: 'background knowledge. In Proc. 2001 Int. Conf. Machine Learning (ICML’01), pp. 577–'\n",
            "Warning: Text found before any chapter, section, or subsection: '584, Williamstown, MA, June 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Wei04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G. M. Weiss. Mining with rarity: A unifying framework. SIGKDD Explorations, 6:7–19,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WF94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Wasserman and K. Faust. Social Network Analysis: Methods and Applications. Cam-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bridge University Press, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WF05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. H. Witten and E. Frank. Data Mining: Practical Machine Learning Tools and Techniques'\n",
            "Warning: Text found before any chapter, section, or subsection: '(2nd ed.). Morgan Kaufmann, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WFH11]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I. H. Witten, E. Frank, and M. A. Hall. Data Mining: Practical Machine Learning Tools'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Techniques with Java Implementations (3rd ed.). Boston: Morgan Kaufmann, 2011.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WFYH03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Wang, W. Fan, P. S. Yu, and J. Han. Mining concept-drifting data streams using'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ensemble classiﬁers. In Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Mining (KDD’03), pp. 226–235, Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WHH00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Wang, Y. He, and J. Han. Mining frequent itemsets using support constraints. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2000 Int. Conf. Very Large Data Bases (VLDB’00), pp. 43–52, Cairo, Egypt, Sept.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WHJ+10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Wang, J. Han, Y. Jia, J. Tang, D. Zhang, Y. Yu, and J. Guo. Mining advisor-advisee'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relationships from research publication networks. In Proc. 2010 ACM SIGKDD Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Knowledge Discovery and Data Mining (KDD’10), Washington, DC, July 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WHLT05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Wang, J. Han, Y. Lu, and P. Tzvetkov. TFP: An efﬁcient algorithm for mining top-k'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent closed itemsets. IEEE Trans. Knowledge and Data Engineering, 17:652–664,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '668'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WHP03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Wang, J. Han, and J. Pei. CLOSET+: Searching for the best strategies for mining fre-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quent closed itemsets. In Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Mining (KDD’03), pp. 236–245, Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WI98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. M. Weiss and N. Indurkhya. Predictive Data Mining. Morgan Kaufmann, 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Wid95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Widom. Research problems in data warehousing. In Proc. 4th Int. Conf. Information'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Knowledge Management, pp. 25–30, Baltimore, MD, Nov. 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WIZD04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. Weiss, N. Indurkhya, T. Zhang, and F. Damerau. Text Mining: Predictive Methods for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Analyzing Unstructured Information. New York: Springer, 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WK91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S. M. Weiss and C. A. Kulikowski. Computer Systems That Learn: Classiﬁcation and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Morgan Kaufmann, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WK05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Wang and G. Karypis. HARMONY: Efﬁciently mining the best rules for classiﬁcation.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 2005 SIAM Conf. Data Mining (SDM’05), pp. 205–216, Newport Beach, CA,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apr. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WLFY02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Wang, H. Lu, J. Feng, and J. X. Yu. Condensed cube: An effective approach to reduc-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing data cube size. In Proc. 2002 Int. Conf. Data Engineering (ICDE’02), pp. 155–165,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'San Fransisco, CA, Apr. 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WRL94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B. Widrow, D. E. Rumelhart, and M. A. Lehr. Neural networks: Applications in industry,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business and science. Communications of the ACM, 37:93–105, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WSF95]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. Wang, V. Storey, and C. Firth. A framework for analysis of data quality research. IEEE'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Trans. Knowledge and Data Engineering, 7:623–640, 1995.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Wu83]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. F. J. Wu. On the convergence properties of the EM algorithm. Ann. Statistics, 11:95–'\n",
            "Warning: Text found before any chapter, section, or subsection: '103, 1983.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WW96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Wand and R. Wang. Anchoring data quality dimensions in ontological foundations.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Communications of the ACM, 39:86–95, 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WWYY02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Wang, W. Wang, J. Yang, and P. S. Yu. Clustering by pattern similarity in large'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data sets. In Proc. 2002 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’02),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 418–427, Madison, WI, June 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WXH08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Wu, D. Xin, and J. Han. ARCube: Supporting ranking aggregate queries in partially'\n",
            "Warning: Text found before any chapter, section, or subsection: 'materialized data cubes. In Proc. 2008 ACM SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’08), pp. 79–92, Vancouver, British Columbia, Canada, June 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WXMH09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Wu, D. Xin, Q. Mei, and J. Han. Promotion analysis in multi-dimensional space. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2009 Int. Conf. Very Large Data Bases (VLDB’09), 2(1):109–120, Lyon, France, Aug.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[WYM97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Wang, J. Yang, and R. Muntz. STING: A statistical information grid approach'\n",
            "Warning: Text found before any chapter, section, or subsection: 'to spatial data mining. In Proc. 1997 Int. Conf. Very Large Data Bases (VLDB’97),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 186–195, Athens, Greece, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XCYH06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Xin, H. Cheng, X. Yan, and J. Han. Extracting redundancy-aware top-k patterns.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In Proc. 2006 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’06),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 444–453, Philadelphia, PA, Aug. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XHCL06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Xin, J. Han, H. Cheng, and X. Li. Answering top-k queries with multi-dimensional'\n",
            "Warning: Text found before any chapter, section, or subsection: 'selections: The ranking cube approach. In Proc. 2006 Int. Conf. Very Large Data Bases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(VLDB’06), pp. 463–475, Seoul, Korea, Sept. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '669'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XHLW03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Xin, J. Han, X. Li, and B. W. Wah. Star-cubing: Computing iceberg cubes by top-down'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and bottom-up integration. In Proc. 2003 Int. Conf. Very Large Data Bases (VLDB’03),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 476–487, Berlin, Germany, Sept. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XHSL06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Xin, J. Han, Z. Shao, and H. Liu. C-cubing: Efﬁcient computation of closed cubes by'\n",
            "Warning: Text found before any chapter, section, or subsection: 'aggregation-based checking. In Proc. 2006 Int. Conf. Data Engineering (ICDE’06), p. 4,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Atlanta, GA, Apr. 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XHYC05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Xin, J. Han, X. Yan, and H. Cheng. Mining compressed frequent-pattern sets. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2005 Int. Conf. Very Large Data Bases (VLDB’05), pp. 709–720, Trondheim, Norway,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Aug. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XOJ00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Xiang, K. G. Olesen, and F. V. Jensen. Practical issues in modeling large diagnostic sys-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tems with multiply sectioned Bayesian networks. Intl. J. Pattern Recognition and Artiﬁcial'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence (IJPRAI), 14:59–71, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XPK10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Xing, J. Pei, and E. Keogh. A brief survey on sequence classiﬁcation. SIGKDD'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Explorations, 12:40–48, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XSH+04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Xiong, S. Shekhar, Y. Huang, V. Kumar, X. Ma, and J. S. Yoo. A framework for discov-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ering co-location patterns in data sets with extended spatial objects. In Proc. 2004 SIAM'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Int. Conf. Data Mining (SDM’04), Lake Buena Vista, FL, Apr. 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XYFS07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Xu, N. Yuruk, Z. Feng, and T. A. J. Schweiger. SCAN: A structural clustering algorithm'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for networks. In Proc. 2007 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’07), pp. 824–833, San Jose, CA, Aug. 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[XZYL08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Xu, Z. M. Zhang, P. S. Yu, and B. Long. Evolutionary clustering by hierarchical Dirich-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'let process with hidden Markov state. In Proc. 2008 Int. Conf. Data Mining (ICDM’08),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 658–667, Pisa, Italy, Dec. 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YC01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. Ye and Q. Chen. An anomaly detection technique based on a chi-square statistic'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for detecting intrusions into information systems. Quality and Reliability Engineering'\n",
            "Warning: Text found before any chapter, section, or subsection: 'International, 17:105–112, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YCHX05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yan, H. Cheng, J. Han, and D. Xin. Summarizing itemset patterns: A proﬁle-based'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approach. In Proc. 2005 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’05), pp. 314–323, Chicago, IL, Aug. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YFB01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Yang, U. Fayyad, and P. S. Bradley. Efﬁcient discovery of error-tolerant frequent item-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sets in high dimensions. In Proc. 2001 ACM SIGKDD Int. Conf. Knowledge Discovery in'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Databases (KDD’01), pp. 194–203, San Fransisco, CA, Aug. 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YFM+97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K. Yoda, T. Fukuda, Y. Morimoto, S. Morishita, and T. Tokuyama. Computing optimized'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rectilinear regions for association rules. In Proc. 1997 Int. Conf. Knowledge Discovery and'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Data Mining (KDD’97), pp. 96–103, Newport Beach, CA, Aug. 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YH02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yan and J. Han. gSpan: Graph-based substructure pattern mining. In Proc. 2002 Int.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Conf. Data Mining (ICDM’02), pp. 721–724, Maebashi, Japan, Dec. 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YH03a]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yan and J. Han. CloseGraph: Mining closed frequent graph patterns. In Proc. 2003'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03), pp. 286–295,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YH03b]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yin and J. Han. CPAR: Classiﬁcation based on predictive association rules. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003 SIAM Int. Conf. Data Mining (SDM’03), pp. 331–335, San Fransisco, CA, May'\n",
            "Warning: Text found before any chapter, section, or subsection: '2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '670'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YHA03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yan, J. Han, and R. Afshar. CloSpan: Mining closed sequential patterns in large'\n",
            "Warning: Text found before any chapter, section, or subsection: 'datasets. In Proc. 2003 SIAM Int. Conf. Data Mining (SDM’03), pp. 166–177,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'San Fransisco, CA, May 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YHF10]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P. S. Yu, J. Han, and C. Faloutsos. Link Mining: Models, Algorithms and Applications. New'\n",
            "Warning: Text found before any chapter, section, or subsection: 'York: Springer, 2010.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YHY05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yin, J. Han, and P. S. Yu. Cross-relational clustering with user’s guidance. In Proc.'\n",
            "Warning: Text found before any chapter, section, or subsection: '2005 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’05), pp. 344–353,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chicago, IL, Aug. 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YHY07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yin, J. Han, and P. S. Yu. Object distinction: Distinguishing objects with identical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'names by link analysis. In Proc. 2007 Int. Conf. Data Engineering (ICDE’07), Istanbul,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Turkey, Apr. 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YHY08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yin, J. Han, and P. S. Yu. Truth discovery with multiple conﬂicting information'\n",
            "Warning: Text found before any chapter, section, or subsection: 'providers on the Web. IEEE Trans. Knowledge and Data Engineering, 20:796–808, 2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YHYY04]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yin, J. Han, J. Yang, and P. S. Yu. CrossMine: Efﬁcient classiﬁcation across multiple'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database relations. In Proc. 2004 Int. Conf. Data Engineering (ICDE’04), pp. 399–410,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Boston, MA, Mar. 2004.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YK09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. Ye and E. Keogh. Time series shapelets: A new primitive for data mining. In'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Proc. 2009 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’09),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 947–956, Paris, France, June 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YWY07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J. Yuan, Y. Wu, and M. Yang. Discovery of collocation patterns: From visual words to'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visual phrases. In Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR’07),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 1–8, Minneapolis, MN, June 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YYH03]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H. Yu, J. Yang, and J. Han. Classifying large data sets using SVM with hierarchical clus-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ters. In Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(KDD’03), pp. 306–315, Washington, DC, Aug. 2003.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YYH05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yan, P. S. Yu, and J. Han. Graph indexing based on discriminative frequent structure'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analysis. ACM Trans. Database Systems, 30:960–993, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YZ94]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R. R. Yager and L. A. Zadeh. Fuzzy Sets, Neural Networks and Soft Computing. Van'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Nostrand Reinhold, 1994.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[YZYH06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Yan, F. Zhu, P. S. Yu, and J. Han. Feature-based substructure similarity search. ACM'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Trans. Database Systems, 31:1418–1453, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zad65]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. A. Zadeh. Fuzzy sets. Information and Control, 8:338–353, 1965.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zad83]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L. Zadeh. Commonsense knowledge representation based on fuzzy logic. Computer,'\n",
            "Warning: Text found before any chapter, section, or subsection: '16:61–65, 1983.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zak00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. J. Zaki. Scalable algorithms for association mining. IEEE Trans. Knowledge and Data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Engineering, 12:372–390, 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zak01]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. Zaki. SPADE: An efﬁcient algorithm for mining frequent sequences. Machine'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Learning, 40:31–60, 2001.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZDN97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Y. Zhao, P. M. Deshpande, and J. F. Naughton. An array-based algorithm for simultan-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'eous multidimensional aggregates. In Proc. 1997 ACM-SIGMOD Int. Conf. Management'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of Data (SIGMOD’97), pp. 159–170, Tucson, AZ, May 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZH02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. J. Zaki and C. J. Hsiao. CHARM: An efﬁcient algorithm for closed itemset min-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ing. In Proc. 2002 SIAM Int. Conf. Data Mining (SDM’02), pp. 457–473, Arlington, VA,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apr. 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bibliography'\n",
            "Warning: Text found before any chapter, section, or subsection: '671'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zha08]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C. Zhai. Statistical Language Models for Information Retrieval. Morgan and Claypool,'\n",
            "Warning: Text found before any chapter, section, or subsection: '2008.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZHL+98]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'O. R. Za¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ıane, J. Han, Z. N. Li, J. Y. Chiang, and S. Chee. MultiMedia-Miner: A sys-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tem prototype for multimedia data mining. In Proc. 1998 ACM-SIGMOD Int. Conf.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Management of Data (SIGMOD’98), pp. 581–583, Seattle, WA, June 1998.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zhu05]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'X. Zhu. Semi-supervised learning literature survey. In Computer Sciences Technical'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Report 1530, University of Wisconsin–Madison, 2005.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZHZ00]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'O. R. Za¨'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ıane, J. Han, and H. Zhu. Mining recurrent items in multimedia with progressive'\n",
            "Warning: Text found before any chapter, section, or subsection: 'resolution reﬁnement. In Proc. 2000 Int. Conf. Data Engineering (ICDE’00), pp. 461–470,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'San Diego, CA, Feb. 2000.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[Zia91]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W. Ziarko. The discovery, analysis, and representation of data dependencies in databases.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'In G. Piatetsky-Shapiro and W. J. Frawley (eds.), Knowledge Discovery in Databases,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 195–209. AAAI Press, 1991.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZL06]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z.-H. Zhou and X.-Y. Liu. Training cost-sensitive neural networks with methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'addressing the class imbalance problem. IEEE Trans. Knowledge and Data Engineering,'\n",
            "Warning: Text found before any chapter, section, or subsection: '18:63–77, 2006.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZPOL97]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithm for discovery of'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rules. Data Mining and Knowledge Discovery, 1:343–374, 1997.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZRL96]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T. Zhang, R. Ramakrishnan, and M. Livny. BIRCH: An efﬁcient data clustering method'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for very large databases. In Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SIGMOD’96), pp. 103–114, Montreal, Quebec, Canada, June 1996.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZS02]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N. Zapkowicz and S. Stephen. The class imbalance program: A systematic study.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Intelligence Data Analysis, 6:429–450, 2002.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZYH+07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Zhu, X. Yan, J. Han, P. S. Yu, and H. Cheng. Mining colossal frequent patterns by'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core pattern fusion. In Proc. 2007 Int. Conf. Data Engineering (ICDE’07), pp. 706–715,'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Istanbul, Turkey, Apr. 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZYHY07]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F. Zhu, X. Yan, J. Han, and P. S. Yu. gPrune: A constraint pushing framework for graph'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern mining. In Proc. 2007 Paciﬁc-Asia Conf. Knowledge Discovery and Data Mining'\n",
            "Warning: Text found before any chapter, section, or subsection: '(PAKDD’07), pp. 388–400, Nanjing, China, May 2007.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZZ09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z. Zhang and R. Zhang. Multimedia Data Mining: A Systematic Introduction to Concepts'\n",
            "Warning: Text found before any chapter, section, or subsection: 'and Theory. Chapman & Hall, 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: '[ZZH09]'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D. Zhang, C. Zhai, and J. Han. Topic cube: Topic modeling for OLAP on multi-'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional text databases. In Proc. 2009 SIAM Int. Conf. Data Mining (SDM’09),'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pp. 1123–1134, Sparks, NV, Apr. 2009.'\n",
            "Warning: Text found before any chapter, section, or subsection: 'This page intentionally left blank'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Numbers and Symbols'\n",
            "Warning: Text found before any chapter, section, or subsection: '.632 bootstrap, 371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'δ-bicluster algorithm, 517–518'\n",
            "Warning: Text found before any chapter, section, or subsection: 'δ-pCluster, 518–519'\n",
            "Warning: Text found before any chapter, section, or subsection: 'A'\n",
            "Warning: Text found before any chapter, section, or subsection: 'absolute-error criterion, 455'\n",
            "Warning: Text found before any chapter, section, or subsection: 'absolute support, 246'\n",
            "Warning: Text found before any chapter, section, or subsection: 'abstraction levels, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute construction and, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boosting, 382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with bootstrap, 371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation, 377–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁer, 330, 366'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with cross-validation, 370–371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 84'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with holdout method, 370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measures, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random forests, 383'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with random subsampling, 370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule selection based on, 361'\n",
            "Warning: Text found before any chapter, section, or subsection: 'activation function, 402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'active learning, 25, 430, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ad hoc data mining, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AdaBoost, 380–382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'TrAdaBoost, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'adaptive probabilistic networks, 397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advanced data analysis, 3, 4'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advanced database systems, 4'\n",
            "Warning: Text found before any chapter, section, or subsection: 'afﬁnity matrix, 520, 521'\n",
            "Warning: Text found before any chapter, section, or subsection: 'agglomerative hierarchical method, 459'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AGNES, 459, 460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'divisive hierarchical clustering versus,'\n",
            "Warning: Text found before any chapter, section, or subsection: '459–460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Agglomerative Nesting (AGNES), 459, 460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'aggregate cells, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'aggregation, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bootstrap, 379'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex data types and, 166'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube computation and, 193'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube, 110–111'\n",
            "Warning: Text found before any chapter, section, or subsection: 'at multiple granularities, 230–231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiway array, 195–199'\n",
            "Warning: Text found before any chapter, section, or subsection: 'simultaneous, 193, 195'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AGNES. See Agglomerative Nesting'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algebraic measures, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithms. See speciﬁc algorithms'\n",
            "Warning: Text found before any chapter, section, or subsection: 'all conﬁdence measure, 268, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'all-versus-all (AVA), 430–431'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analysis of variance (ANOVA), 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analytical processing, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ancestor cells, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'angle-based outlier detection (ABOD), 580'\n",
            "Warning: Text found before any chapter, section, or subsection: 'angle-based outlier factor (ABOF), 580'\n",
            "Warning: Text found before any chapter, section, or subsection: 'anomalies. See outliers'\n",
            "Warning: Text found before any chapter, section, or subsection: 'anomaly mining. See outlier analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'anomaly-based detection, 614'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonic constraints, 298, 301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonic measures, 194'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonicity, 249'\n",
            "Warning: Text found before any chapter, section, or subsection: 'apex cuboids, 111, 138, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application domain-speciﬁc semantics, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 33, 607–618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business intelligence, 27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computer science, 613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'domain-speciﬁc, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'engineering, 613, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exploration, 623'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁnancial data analysis, 607–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intrusion detection/prevention, 614–615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recommender systems, 615–618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'retail industry, 609–611'\n",
            "Warning: Text found before any chapter, section, or subsection: 'science, 611–613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'social science and social studies, 613'\n",
            "Warning: Text found before any chapter, section, or subsection: '673'\n",
            "Warning: Text found before any chapter, section, or subsection: '674'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'targeted, 27–28'\n",
            "Warning: Text found before any chapter, section, or subsection: 'telecommunications industry, 611'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Web search engines, 28'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application-speciﬁc outlier detection, 548–549'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approximate patterns, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 307–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apriori algorithm, 248–253, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dynamic itemset counting, 256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'efﬁciency, improving, 254–256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 250–252'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hash-based technique, 255'\n",
            "Warning: Text found before any chapter, section, or subsection: 'join step, 249'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning, 255–256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prune step, 249–250'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pseudocde, 253'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sampling, 256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transaction reduction, 255'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apriori property, 194, 201, 249'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonicity, 249'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in Apriori algorithm, 298'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apriori pruning method, 194'\n",
            "Warning: Text found before any chapter, section, or subsection: 'arrays'\n",
            "Warning: Text found before any chapter, section, or subsection: '3-D for dimensions, 196'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparse compression, 198–199'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association analysis, 17–18'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rules, 245'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approximate, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Boolean, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compressed, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conﬁdence, 21, 245, 246, 416'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraints, 296–297'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation, 265, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discarded, 17'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁttest, 426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent patterns and, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generation from frequent itemsets, 253, 254'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hybrid-dimensional, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interdimensional, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intradimensional, 287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metarule-guided mining of, 295–296'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimum conﬁdence threshold, 18, 245'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimum support threshold, 245'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional, 17, 287–289, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilevel, 281, 283–287, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'near-match, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'objective measures, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'offspring, 426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantitative, 281, 289, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy-aware top-k, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'single-dimensional, 17, 287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strong, 264–265, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support, 21, 245, 246, 417'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of values in, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'associative classiﬁcation, 415, 416–419, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CBA, 417'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CMAR, 417–418'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CPAR, 418–419'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule conﬁdence, 416'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule support, 417'\n",
            "Warning: Text found before any chapter, section, or subsection: 'steps, 417'\n",
            "Warning: Text found before any chapter, section, or subsection: 'asymmetric binary dissimilarity, 71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'asymmetric binary similarity, 71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute construction, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy and, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multivariate splits, 344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute selection measures, 331, 336–344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CHAID, 343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gain ratio, 340–341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Gini index, 341–343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information gain, 336–340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Minimum Description Length (MDL),'\n",
            "Warning: Text found before any chapter, section, or subsection: '343–344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multivariate splits, 343–344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute subset selection, 100, 103–105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree induction, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'forward selection/backward elimination'\n",
            "Warning: Text found before any chapter, section, or subsection: 'combination, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy methods, 104–105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stepwise backward elimination, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stepwise forward selection, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute vectors, 40, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute-oriented induction (AOI), 166–178, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm, 173'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for class comparisons, 175–178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for data characterization, 167–172'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data generalization by, 166–178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalized relation, 172'\n",
            "Warning: Text found before any chapter, section, or subsection: 'implementation of, 172–174'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attributes, 9, 40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'abstraction level differences, 99'\n",
            "Warning: Text found before any chapter, section, or subsection: 'behavioral, 546, 573'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binary, 41–42, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Boolean, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categorical, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class label, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual, 546, 573'\n",
            "Warning: Text found before any chapter, section, or subsection: 'continuous, 44'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlated, 54–56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimension correspondence, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '675'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrete, 44'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalization, 169–170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalization control, 170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalization threshold control, 170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grouping, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interval-scaled, 43, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of mixed type, 75–77'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nominal, 41, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric, 43–44, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordered, 103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordinal, 41, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'qualitative, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ratio-scaled, 43–44, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reducts of, 427'\n",
            "Warning: Text found before any chapter, section, or subsection: 'removal, 169'\n",
            "Warning: Text found before any chapter, section, or subsection: 'repetition, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'set of, 118'\n",
            "Warning: Text found before any chapter, section, or subsection: 'splitting, 333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'terminology for, 40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'type determination, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 39'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unordered, 103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'audio data mining, 604–607, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'automatic classiﬁcation, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AVA. See all-versus-all'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AVC-group, 347'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AVC-set, 347'\n",
            "Warning: Text found before any chapter, section, or subsection: 'average(), 215'\n",
            "Warning: Text found before any chapter, section, or subsection: 'B'\n",
            "Warning: Text found before any chapter, section, or subsection: 'background knowledge, 30–31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'backpropagation, 393, 398–408, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'activation function, 402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 401'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biases, 402, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'case updating, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'efﬁciency, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'epoch updating, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error, 403'\n",
            "Warning: Text found before any chapter, section, or subsection: 'functioning of, 400–403'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hidden layers, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'input layers, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'input propagation, 401–402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretability and, 406–408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning, 400'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning rate, 403–404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'logistic function, 402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilayer feed-forward neural network,'\n",
            "Warning: Text found before any chapter, section, or subsection: '398–399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'network pruning, 406–407'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neural network topology deﬁnition, 400'\n",
            "Warning: Text found before any chapter, section, or subsection: 'output layers, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sample learning calculations, 404–406'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sensitivity analysis, 408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sigmoid function, 402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'squashing function, 403'\n",
            "Warning: Text found before any chapter, section, or subsection: 'terminating conditions, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unknown tuple classiﬁcation, 406'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weights initialization, 401'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also classiﬁcation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bagging, 379–380'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 380'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boosting versus, 381–382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in building random forests, 383'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bar charts, 54'\n",
            "Warning: Text found before any chapter, section, or subsection: 'base cells, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'base cuboids, 111, 137–138, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Basic Local Alignment Search Tool (BLAST), 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Baum-Welch algorithm, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayes’ theorem, 350–351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian belief networks, 393–397, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithms, 396'\n",
            "Warning: Text found before any chapter, section, or subsection: 'components of, 394'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conditional probability table (CPT),'\n",
            "Warning: Text found before any chapter, section, or subsection: '394, 395'\n",
            "Warning: Text found before any chapter, section, or subsection: 'directed acyclic graph, 394–395'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gradient descent strategy, 396–397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 394'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mechanisms, 394–396'\n",
            "Warning: Text found before any chapter, section, or subsection: 'problem modeling, 395–396'\n",
            "Warning: Text found before any chapter, section, or subsection: 'topology, 396'\n",
            "Warning: Text found before any chapter, section, or subsection: 'training, 396–397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also classiﬁcation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian classiﬁcation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'basis, 350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayes’ theorem, 350–351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class conditional independence, 350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'naive, 351–355, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'posterior probability, 351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prior probability, 351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BCubed precision metric, 488, 489'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BCubed recall metric, 489'\n",
            "Warning: Text found before any chapter, section, or subsection: 'behavioral attributes, 546, 573'\n",
            "Warning: Text found before any chapter, section, or subsection: 'believability, data, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BI (business intelligence), 27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biases, 402, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biclustering, 512–519, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application examples, 512–515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'enumeration methods, 517, 518–519'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gene expression example, 513–514'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 517–518'\n",
            "Warning: Text found before any chapter, section, or subsection: 'optimization-based methods, 517–518'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recommender system example, 514–515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: '676'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biclusters, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with coherent values, 516'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with coherent values on rows, 516'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with constant values, 515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with constant values on columns, 515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with constant values on rows, 515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as submatrix, 515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 515–516'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bimodal, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bin boundaries, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binary attributes, 41, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'asymmetric, 42, 70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as Boolean, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contingency table for, 70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dissimilarity between, 71–72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 41–42'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity measures, 70–72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symmetric, 42, 70–71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also attributes'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binning'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discretization by, 115'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equal-frequency, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'smoothing by bin boundaries, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'smoothing by bin means, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'smoothing by bin medians, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biological sequences, 586, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'alignment of, 590–591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analysis, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BLAST, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hidden Markov model, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as mining trend, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple sequence alignment, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pairwise alignment, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'phylogenetic tree, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'substitution matrices, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bipartite graphs, 523'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BIRCH, 458, 462–466'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CF-trees, 462–463, 464, 465–466'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering feature, 462, 463, 464'\n",
            "Warning: Text found before any chapter, section, or subsection: 'effectiveness, 465'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiphase clustering technique, 464–465'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also hierarchical methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bitmap indexing, 160–161, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bitmapped join indexing, 163, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bivariate distribution, 40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BLAST. See Basic Local Alignment Search Tool'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BOAT. See Bootstrapped Optimistic Algorithm for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Tree construction'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Boolean association rules, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Boolean attributes, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boosting, 380'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy, 382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'AdaBoost, 380–382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bagging versus, 381–382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weight assignment, 381'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bootstrap method, 371, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bottom-up design approach, 133, 151–152'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bottom-up subspace search, 510–511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boxplots, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation, 50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁve-number summary, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in outlier visualization, 555'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BUC, 200–204, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for 3-D data cube computation, 200'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm, 202'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apriori property, 201'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bottom-up construction, 201'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg cube construction, 201'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning snapshot, 203'\n",
            "Warning: Text found before any chapter, section, or subsection: 'performance, 204'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down processing order, 200, 201'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business intelligence (BI), 27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business metadata, 135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business query view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C4.5, 332, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class-based ordering, 358'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gain ratio use, 340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy approach, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pessimistic pruning, 345'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule extraction, 358'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also decision tree induction'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cannot-link constraints, 533'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CART, 332, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cost complexity pruning algorithm, 345'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Gini index use, 341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy approach, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also decision tree induction'\n",
            "Warning: Text found before any chapter, section, or subsection: 'case updating, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'case-based reasoning (CBR), 425–426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'challenges, 426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categorical attributes, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CBA. See Classiﬁcation Based on Associations'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CBLOF. See cluster-based local outlier factor'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CELL method, 562, 563'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cells, 10–11'\n",
            "Warning: Text found before any chapter, section, or subsection: 'aggregate, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ancestor, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'base, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'descendant, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '677'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exceptions, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'residual value, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'central tendency measures, 39, 44, 45–47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mean, 45–46'\n",
            "Warning: Text found before any chapter, section, or subsection: 'median, 46–47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'midrange, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for missing values, 88'\n",
            "Warning: Text found before any chapter, section, or subsection: 'models, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'centroid distance, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CF-trees, 462–463, 464'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nodes, 465'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parameters, 464'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structure illustration, 464'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CHAID, 343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chameleon, 459, 466–467'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering illustration, 466'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relative closeness, 467'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relative interconnectivity, 466–467'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also hierarchical methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chernoff faces, 60'\n",
            "Warning: Text found before any chapter, section, or subsection: 'asymmetrical, 61'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 62'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ChiMerge, 117'\n",
            "Warning: Text found before any chapter, section, or subsection: 'chi-square test, 95'\n",
            "Warning: Text found before any chapter, section, or subsection: 'chunking, 195'\n",
            "Warning: Text found before any chapter, section, or subsection: 'chunks, 195'\n",
            "Warning: Text found before any chapter, section, or subsection: '2-D, 197'\n",
            "Warning: Text found before any chapter, section, or subsection: '3-D, 197'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation of, 198'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scanning order, 197'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CLARA. See Clustering Large Applications'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CLARANS. See Clustering Large Applications'\n",
            "Warning: Text found before any chapter, section, or subsection: 'based upon Randomized Search'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class comparisons, 166, 175, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute-oriented induction for,'\n",
            "Warning: Text found before any chapter, section, or subsection: '175–178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 176'\n",
            "Warning: Text found before any chapter, section, or subsection: 'presentation of, 175–176'\n",
            "Warning: Text found before any chapter, section, or subsection: 'procedure, 175–176'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class conditional independence, 350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class imbalance problem, 384–385, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ensemble methods for, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on multiclass tasks, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'oversampling, 384–385, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'threshold-moving approach, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'undersampling, 384–385, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class label attributes, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class-based ordering, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class/concept descriptions, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classes, 15, 166'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contrasting, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equivalence, 427'\n",
            "Warning: Text found before any chapter, section, or subsection: 'target, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation, 18, 327–328, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy improvement techniques, 377–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'active learning, 433–434'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advanced methods, 393–442'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 327'\n",
            "Warning: Text found before any chapter, section, or subsection: 'associative, 415, 416–419, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'automatic, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'backpropagation, 393, 398–408, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bagging, 379–380'\n",
            "Warning: Text found before any chapter, section, or subsection: 'basic concepts, 327–330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayes methods, 350–355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian belief networks, 393–397, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boosting, 380–382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'case-based reasoning, 425–426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of class-imbalanced data, 383–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'confusion matrix, 365–366, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'costs and beneﬁts, 373–374'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree induction, 330–350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminative frequent pattern-based, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'document, 430'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ensemble methods, 378–379'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evaluation metrics, 364–370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 19'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent pattern-based, 393, 415–422, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy set approaches, 428–429, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'general approach to, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'genetic algorithms, 426–427, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous networks, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'homogeneous networks, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IF-THEN rules for, 355–357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretability, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-nearest-neighbor, 423–425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lazy learners, 393, 422–426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning step, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'model representation, 18'\n",
            "Warning: Text found before any chapter, section, or subsection: 'model selection, 364, 370–377'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiclass, 430–432, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multimedia data mining, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neural networks for, 19, 398–408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-based, 282, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'perception-based, 348–350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'precision measure, 368–369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as prediction problem, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'process, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'process illustration, 329'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random forests, 382–383'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recall measure, 368–369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'robustness, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rough set approach, 427–428, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: '678'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule-based, 355–363, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalability, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised, 432–433, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sentiment, 434'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speed, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support vector machines (SVMs), 393,'\n",
            "Warning: Text found before any chapter, section, or subsection: '408–415, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transfer learning, 434–436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tree pruning, 344–347, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web-document, 435'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Classiﬁcation Based on Associations (CBA), 417'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Classiﬁcation based on Multiple Association Rules'\n",
            "Warning: Text found before any chapter, section, or subsection: '(CMAR), 417–418'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Classiﬁcation based on Predictive Association Rules'\n",
            "Warning: Text found before any chapter, section, or subsection: '(CPAR), 418–419'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation-based outlier detection, 571–573, 582'\n",
            "Warning: Text found before any chapter, section, or subsection: 'one-class model, 571–572'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised learning, 572'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also outlier detection'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁers, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy, 330, 366'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bagged, 379–380'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian, 350, 353'\n",
            "Warning: Text found before any chapter, section, or subsection: 'case-based reasoning, 425–426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'comparing with ROC curves, 373–377'\n",
            "Warning: Text found before any chapter, section, or subsection: 'comparison aspects, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree, 331'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error rate, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-nearest-neighbor, 423–425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Naive Bayesian, 351–352'\n",
            "Warning: Text found before any chapter, section, or subsection: 'overﬁtting data, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'performance evaluation metrics, 364–370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recognition rate, 366–367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule-based, 355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Clementine, 603, 606'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CLIQUE, 481–483'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering steps, 481–482'\n",
            "Warning: Text found before any chapter, section, or subsection: 'effectiveness, 483'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strategy, 481'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis; grid-based methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed data cubes, 192'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed frequent itemsets, 247, 308'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 248'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 262–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shortcomings for compression, 308–309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed graphs, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed patterns, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k most frequent, 307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closure checking, 263–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cloud computing, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster analysis, 19–20, 443–495'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advanced, 497–541'\n",
            "Warning: Text found before any chapter, section, or subsection: 'agglomerative hierarchical clustering,'\n",
            "Warning: Text found before any chapter, section, or subsection: '459–461'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 444, 490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute types and, 446'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as automatic classiﬁcation, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biclustering, 511, 512–519'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BIRCH, 458, 462–466'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chameleon, 458, 466–467'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CLIQUE, 481–483'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering quality measurement, 484, 487–490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering tendency assessment, 484–486'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based, 447, 497, 532–538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation-based, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as data redundancy technique, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as data segmentation, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DBSCAN, 471–473'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DENCLUE, 476–479'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based methods, 449, 471–479, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in derived space, 519–520'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensionality reduction methods, 519–522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discretization by, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance measures, 461–462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'divisive hierarchical clustering, 459–461'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evaluation, 483–490, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 20'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expectation-maximization (EM) algorithm,'\n",
            "Warning: Text found before any chapter, section, or subsection: '505–508'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph and network data, 497, 522–532'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grid-based methods, 450, 479–483, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous networks, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hierarchical methods, 449, 457–470, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'high-dimensional data, 447, 497, 508–522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'homogeneous networks, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in image recognition, 444'\n",
            "Warning: Text found before any chapter, section, or subsection: 'incremental, 446'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretability, 447'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-means, 451–454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-medoids, 454–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-modes, 454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in large databases, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as learning by observation, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'low-dimensional, 509'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 448–451'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple-phase, 458–459'\n",
            "Warning: Text found before any chapter, section, or subsection: 'number of clusters determination, 484, 486–487'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OPTICS, 473–476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'orthogonal aspects, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for outlier detection, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier detection and, 543'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '679'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning methods, 448, 451–457, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern, 282, 308–310'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic hierarchical clustering, 467–470'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probability model-based, 497–508'\n",
            "Warning: Text found before any chapter, section, or subsection: 'PROCLUS, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'requirements, 445–448, 490–491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalability, 446'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in search results organization, 444'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spectral, 519–522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as standalone tool, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'STING, 479–481'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace, 318–319, 448'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace search methods, 510–511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'taxonomy formation, 20'\n",
            "Warning: Text found before any chapter, section, or subsection: 'techniques, 443, 444'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as unsupervised learning, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'usability, 447'\n",
            "Warning: Text found before any chapter, section, or subsection: 'use of, 444'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster computing, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster samples, 108–109'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster-based local outlier factor (CBLOF), 569–570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering. See cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering features, 462, 463, 464'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Clustering Large Applications based upon'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Randomized Search (CLARANS), 457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Clustering Large Applications (CLARA), 456–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering quality measurement, 484t, 487–490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster completeness, 488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster homogeneity, 487–488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extrinsic methods, 487–489'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intrinsic methods, 487, 489–490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rag bag, 488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'silhouette coefﬁcient, 489–490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'small cluster preservation, 488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering space, 448'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering tendency assessment, 484–486'\n",
            "Warning: Text found before any chapter, section, or subsection: 'homogeneous hypothesis, 486'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Hopkins statistic, 484–485'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonhomogeneous hypothesis, 486'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonuniform distribution of data, 484'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering with obstacles problem, 537'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering-based methods, 552, 567–571'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 553'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also outlier detection'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering-based outlier detection, 567–571, 582'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approaches, 567'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance to closest cluster, 568–569'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁxed-width clustering, 570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intrusion detection by, 569–570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'objects not belonging to a cluster, 568'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in small clusters, 570–571'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weakness of, 571'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering-based quantitative associations, 290–291'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clusters, 66, 443, 444, 490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'arbitrary shape, discovery of, 446'\n",
            "Warning: Text found before any chapter, section, or subsection: 'assignment rule, 497–498'\n",
            "Warning: Text found before any chapter, section, or subsection: 'completeness, 488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraints on, 533'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cuts and, 529–530'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based, 472'\n",
            "Warning: Text found before any chapter, section, or subsection: 'determining number of, 484, 486–487'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discovery of, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy, 499–501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph clusters, ﬁnding, 528–529'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on high-dimensional data, 509'\n",
            "Warning: Text found before any chapter, section, or subsection: 'homogeneity, 487–488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'merging, 469, 470'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordering, 474–475, 477'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-based, 516'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic, 502–503'\n",
            "Warning: Text found before any chapter, section, or subsection: 'separation of, 447'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shapes, 471'\n",
            "Warning: Text found before any chapter, section, or subsection: 'small, preservation, 488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CMAR. See Classiﬁcation based on Multiple'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Association Rules'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CN2, 359, 363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'collaborative recommender systems, 610, 617, 618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'collective outlier detection, 548, 582'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categories of, 576'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual outlier detection versus, 575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on graph data, 576'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structure discovery, 575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'collective outliers, 575, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 575–576'\n",
            "Warning: Text found before any chapter, section, or subsection: 'co-location patterns, 319, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'colossal patterns, 302, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core descendants, 305, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core patterns, 304–305'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 303'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining challenge, 302–303'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pattern-Fusion mining, 302–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'combined signiﬁcance, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complete-linkage algorithm, 462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'completeness'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 84–85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining algorithm, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex data types, 166'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biological sequence data, 586, 590–591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph patterns, 591–592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 585–598, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networks, 591–592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in science applications, 612'\n",
            "Warning: Text found before any chapter, section, or subsection: '680'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex data types (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summary, 586'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symbolic sequence data, 586, 588–590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series data, 586, 587–588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'composite join indices, 162'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compressed patterns, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 307–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining by pattern clustering, 308–310'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compression, 100, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lossless, 100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lossy, 100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'theory, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computer science applications, 613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept characterization, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept comparison, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept description, 166, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept hierarchies, 142, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for generalizing data, 150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 143, 144'\n",
            "Warning: Text found before any chapter, section, or subsection: 'implicit, 143'\n",
            "Warning: Text found before any chapter, section, or subsection: 'manual provision, 144'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilevel association rule mining with, 285'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple, 144'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for nominal attributes, 284'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for specializing data, 150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept hierarchy generation, 112, 113, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'based on number of distinct values, 118'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 117–119'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for nominal data, 117–119'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with prespeciﬁed semantic connections, 119'\n",
            "Warning: Text found before any chapter, section, or subsection: 'schema, 119'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conditional probability table (CPT), 394, 395–396'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conﬁdence, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rule, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interval, 219–220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'limits, 373'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule, 245, 246'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conﬂict resolution strategy, 356'\n",
            "Warning: Text found before any chapter, section, or subsection: 'confusion matrix, 365–366, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 366'\n",
            "Warning: Text found before any chapter, section, or subsection: 'connectionist learning, 398'\n",
            "Warning: Text found before any chapter, section, or subsection: 'consecutive rules, 92'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Constrained Vector Quantization Error (CVQE)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm, 536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based clustering, 447, 497, 532–538, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categorization of constraints and, 533–535'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hard constraints, 535–536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 535–538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'soft constraints, 536–537'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speeding up, 537–538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based mining, 294–301, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interactive exploratory mining/analysis, 295'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as mining trend, 623'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based patterns/rules, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based sequential pattern mining, 589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-guided mining, 30'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraints'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonic, 298, 301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rule, 296–297'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cannot-link, 533'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on clusters, 533'\n",
            "Warning: Text found before any chapter, section, or subsection: 'coherence, 535'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conﬂicting, 535'\n",
            "Warning: Text found before any chapter, section, or subsection: 'convertible, 299–300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data-antimonotonic, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data-pruning, 300–301, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data-succinct, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimension/level, 294, 297'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hard, 534, 535–536, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inconvertible, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on instances, 533, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interestingness, 294, 297'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge type, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'monotonic, 298'\n",
            "Warning: Text found before any chapter, section, or subsection: 'must-link, 533, 536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-pruning, 297–300, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rules for, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on similarity measures, 533–534'\n",
            "Warning: Text found before any chapter, section, or subsection: 'soft, 534, 536–537, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'succinct, 298–299'\n",
            "Warning: Text found before any chapter, section, or subsection: 'content-based retrieval, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'context indicators, 314'\n",
            "Warning: Text found before any chapter, section, or subsection: 'context modeling, 316'\n",
            "Warning: Text found before any chapter, section, or subsection: 'context units, 314'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual attributes, 546, 573'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual outlier detection, 546–547, 582'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with identiﬁed context, 574'\n",
            "Warning: Text found before any chapter, section, or subsection: 'normal behavior modeling, 574–575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structures as contexts, 575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summary, 575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transformation to conventional outlier'\n",
            "Warning: Text found before any chapter, section, or subsection: 'detection, 573–574'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual outliers, 545–547, 573, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 546, 573'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 573–575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contingency tables, 95'\n",
            "Warning: Text found before any chapter, section, or subsection: 'continuous attributes, 44'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contrasting classes, 15, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'initial working relations, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prime relation, 175, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'convertible constraints, 299–300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '681'\n",
            "Warning: Text found before any chapter, section, or subsection: 'COP k-means algorithm, 536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core descendants, 305'\n",
            "Warning: Text found before any chapter, section, or subsection: 'colossal patterns, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'merging of core patterns, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core patterns, 304–305'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core ratio, 305'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation analysis, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discretization by, 117'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interestingness measures, 264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with lift, 266–267'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nominal data, 95–96'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric data, 96–97'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy and, 94–98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation coefﬁcient, 94, 96'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric data, 96–97'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation rules, 265, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation-based clustering methods, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlations, 18'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cosine measure, 268'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cosine similarity, 77'\n",
            "Warning: Text found before any chapter, section, or subsection: 'between two term-frequency vectors, 78'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cost complexity pruning algorithm, 345'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cotraining, 432–433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'covariance, 94, 97'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric data, 97–98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CPAR. See Classiﬁcation based on Predictive'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Association Rules'\n",
            "Warning: Text found before any chapter, section, or subsection: 'credit policy analysis, 608–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CRM. See customer relationship management'\n",
            "Warning: Text found before any chapter, section, or subsection: 'crossover operation, 426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cross-validation, 370–371, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-fold, 370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'leave-one-out, 371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in number of clusters determination, 487'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stratiﬁed, 371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube gradient analysis, 321'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube shells, 192, 211'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computing, 211'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube space'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discovery-driven exploration, 231–234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional data analysis in, 227–234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prediction mining in, 227'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspaces, 228–229'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cuboid trees, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cuboids, 137'\n",
            "Warning: Text found before any chapter, section, or subsection: 'apex, 111, 138, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'base, 111, 137–138, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'child, 193'\n",
            "Warning: Text found before any chapter, section, or subsection: 'individual, 190'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lattice of, 139, 156, 179, 188–189,'\n",
            "Warning: Text found before any chapter, section, or subsection: '234, 290'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparse, 190'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subset selection, 160'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data cubes'\n",
            "Warning: Text found before any chapter, section, or subsection: 'curse of dimensionality, 158, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'customer relationship management (CRM),'\n",
            "Warning: Text found before any chapter, section, or subsection: '619'\n",
            "Warning: Text found before any chapter, section, or subsection: 'customer retention analysis, 610'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CVQE. See Constrained Vector Quantization Error'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cyber-physical systems (CPS), 596, 623–624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'D'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonicity, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'archeology, 6'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biological sequence, 586, 590–591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complexity, 32'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conversion to knowledge, 2'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cyber-physical system, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for data mining, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data warehouse, 13–15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database, 9–10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrimination, 16'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dredging, 6'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalizing, 150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'growth, 2'\n",
            "Warning: Text found before any chapter, section, or subsection: 'linearly inseparable, 413–415'\n",
            "Warning: Text found before any chapter, section, or subsection: 'linearly separated, 409'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimedia, 14, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple sources, 15, 32'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multivariate, 556'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networked, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'overﬁtting, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sample, 219'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity and dissimilarity measures, 65–78'\n",
            "Warning: Text found before any chapter, section, or subsection: 'skewed, 47, 271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 14, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatiotemporal, 595–596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'specializing, 150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical descriptions, 44–56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'streams, 598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symbolic sequence, 586, 588–589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'temporal, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'text, 14, 596–597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series, 586, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: '“tombs,” 5'\n",
            "Warning: Text found before any chapter, section, or subsection: 'training, 18'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transactional, 13–14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 33'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web, 597–598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data auditing tools, 92'\n",
            "Warning: Text found before any chapter, section, or subsection: '682'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data characterization, 15, 166'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute-oriented induction, 167–172'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining query, 167–168'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 16'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 16'\n",
            "Warning: Text found before any chapter, section, or subsection: 'output, 16'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data classiﬁcation. See classiﬁcation'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cleaning, 6, 85, 88–93, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in back-end tools/utilities, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binning, 89–90'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrepancy detection, 91–93'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by information network analysis, 592–593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'missing values, 88–89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'noisy data, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier analysis, 90'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern mining for, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as process, 91–93'\n",
            "Warning: Text found before any chapter, section, or subsection: 'regression, 90'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data preprocessing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data constraints, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonic, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pruning data space with, 300–301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'succinct, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also constraints'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube aggregation, 110–111'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube computation, 156–160, 214–215'\n",
            "Warning: Text found before any chapter, section, or subsection: 'aggregation and, 193'\n",
            "Warning: Text found before any chapter, section, or subsection: 'average(), 215'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BUC, 200–204, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube operator, 157–159'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube shells, 211'\n",
            "Warning: Text found before any chapter, section, or subsection: 'full, 189–190, 195–199'\n",
            "Warning: Text found before any chapter, section, or subsection: 'general strategies for, 192–194'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg, 160, 193–194'\n",
            "Warning: Text found before any chapter, section, or subsection: 'memory allocation, 199'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 194–218, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiway array aggregation, 195–199'\n",
            "Warning: Text found before any chapter, section, or subsection: 'one-pass, 198'\n",
            "Warning: Text found before any chapter, section, or subsection: 'preliminary concepts, 188–194'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shell fragments, 210–218, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Star-Cubing, 204–210, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cubes, 10, 136, 178, 188'\n",
            "Warning: Text found before any chapter, section, or subsection: '3-D, 138'\n",
            "Warning: Text found before any chapter, section, or subsection: '4-D, 138, 139'\n",
            "Warning: Text found before any chapter, section, or subsection: 'apex cuboid, 111, 138, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'base cuboid, 111, 137–138, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed, 192'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube shell, 192'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cuboids, 137'\n",
            "Warning: Text found before any chapter, section, or subsection: 'curse of dimensionality, 158'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discovery-driven exploration, 231–234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 11–13'\n",
            "Warning: Text found before any chapter, section, or subsection: 'full, 189–190, 196–197'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gradient analysis, 321'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg, 160, 190–191, 201, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lattice of cuboids, 157, 234, 290'\n",
            "Warning: Text found before any chapter, section, or subsection: 'materialization, 159–160, 179, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measures, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional, 12, 136–139'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional data mining and, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multifeature, 227, 230–231, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimedia, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prediction, 227–230, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'qualitative association mining, 289–290'\n",
            "Warning: Text found before any chapter, section, or subsection: 'queries, 230'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query processing, 218–227'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ranking, 225–227, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sampling, 218–220, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shell, 160, 211'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shell fragments, 192, 210–218, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparse, 190'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'technology, 187–242'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data discretization. See discretization'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data dispersion, 44, 48–51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boxplots, 49–50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁve-number summary, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quartiles, 48–49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'standard deviation, 50–51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'variance, 50–51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data extraction, in back-end tools/utilities, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data focusing, 168'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data generalization, 179–180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by attribute-oriented induction, 166–178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data integration, 6, 85–86, 93–99, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation analysis, 94–98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'detection/resolution of data value conﬂicts,'\n",
            "Warning: Text found before any chapter, section, or subsection: '99'\n",
            "Warning: Text found before any chapter, section, or subsection: 'entity identiﬁcation problem, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by information network analysis, 592–593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'object matching, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy and, 94–98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'schema, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tuple duplication, 98–99'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data preprocessing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data marts, 132, 142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data warehouses versus, 142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dependent, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributed, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'implementation, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'independent, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data matrix, 67–68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dissimilarity matrix versus, 67–68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational table, 67–68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '683'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rows and columns, 68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as two-mode matrix, 68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data migration tools, 93'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining, 5–8, 33, 598, 623'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ad hoc, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 607–618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biological data, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex data types, 585–598, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cyber-physical system data, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data streams, 598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data types for, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data warehouses for, 154'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database types and, 32'\n",
            "Warning: Text found before any chapter, section, or subsection: 'descriptive, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributed, 615, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'efﬁciency, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'foundations, views on, 600–601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'functionalities, 15–23, 34'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graphs and networks, 591–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'incremental, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as information technology evolution, 2–5'\n",
            "Warning: Text found before any chapter, section, or subsection: 'integration, 623'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interactive, 30'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as interdisciplinary effort, 29–30'\n",
            "Warning: Text found before any chapter, section, or subsection: 'invisible, 33, 618–620, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'issues in, 29–33, 34'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in knowledge discovery, 7'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as knowledge search through data, 6'\n",
            "Warning: Text found before any chapter, section, or subsection: 'machine learning similarities, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methodologies, 29–30, 585–607'\n",
            "Warning: Text found before any chapter, section, or subsection: 'motivation for, 1–5'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional, 11–13, 26, 33–34, 155–156,'\n",
            "Warning: Text found before any chapter, section, or subsection: '179, 227–230'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimedia data, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP and, 154'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as pattern/knowledge discovery process, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictive, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'presentation/visualization of results, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'privacy-preserving, 32, 621–622, 624–625, 626'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query languages, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational databases, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalability, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequence data, 586'\n",
            "Warning: Text found before any chapter, section, or subsection: 'social impacts, 32'\n",
            "Warning: Text found before any chapter, section, or subsection: 'society and, 618–622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial data, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatiotemporal data and moving objects,'\n",
            "Warning: Text found before any chapter, section, or subsection: '595–596, 623–624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical, 598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'text data, 596–597, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trends, 622–625, 626'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ubiquitous, 618–620, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'user interaction and, 30–31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visual and audio, 602–607, 624, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Web data, 597–598, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining systems, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data models'\n",
            "Warning: Text found before any chapter, section, or subsection: 'entity-relationship (ER), 9, 139'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional, 135–146'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data objects, 40, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity, 40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'terminology for, 40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data preprocessing, 83–124'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cleaning, 88–93'\n",
            "Warning: Text found before any chapter, section, or subsection: 'forms illustration, 87'\n",
            "Warning: Text found before any chapter, section, or subsection: 'integration, 93–99'\n",
            "Warning: Text found before any chapter, section, or subsection: 'overview, 84–87'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quality, 84–85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reduction, 99–111'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in science applications, 612'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summary, 87'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tasks in, 85–87'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transformation, 111–119'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data quality, 84, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy, 84'\n",
            "Warning: Text found before any chapter, section, or subsection: 'believability, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'completeness, 84–85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'consistency, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretability, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'timeliness, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data reduction, 86, 99–111, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute subset selection, 103–105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compression, 100, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube aggregation, 110–111'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensionality, 86, 99–100, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'histograms, 106–108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numerosity, 86, 100, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parametric, 105–106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'principle components analysis, 102–103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sampling, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strategies, 99–100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'theory, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'wavelet transforms, 100–102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data preprocessing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data rich but information poor, 5'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data scrubbing tools, 92'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data security-enhancing techniques, 621'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data segmentation, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data selection, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data source view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data streams, 14, 598, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data transformation, 8, 87, 111–119, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'aggregation, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: '684'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data transformation (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute construction, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in back-end tools/utilities, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept hierarchy generation, 112, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discretization, 111, 112, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'normalization, 112, 113–115, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'smoothing, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strategies, 112–113'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data preprocessing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data types'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex, 166'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex, mining, 585–598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for data mining, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data validation, 592–593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data visualization, 56–65, 79, 602–603'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex data and relations, 64–65'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geometric projection techniques, 58–60'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hierarchical techniques, 63–64'\n",
            "Warning: Text found before any chapter, section, or subsection: 'icon-based techniques, 60–63'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining process, 603'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining result, 603, 605'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pixel-oriented techniques, 57–58'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in science applications, 613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summary, 65'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tag clouds, 64, 66'\n",
            "Warning: Text found before any chapter, section, or subsection: 'techniques, 39–40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data warehouses, 10–13, 26, 33, 125–185'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analytical processing, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'back-end tools/utilities, 134, 178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'basic concepts, 125–135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bottom-up design approach, 133, 151–152'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business analysis framework for, 150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business query view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'combined design approach, 152'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mart, 132, 142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining, 154'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data source view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'design process, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'development approach, 133'\n",
            "Warning: Text found before any chapter, section, or subsection: 'development tools, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'enterprise, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extractors, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fact constellation, 141–142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for ﬁnancial data, 608'\n",
            "Warning: Text found before any chapter, section, or subsection: 'framework illustration, 11'\n",
            "Warning: Text found before any chapter, section, or subsection: 'front-end client layer, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gateways, 131'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geographic, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'implementation, 156–165'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information processing, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'integrated, 126'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metadata, 134–135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'modeling, 10, 135–150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'models, 132–134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multitier, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multitiered architecture, 130–132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonvolatile, 127'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP server, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'operational database systems versus, 128–129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'planning and analysis tools, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'retail industry, 609–610'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in science applications, 612'\n",
            "Warning: Text found before any chapter, section, or subsection: 'snowﬂake schema, 140–141'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star schema, 139–140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subject-oriented, 126'\n",
            "Warning: Text found before any chapter, section, or subsection: 'three-tier architecture, 131, 178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-variant, 127'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tools, 11'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down design approach, 133, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'update-driven approach, 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'usage for information processing, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'virtual, 133'\n",
            "Warning: Text found before any chapter, section, or subsection: 'warehouse database server, 131'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database management systems (DBMSs), 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database queries. See queries'\n",
            "Warning: Text found before any chapter, section, or subsection: 'databases, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inductive, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational. See relational databases'\n",
            "Warning: Text found before any chapter, section, or subsection: 'research, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical, 148–149'\n",
            "Warning: Text found before any chapter, section, or subsection: 'technology evolution, 3'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transactional, 13–15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 32'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web-based, 4'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data/pattern analysis. See data mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DBSCAN, 471–473'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 474'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core objects, 472'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density estimation, 477'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based cluster, 472'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-connected, 472, 473'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-reachable, 472, 473'\n",
            "Warning: Text found before any chapter, section, or subsection: 'directly density-reachable, 472'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neighborhood density, 471'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis; density-based methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DDPMine, 422'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decimal scaling, normalization by, 115'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree analysis, discretization by, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree induction, 330–350, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm differences, 336'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '685'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute selection measures, 336–344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute subset selection, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C4.5, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CART, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CHAID, 343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gain ratio, 340–341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Gini index, 332, 341–343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ID3, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'incremental versions, 336'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information gain, 336–340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multivariate splits, 344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parameters, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalability and, 347–348'\n",
            "Warning: Text found before any chapter, section, or subsection: 'splitting criterion, 333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'from training tuples, 332–333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tree pruning, 344–347, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visual mining for, 348–350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision trees, 18, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'branches, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 331'\n",
            "Warning: Text found before any chapter, section, or subsection: 'internal nodes, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'leaf nodes, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pruning, 331, 344–347'\n",
            "Warning: Text found before any chapter, section, or subsection: 'root node, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule extraction from, 357–359'\n",
            "Warning: Text found before any chapter, section, or subsection: 'deep web, 597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'default rules, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DENCLUE, 476–479'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advantages, 479'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clusters, 478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density attractor, 478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density estimation, 476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'kernel density estimation, 477–478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'kernels, 478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis; density-based methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dendrograms, 460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'densiﬁcation power law, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density estimation, 476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DENCLUE, 477–478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'kernel function, 477–478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based methods, 449, 471–479, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DBSCAN, 471–473'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DENCLUE, 476–479'\n",
            "Warning: Text found before any chapter, section, or subsection: 'object division, 449'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OPTICS, 473–476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'STING as, 480'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based outlier detection, 564–567'\n",
            "Warning: Text found before any chapter, section, or subsection: 'local outlier factor, 566–567'\n",
            "Warning: Text found before any chapter, section, or subsection: 'local proximity, 564'\n",
            "Warning: Text found before any chapter, section, or subsection: 'local reachability density, 566'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relative density, 565'\n",
            "Warning: Text found before any chapter, section, or subsection: 'descendant cells, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'descriptive mining tasks, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DIANA (Divisive Analysis), 459, 460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dice operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'differential privacy, 622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimension tables, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensional cells, 189'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensionality reduction, 86, 99–100, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensionality reduction methods, 510,'\n",
            "Warning: Text found before any chapter, section, or subsection: '519–522, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'list of, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spectral clustering, 520–522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimension/level'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application of, 297'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraints, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 10, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rule, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cardinality of, 159'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept hierarchies and, 142–144'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multidimensional view, 33'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordering of, 210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ranking, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relevance analysis, 175'\n",
            "Warning: Text found before any chapter, section, or subsection: 'selection, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shared, 204'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data warehouses'\n",
            "Warning: Text found before any chapter, section, or subsection: 'direct discriminative pattern mining, 422'\n",
            "Warning: Text found before any chapter, section, or subsection: 'directed acyclic graphs, 394–395'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discernibility matrix, 427'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discovery-driven exploration, 231–234, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrepancy detection, 91–93'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrete attributes, 44'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrete Fourier transform (DFT), 101, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrete wavelet transform (DWT), 100–102,'\n",
            "Warning: Text found before any chapter, section, or subsection: '587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discretization, 112, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by binning, 115'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by clustering, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by correlation analysis, 117'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by decision tree analysis, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by histogram analysis, 115–116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'techniques, 113'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminant analysis, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminant rules, 16'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminative frequent pattern-based classiﬁcation,'\n",
            "Warning: Text found before any chapter, section, or subsection: '416, 419–422, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'basis for, 419'\n",
            "Warning: Text found before any chapter, section, or subsection: 'feature generation, 420'\n",
            "Warning: Text found before any chapter, section, or subsection: 'feature selection, 420–421'\n",
            "Warning: Text found before any chapter, section, or subsection: 'framework, 420–421'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning of classiﬁcation model, 421'\n",
            "Warning: Text found before any chapter, section, or subsection: '686'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dispersion of data, 44, 48–51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dissimilarity'\n",
            "Warning: Text found before any chapter, section, or subsection: 'asymmetric binary, 71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'between attributes of mixed type, 76–77'\n",
            "Warning: Text found before any chapter, section, or subsection: 'between binary attributes, 71–72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measuring, 65–78, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'between nominal attributes, 69'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on numeric data, 72–74'\n",
            "Warning: Text found before any chapter, section, or subsection: 'between ordinal attributes, 75'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symmetric binary, 70–71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dissimilarity matrix, 67, 68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data matrix versus, 67–68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'n-by-n table representation, 68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as one-mode matrix, 68'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance measures, 461–462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Euclidean, 72–73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Manhattan, 72–73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Minkowski, 73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supremum, 73–74'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based cluster analysis, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based outlier detection, 561–562'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nested loop algorithm, 561, 562'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also outlier detection'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributed data mining, 615, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributed privacy preservation, 622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributions'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boxplots for visualizing, 49–50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁve-number summary, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributive measures, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Divisive Analysis (DIANA), 459, 460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'divisive hierarchical method, 459'\n",
            "Warning: Text found before any chapter, section, or subsection: 'agglomerative hierarchical clustering versus,'\n",
            "Warning: Text found before any chapter, section, or subsection: '459–460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DIANA, 459, 460'\n",
            "Warning: Text found before any chapter, section, or subsection: 'DNA chips, 512'\n",
            "Warning: Text found before any chapter, section, or subsection: 'document classiﬁcation, 430'\n",
            "Warning: Text found before any chapter, section, or subsection: 'documents'\n",
            "Warning: Text found before any chapter, section, or subsection: 'language model, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'topic model, 26–27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drill-across operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drill-down operation, 11, 146–147'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drill-through operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dynamic itemset counting, 256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'E'\n",
            "Warning: Text found before any chapter, section, or subsection: 'eager learners, 423, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Eclat (Equivalence Class Transformation) algorithm,'\n",
            "Warning: Text found before any chapter, section, or subsection: '260, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'e-commerce, 609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'editing method, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'efﬁciency'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apriori algorithm, 255–256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'backpropagation, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining algorithms, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'elbow method, 486'\n",
            "Warning: Text found before any chapter, section, or subsection: 'email spam ﬁltering, 435'\n",
            "Warning: Text found before any chapter, section, or subsection: 'engineering applications, 613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ensemble methods, 378–379, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bagging, 379–380'\n",
            "Warning: Text found before any chapter, section, or subsection: 'boosting, 380–382'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for class imbalance problem, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random forests, 382–383'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 378, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'enterprise warehouses, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'entity identiﬁcation problem, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'entity-relationship (ER) data model, 9, 139'\n",
            "Warning: Text found before any chapter, section, or subsection: 'epoch updating, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equal-frequency histograms, 107, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equal-width histograms, 107, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equivalence classes, 427'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error rates, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error-correcting codes, 431–432'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Euclidean distance, 72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mathematical properties, 72–73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weighted, 74'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also distance measures'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evaluation metrics, 364–370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evolution, of database system technology, 3–5'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evolutionary searches, 579'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exception-based, discovery-driven exploration,'\n",
            "Warning: Text found before any chapter, section, or subsection: '231–234, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exceptions, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exhaustive rules, 358'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expectation-maximization (EM) algorithm,'\n",
            "Warning: Text found before any chapter, section, or subsection: '505–508, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expectation step (E-step), 505'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy clustering with, 505–507'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximization step (M-step), 505'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for mixture models, 507–508'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for probabilistic model-based clustering,'\n",
            "Warning: Text found before any chapter, section, or subsection: '507–508'\n",
            "Warning: Text found before any chapter, section, or subsection: 'steps, 505'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also probabilistic model-based clustering'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expected values, 97'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cell, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exploratory data mining. See multidimensional data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extraction'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule, from decision tree, 357–359'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extraction/transformation/loading (ETL) tools, 93'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extractors, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '687'\n",
            "Warning: Text found before any chapter, section, or subsection: 'F'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fact constellation, 141'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 141–142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fact tables, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summary, 165'\n",
            "Warning: Text found before any chapter, section, or subsection: 'factor analysis, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'facts, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'false negatives, 365'\n",
            "Warning: Text found before any chapter, section, or subsection: 'false positives, 365'\n",
            "Warning: Text found before any chapter, section, or subsection: 'farthest-neighbor clustering algorithm, 462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁeld overloading, 92'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁnancial data analysis, 607–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'credit policy analysis, 608–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'crimes detection, 609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data warehouses, 608'\n",
            "Warning: Text found before any chapter, section, or subsection: 'loan payment prediction, 608–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'targeted marketing, 609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'FindCBLOF algorithm, 569–570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁve-number summary, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁxed-width clustering, 570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'FOIL, 359, 363, 418'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Forest-RC, 383'\n",
            "Warning: Text found before any chapter, section, or subsection: 'forward algorithm, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'FP-growth, 257–259, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 260'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 257–258'\n",
            "Warning: Text found before any chapter, section, or subsection: 'performance, 259'\n",
            "Warning: Text found before any chapter, section, or subsection: 'FP-trees, 257'\n",
            "Warning: Text found before any chapter, section, or subsection: 'condition pattern base, 258'\n",
            "Warning: Text found before any chapter, section, or subsection: 'construction, 257–258'\n",
            "Warning: Text found before any chapter, section, or subsection: 'main memory-based, 259'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 258, 259'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Frag-Shells, 212, 213'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fraudulent analysis, 610–611'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequency patterns'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approximate, 281, 307–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compressed, 281, 307–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'near-match, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy-aware top-k, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent itemset mining, 18, 272, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Apriori algorithm, 248–253'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed patterns, 262–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'market basket analysis, 244–246'\n",
            "Warning: Text found before any chapter, section, or subsection: 'max patterns, 262–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 248–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-growth approach, 257–259'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with vertical data format, 259–262, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent itemsets, 243, 246, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rule generation from, 253, 254'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed, 247, 248, 262–264, 308'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁnding, 247'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁnding by conﬁned candidate generation,'\n",
            "Warning: Text found before any chapter, section, or subsection: '248–253'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximal, 247, 248, 262–264, 308'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subsets, 309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent pattern mining, 279'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advanced forms of patterns, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application domain-speciﬁc semantics, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 317–319, 321'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approximate patterns, 307–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation criteria, 280–283'\n",
            "Warning: Text found before any chapter, section, or subsection: 'colossal patterns, 301–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compressed patterns, 307–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based, 294–301, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data analysis usages, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for data cleaning, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'direct discriminative, 422'\n",
            "Warning: Text found before any chapter, section, or subsection: 'high-dimensional data, 301–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in high-dimensional space, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in image data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for indexing structures, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'kinds of data and features, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional associations, 287–289'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multilevel, multidimensional space, 283–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilevel associations, 283–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multimedia data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative patterns, 291–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for noise ﬁltering, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pattern-Fusion, 302–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantitative association rules, 289–291'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rare patterns, 291–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in recommender systems, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'road map, 279–283'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalable computation and, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scope of, 319–320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in sequence or structural data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in spatiotemporal data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for structure and cluster discovery, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for subspace clustering, 318–319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in time-series data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k, 310'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in video data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also frequent patterns'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent pattern-based classiﬁcation, 415–422, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'associative, 415, 416–419'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminative, 416, 419–422'\n",
            "Warning: Text found before any chapter, section, or subsection: 'framework, 422'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent patterns, 17, 243'\n",
            "Warning: Text found before any chapter, section, or subsection: 'abstraction levels, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rule mapping, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'basic, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: '688'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent patterns (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closed, 262–264, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concepts, 243–244'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'diversity, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exploration, 313–319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'growth, 257–259, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'max, 262–264, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 243–244, 279–325'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining constraints or criteria, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'number of dimensions involved in, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semantic annotation of, 313–317'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequential, 243'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strong associations, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structured, 243'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trees, 257–259'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of values in, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent subgraphs, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'front-end client layer, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'full materialization, 159, 179, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy clustering, 499–501, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data set for, 506'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with EM algorithm, 505–507'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 500'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expectation step (E-step), 505'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬂexibility, 501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximization step (M-step), 506–507'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partition matrix, 499'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as soft clusters, 501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy logic, 428'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy sets, 428–429, 437, 499'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evaluation, 500–501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 499'\n",
            "Warning: Text found before any chapter, section, or subsection: 'G'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gain ratio, 340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'C4.5 use of, 340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'formula, 341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximum, 341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gateways, 131'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gene expression, 513–514'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalization'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute, 169–170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute, control, 170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute, threshold control, 170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multimedia data mining, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'process, 172'\n",
            "Warning: Text found before any chapter, section, or subsection: 'results presentation, 174'\n",
            "Warning: Text found before any chapter, section, or subsection: 'synchronous, 175'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalized linear models, 599–600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalized relations'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute-oriented induction, 172'\n",
            "Warning: Text found before any chapter, section, or subsection: 'presentation of, 174'\n",
            "Warning: Text found before any chapter, section, or subsection: 'threshold control, 170'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generative model, 467–469'\n",
            "Warning: Text found before any chapter, section, or subsection: 'genetic algorithms, 426–427, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'genomes, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geodesic distance, 525–526, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'diameter, 525'\n",
            "Warning: Text found before any chapter, section, or subsection: 'eccentricity, 525'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measurements based on, 526'\n",
            "Warning: Text found before any chapter, section, or subsection: 'peripheral vertex, 525'\n",
            "Warning: Text found before any chapter, section, or subsection: 'radius, 525'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geographic data warehouses, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geometric projection visualization, 58–60'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Gini index, 341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binary enforcement, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binary indexes, 341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CART use of, 341'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree induction using,'\n",
            "Warning: Text found before any chapter, section, or subsection: '342–343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimum, 342'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning and, 342'\n",
            "Warning: Text found before any chapter, section, or subsection: 'global constants, for missing values, 88'\n",
            "Warning: Text found before any chapter, section, or subsection: 'global outliers, 545, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'detection, 545'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 545'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Google'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Flu Trends, 2'\n",
            "Warning: Text found before any chapter, section, or subsection: 'popularity of, 619–620'\n",
            "Warning: Text found before any chapter, section, or subsection: 'gradient descent strategy, 396–397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithms, 397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy hill-climbing, 397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as iterative, 396–397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph and network data clustering, 497,'\n",
            "Warning: Text found before any chapter, section, or subsection: '522–532, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 523–525'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bipartite graph, 523'\n",
            "Warning: Text found before any chapter, section, or subsection: 'challenges, 523–525, 530'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cuts and clusters, 529–530'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generic method, 530–531'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geodesic distance, 525–526'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 528–532'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity measures, 525–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SimRank, 526–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'social network, 524–525'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web search engines, 523–524'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph cuts, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph data, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph index structures, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graph pattern mining, 591–592, 612–613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graphic displays'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data presentation software, 44–45'\n",
            "Warning: Text found before any chapter, section, or subsection: 'histogram, 54, 55'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '689'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantile plot, 51–52'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantile-quantile plot, 52–54'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scatter plot, 54–56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy hill-climbing, 397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy methods, attribute subset selection,'\n",
            "Warning: Text found before any chapter, section, or subsection: '104–105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grid-based methods, 450, 479–483, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CLIQUE, 481–483'\n",
            "Warning: Text found before any chapter, section, or subsection: 'STING, 479–481'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grid-based outlier detection, 562–564'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CELL method, 562, 563'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cell properties, 562'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cell pruning rules, 563'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also outlier detection'\n",
            "Warning: Text found before any chapter, section, or subsection: 'group-based support, 286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'group-by clause, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grouping attributes, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grouping variables, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Grubb’s test, 555'\n",
            "Warning: Text found before any chapter, section, or subsection: 'H'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hamming distance, 431'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hard constraints, 534, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 534'\n",
            "Warning: Text found before any chapter, section, or subsection: 'handling, 535–536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'harmonic mean, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hash-based technique, 255'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous networks, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation of, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering of, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ranking of, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous transfer learning, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hidden Markov model (HMM), 590, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hierarchical methods, 449, 457–470, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'agglomerative, 459–461'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithmic, 459, 461–462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian, 459'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BIRCH, 458, 462–466'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chameleon, 458, 466–467'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complete linkages, 462, 463'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance measures, 461–462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'divisive, 459–461'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drawbacks, 449'\n",
            "Warning: Text found before any chapter, section, or subsection: 'merge or split points and, 458'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic, 459, 467–470'\n",
            "Warning: Text found before any chapter, section, or subsection: 'single linkages, 462, 463'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hierarchical visualization, 63'\n",
            "Warning: Text found before any chapter, section, or subsection: 'treemaps, 63, 65'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Worlds-with-Worlds, 63, 64'\n",
            "Warning: Text found before any chapter, section, or subsection: 'high-dimensional data, 301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering, 447'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data distribution of, 560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent pattern mining, 301–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier detection in, 576–580, 582'\n",
            "Warning: Text found before any chapter, section, or subsection: 'row enumeration, 302'\n",
            "Warning: Text found before any chapter, section, or subsection: 'high-dimensional data clustering, 497, 508–522,'\n",
            "Warning: Text found before any chapter, section, or subsection: '538, 553'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biclustering, 512–519'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensionality reduction methods, 510,'\n",
            "Warning: Text found before any chapter, section, or subsection: '519–522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 508–509'\n",
            "Warning: Text found before any chapter, section, or subsection: 'problems, challenges, and methodologies,'\n",
            "Warning: Text found before any chapter, section, or subsection: '508–510'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace clustering methods, 509,'\n",
            "Warning: Text found before any chapter, section, or subsection: '510–511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'HilOut algorithm, 577–578'\n",
            "Warning: Text found before any chapter, section, or subsection: 'histograms, 54, 106–108, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analysis by discretization, 115–116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attributes, 106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'binning, 106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'construction, 559'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equal-frequency, 107'\n",
            "Warning: Text found before any chapter, section, or subsection: 'equal-width, 107'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 54'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 55, 107'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as nonparametric model, 559'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier detection using, 558–560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'holdout method, 370, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'holistic measures, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'homogeneous networks, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation of, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering of, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Hopkins statistic, 484–485'\n",
            "Warning: Text found before any chapter, section, or subsection: 'horizontal data format, 259'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hybrid OLAP (HOLAP), 164–165, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hybrid-dimensional association rules,'\n",
            "Warning: Text found before any chapter, section, or subsection: '288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'I'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IBM Intelligent Miner, 603, 606'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg condition, 191'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg cubes, 160, 179, 190, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'BUC construction, 201'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation, 160, 193–194, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation and storage, 210–211'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation with Star-Cubing algorithm,'\n",
            "Warning: Text found before any chapter, section, or subsection: '204–210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'materialization, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speciﬁcation of, 190–191'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data cubes'\n",
            "Warning: Text found before any chapter, section, or subsection: 'icon-based visualization, 60'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Chernoff faces, 60–61'\n",
            "Warning: Text found before any chapter, section, or subsection: '690'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'icon-based visualization (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stick ﬁgure technique, 61–63'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also data visualization'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ID3, 332, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy approach, 332'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information gain, 336'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also decision tree induction'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IF-THEN rules, 355–357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy, 356'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conﬂict resolution strategy, 356'\n",
            "Warning: Text found before any chapter, section, or subsection: 'coverage, 356'\n",
            "Warning: Text found before any chapter, section, or subsection: 'default rule, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extracting from decision tree, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'form, 355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule antecedent, 355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule consequent, 355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule ordering, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'satisﬁed, 356'\n",
            "Warning: Text found before any chapter, section, or subsection: 'triggered, 356'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 149'\n",
            "Warning: Text found before any chapter, section, or subsection: 'image data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'imbalance problem, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'imbalance ratio (IR), 270'\n",
            "Warning: Text found before any chapter, section, or subsection: 'skewness, 271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inconvertible constraints, 300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'incremental data mining, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'indexes'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bitmapped join, 163'\n",
            "Warning: Text found before any chapter, section, or subsection: 'composite join, 162'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Gini, 332, 341–343'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inverted, 212, 213'\n",
            "Warning: Text found before any chapter, section, or subsection: 'indexing'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bitmap, 160–161, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bitmapped join, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent pattern mining for, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'join, 161–163, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP, 160–163'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inductive databases, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inferential statistics, 24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information age, moving toward, 1–2'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information extraction systems, 430'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information gain, 336–340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree induction using, 338–339'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ID3 use of, 336'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern frequency support versus, 421'\n",
            "Warning: Text found before any chapter, section, or subsection: 'single feature plot, 420'\n",
            "Warning: Text found before any chapter, section, or subsection: 'split-point, 340'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information networks'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analysis, 592–593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evolution of, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'link prediction in, 593–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 623'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP in, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'role discovery in, 593–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity search in, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information processing, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information retrieval (IR), 26–27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'challenges, 27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'language model, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'topic model, 26–27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'informativeness model, 535'\n",
            "Warning: Text found before any chapter, section, or subsection: 'initial working relations, 168, 169, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'instance-based learners. See lazy learners'\n",
            "Warning: Text found before any chapter, section, or subsection: 'instances, constraints on, 533, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'integrated data warehouses, 126'\n",
            "Warning: Text found before any chapter, section, or subsection: 'integrators, 127'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intelligent query answering, 618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interactive data mining, 604, 607'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interactive mining, 30'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intercuboid query expansion, 221'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 224–225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'method, 223–224'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interdimensional association rules, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interestingness, 21–23'\n",
            "Warning: Text found before any chapter, section, or subsection: 'assessment methods, 23'\n",
            "Warning: Text found before any chapter, section, or subsection: 'components of, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expected, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'objective measures, 21–22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strong association rules, 264–265'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subjective measures, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'threshold, 21–22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unexpected, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interestingness constraints, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application of, 297'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretability'\n",
            "Warning: Text found before any chapter, section, or subsection: 'backpropagation and, 406–408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster analysis, 447'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data quality and, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic hierarchical clustering,'\n",
            "Warning: Text found before any chapter, section, or subsection: '469'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interquartile range (IQR), 49, 555'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interval-scaled attributes, 43, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intracuboid query expansion, 221'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 223'\n",
            "Warning: Text found before any chapter, section, or subsection: 'method, 221–223'\n",
            "Warning: Text found before any chapter, section, or subsection: 'value usage, 222'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intradimensional association rules, 287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intrusion detection, 569–570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'anomaly-based, 614'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining algorithms, 614–615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminative classiﬁers, 615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributed data mining, 615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '691'\n",
            "Warning: Text found before any chapter, section, or subsection: 'signature-based, 614'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stream data analysis, 615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visualization and query tools, 615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inverted indexes, 212, 213'\n",
            "Warning: Text found before any chapter, section, or subsection: 'invisible data mining, 33, 618–620, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IQR. See Interquartile range'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IR. See information retrieval'\n",
            "Warning: Text found before any chapter, section, or subsection: 'item merging, 263'\n",
            "Warning: Text found before any chapter, section, or subsection: 'item skipping, 263'\n",
            "Warning: Text found before any chapter, section, or subsection: 'items, 13'\n",
            "Warning: Text found before any chapter, section, or subsection: 'itemsets, 246'\n",
            "Warning: Text found before any chapter, section, or subsection: 'candidate, 251, 252'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dependent, 266'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dynamic counting, 256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'imbalance ratio (IR), 270, 271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negatively correlated, 292'\n",
            "Warning: Text found before any chapter, section, or subsection: 'occurrence independence, 266'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strongly negatively correlated, 292'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also frequent itemsets'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iterative Pattern-Fusion, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iterative relocation techniques, 448'\n",
            "Warning: Text found before any chapter, section, or subsection: 'J'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Jaccard coefﬁcient, 71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'join indexing, 161–163, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'K'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-anonymity method, 621–622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Karush-Kuhn-Tucker (KKT) conditions, 412'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-distance neighborhoods, 565'\n",
            "Warning: Text found before any chapter, section, or subsection: 'kernel density estimation, 477–478'\n",
            "Warning: Text found before any chapter, section, or subsection: 'kernel function, 415'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-fold cross-validation, 370–371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-means, 451–454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm, 452'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application of, 454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CLARANS, 457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'within-cluster variation, 451, 452'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering by, 453'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drawback of, 454–455'\n",
            "Warning: Text found before any chapter, section, or subsection: 'functioning of, 452'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalability, 454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time complexity, 453'\n",
            "Warning: Text found before any chapter, section, or subsection: 'variants, 453–454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-means clustering, 536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-medoids, 454–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'absolute-error criterion, 455'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cost function for, 456'\n",
            "Warning: Text found before any chapter, section, or subsection: 'PAM, 455–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-nearest-neighbor classiﬁcation, 423'\n",
            "Warning: Text found before any chapter, section, or subsection: 'closeness, 423'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based comparisons, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'editing method, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'missing values and, 424'\n",
            "Warning: Text found before any chapter, section, or subsection: 'number of neighbors, 424–425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partial distance method, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speed, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge'\n",
            "Warning: Text found before any chapter, section, or subsection: 'background, 30–31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 29'\n",
            "Warning: Text found before any chapter, section, or subsection: 'presentation, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'representation, 33'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transfer, 434'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge bases, 5, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge discovery'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining in, 7'\n",
            "Warning: Text found before any chapter, section, or subsection: 'process, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge discovery from data (KDD), 6'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge extraction. See data mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge mining. See data mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'knowledge type constraints, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-predicate sets, 289'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Kulczynski measure, 268, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negatively correlated pattern based on, 293–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'L'\n",
            "Warning: Text found before any chapter, section, or subsection: 'language model, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Laplacian correction, 355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lattice of cuboids, 139, 156, 179, 188–189, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lazy learners, 393, 422–426, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'case-based reasoning classiﬁers, 425–426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-nearest-neighbor classiﬁers, 423–425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'l-diversity method, 622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning'\n",
            "Warning: Text found before any chapter, section, or subsection: 'active, 430, 433–434, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'backpropagation, 400'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as classiﬁcation step, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'connectionist, 398'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by examples, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by observation, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rate, 397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised, 572'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supervised, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transfer, 430, 434–436, 438'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unsupervised, 330, 445, 490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning rates, 403–404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'leave-one-out, 371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lift, 266, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation analysis with, 266–267'\n",
            "Warning: Text found before any chapter, section, or subsection: 'likelihood ratio statistic, 363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'linear regression, 90, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple, 106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'linearly, 412–413'\n",
            "Warning: Text found before any chapter, section, or subsection: 'linearly inseparable data, 413–415'\n",
            "Warning: Text found before any chapter, section, or subsection: '692'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'link mining, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'link prediction, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'load, in back-end tools/utilities, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'loan payment prediction, 608–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'local outlier factor, 566–567'\n",
            "Warning: Text found before any chapter, section, or subsection: 'local proximity-based outliers, 564–565'\n",
            "Warning: Text found before any chapter, section, or subsection: 'logistic function, 402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'log-linear models, 106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lossless compression, 100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lossy compression, 100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'lower approximation, 427'\n",
            "Warning: Text found before any chapter, section, or subsection: 'M'\n",
            "Warning: Text found before any chapter, section, or subsection: 'machine learning, 24–26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'active, 25'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining similarities, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised, 25'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supervised, 24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unsupervised, 25'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Mahalanobis distance, 556'\n",
            "Warning: Text found before any chapter, section, or subsection: 'majority voting, 335'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Manhattan distance, 72–73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MaPle, 519'\n",
            "Warning: Text found before any chapter, section, or subsection: 'margin, 410'\n",
            "Warning: Text found before any chapter, section, or subsection: 'market basket analysis, 244–246, 271–272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 244'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 244'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Markov chains, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'materialization'\n",
            "Warning: Text found before any chapter, section, or subsection: 'full, 159, 179, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iceberg cubes, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'no, 159'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partial, 159–160, 192, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-ofﬂine, 226'\n",
            "Warning: Text found before any chapter, section, or subsection: 'max patterns, 280'\n",
            "Warning: Text found before any chapter, section, or subsection: 'max conﬁdence measure, 268, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximal frequent itemsets, 247, 308'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 248'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 262–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shortcomings for compression, 308–309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximum marginal hyperplane (MMH), 409'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SVM ﬁnding, 412'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximum normed residual test, 555'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mean, 39, 45'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bin, smoothing by, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 45'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for missing values, 88'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trimmed, 46'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weighted arithmetic, 45'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measures, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'accuracy-based, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algebraic, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'all conﬁdence, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'antimonotonic, 194'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attribute selection, 331'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categories of, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of central tendency, 39, 44, 45–47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation, 266'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dispersion, 48–51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance, 72–74, 461–462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributive, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'holistic, 145'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Kulczynski, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'max conﬁdence, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of multidimensional databases, 146'\n",
            "Warning: Text found before any chapter, section, or subsection: 'null-invariant, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern evaluation, 267–271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'precision, 368–369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity, 67, 68–72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recall, 368–369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sensitivity, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'signiﬁcance, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity/dissimilarity, 65–78'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speciﬁcity, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'median, 39, 46'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bin, smoothing by, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 46'\n",
            "Warning: Text found before any chapter, section, or subsection: 'formula, 46–47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for missing values, 88'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metadata, 92, 134, 178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'business, 135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'importance, 135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'operational, 135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'repositories, 134–135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metarule-guided mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of association rules, 295–296'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 295–296'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metrics, 73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation evaluation, 364–370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'microeconomic view, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'midrange, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MineSet, 603, 605'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimal interval size, 116'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimal spanning tree algorithm, 462'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimum conﬁdence threshold, 18, 245'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Minimum Description Length (MDL), 343–344'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimum support threshold, 18, 190'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rules, 245'\n",
            "Warning: Text found before any chapter, section, or subsection: 'count, 246'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Minkowski distance, 73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'min-max normalization, 114'\n",
            "Warning: Text found before any chapter, section, or subsection: 'missing values, 88–89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mixed-effect models, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '693'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mixture models, 503, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'EM algorithm for, 507–508'\n",
            "Warning: Text found before any chapter, section, or subsection: 'univariate Gaussian, 504'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mode, 39, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'model selection, 364'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with statistical tests of signiﬁcance, 372–373'\n",
            "Warning: Text found before any chapter, section, or subsection: 'models, 18'\n",
            "Warning: Text found before any chapter, section, or subsection: 'modularity'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of clustering, 530'\n",
            "Warning: Text found before any chapter, section, or subsection: 'use of, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'MOLAP. See multidimensional OLAP'\n",
            "Warning: Text found before any chapter, section, or subsection: 'monotonic constraints, 298'\n",
            "Warning: Text found before any chapter, section, or subsection: 'motifs, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'moving-object data mining, 595–596, 623–624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiclass classiﬁcation, 430–432, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'all-versus-all (AVA), 430–431'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error-correcting codes, 431–432'\n",
            "Warning: Text found before any chapter, section, or subsection: 'one-versus-all (OVA), 430'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional association rules, 17, 283,'\n",
            "Warning: Text found before any chapter, section, or subsection: '288, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hybrid-dimensional, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interdimensional, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 287–289'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining with static discretization of quantitative'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attributes, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with no repeated predicates, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also association rules'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional data analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in cube space, 227–234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multimedia data mining, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of top-k results, 226'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional data mining, 11–13, 34 155–156,'\n",
            "Warning: Text found before any chapter, section, or subsection: '179, 187, 227, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube promotion of, 26'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 33'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 228–229'\n",
            "Warning: Text found before any chapter, section, or subsection: 'retail industry, 610'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional data model, 135–146, 178'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube as, 136–139'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimension table, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 142–144'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fact constellation, 141–142'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fact table, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'snowﬂake schema, 140–141'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star schema, 139–140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional databases'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measures of, 146'\n",
            "Warning: Text found before any chapter, section, or subsection: 'querying with starnet model, 149–150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional histograms, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional OLAP (MOLAP), 132, 164, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multifeature cubes, 227, 230, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'complex query support, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'examples, 230–231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilayer feed-forward neural networks,'\n",
            "Warning: Text found before any chapter, section, or subsection: '398–399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 405'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'layers, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'units, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilevel association rules, 281, 283, 284, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ancestors, 287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept hierarchies, 285'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'group-based support, 286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 283–287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reduced support, 285, 286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy, checking, 287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'uniform support, 285–286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimedia data, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimedia data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimedia data mining, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multimodal, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple linear regression, 90, 106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple sequence alignment, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiple-phase clustering, 458–459'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multitier data warehouses, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multivariate outlier detection, 556'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with Mahalanobis distance, 556'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with multiple clusters, 557'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with multiple parametric distributions, 557'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with χ2-static, 556'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiway array aggregation, 195, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for full cube computation, 195–199'\n",
            "Warning: Text found before any chapter, section, or subsection: 'minimum memory requirements, 198'\n",
            "Warning: Text found before any chapter, section, or subsection: 'must-link constraints, 533, 536'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mutation operator, 426'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mutual information, 315–316'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mutually exclusive rules, 358'\n",
            "Warning: Text found before any chapter, section, or subsection: 'N'\n",
            "Warning: Text found before any chapter, section, or subsection: 'naive Bayesian classiﬁcation, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class label prediction with, 353–355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'functioning of, 351–352'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nearest-neighbor clustering algorithm, 461'\n",
            "Warning: Text found before any chapter, section, or subsection: 'near-match patterns/rules, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative correlation, 55, 56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative patterns, 280, 283, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 291–292'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 291–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative transfer, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative tuples, 364'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negatively skewed data, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: '694'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neighborhoods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density, 471'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based outlier detection, 560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-distance, 565'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nested loop algorithm, 561, 562'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networked data, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'networks, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous, 592, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'homogeneous, 592, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'information, 592–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining in science applications, 612–613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'social, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical modeling of, 592–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neural networks, 19, 398'\n",
            "Warning: Text found before any chapter, section, or subsection: 'backpropagation, 398–408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as black boxes, 406'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for classiﬁcation, 19, 398'\n",
            "Warning: Text found before any chapter, section, or subsection: 'disadvantages, 406'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fully connected, 399, 406–407'\n",
            "Warning: Text found before any chapter, section, or subsection: 'learning, 398'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multilayer feed-forward, 398–399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pruning, 406–407'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule extraction algorithms, 406, 407'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sensitivity analysis, 408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'three-layer, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'topology deﬁnition, 400'\n",
            "Warning: Text found before any chapter, section, or subsection: 'two-layer, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'neurodes, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Ng-Jordan-Weiss algorithm, 521, 522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'no materialization, 159'\n",
            "Warning: Text found before any chapter, section, or subsection: 'noise ﬁltering, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'noisy data, 89–91'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nominal attributes, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'concept hierarchies for, 284'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation analysis, 95–96'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dissimilarity between, 69'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 41'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity measures, 68–70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity computation, 70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'values of, 79, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also attributes'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonlinear SVMs, 413–415'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonparametric statistical methods,'\n",
            "Warning: Text found before any chapter, section, or subsection: '553–558'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonvolatile data warehouses, 127'\n",
            "Warning: Text found before any chapter, section, or subsection: 'normalization, 112, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data transformation by, 113–115'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by decimal scaling, 115'\n",
            "Warning: Text found before any chapter, section, or subsection: 'min-max, 114'\n",
            "Warning: Text found before any chapter, section, or subsection: 'z-score, 114–115'\n",
            "Warning: Text found before any chapter, section, or subsection: 'null rules, 92'\n",
            "Warning: Text found before any chapter, section, or subsection: 'null-invariant measures, 270–271, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'null-transactions, 270, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'number of, 270'\n",
            "Warning: Text found before any chapter, section, or subsection: 'problem, 292–293'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric attributes, 43–44, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'covariance analysis, 98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interval-scaled, 43, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ratio-scaled, 43–44, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric data, dissimilarity on, 72–74'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric prediction, 328, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support vector machines (SVMs) for, 408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numerosity reduction, 86, 100, 120'\n",
            "Warning: Text found before any chapter, section, or subsection: 'techniques, 100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'O'\n",
            "Warning: Text found before any chapter, section, or subsection: 'object matching, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'objective interestingness measures, 21–22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'one-class model, 571–572'\n",
            "Warning: Text found before any chapter, section, or subsection: 'one-pass cube computation, 198'\n",
            "Warning: Text found before any chapter, section, or subsection: 'one-versus-all (OVA), 430'\n",
            "Warning: Text found before any chapter, section, or subsection: 'online analytical mining (OLAM), 155, 227'\n",
            "Warning: Text found before any chapter, section, or subsection: 'online analytical processing (OLAP), 4, 33, 128,'\n",
            "Warning: Text found before any chapter, section, or subsection: '179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'access patterns, 129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data contents, 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database design, 129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dice operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drill-across operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drill-down operation, 11, 135–136, 146'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drill-through operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example operations, 147'\n",
            "Warning: Text found before any chapter, section, or subsection: 'functionalities of, 154'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hybrid OLAP, 164–165, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'indexing, 125, 160–163'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in information networks, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in knowledge discovery process, 125'\n",
            "Warning: Text found before any chapter, section, or subsection: 'market orientation, 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multidimensional (MOLAP), 132, 164, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLTP versus, 128–129, 130'\n",
            "Warning: Text found before any chapter, section, or subsection: 'operation integration, 125'\n",
            "Warning: Text found before any chapter, section, or subsection: 'operations, 146–148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pivot (rotate) operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'queries, 129, 130, 163–164'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query processing, 125, 163–164'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational OLAP, 132, 164, 165, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'roll-up operation, 11, 135–136, 146'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sample data effectiveness, 219'\n",
            "Warning: Text found before any chapter, section, or subsection: 'server architectures, 164–165'\n",
            "Warning: Text found before any chapter, section, or subsection: 'servers, 132'\n",
            "Warning: Text found before any chapter, section, or subsection: 'slice operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical databases versus, 148–149'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '695'\n",
            "Warning: Text found before any chapter, section, or subsection: 'user-control versus automation, 167'\n",
            "Warning: Text found before any chapter, section, or subsection: 'view, 129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'online transaction processing (OLTP), 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'access patterns, 129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'customer orientation, 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data contents, 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'database design, 129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP versus, 128–129, 130'\n",
            "Warning: Text found before any chapter, section, or subsection: 'view, 129'\n",
            "Warning: Text found before any chapter, section, or subsection: 'operational metadata, 135'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OPTICS, 473–476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster ordering, 474–475, 477'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core-distance, 475'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density estimation, 477'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reachability-distance, 475'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structure, 476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'terminology, 476'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis; density-based methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordered attributes, 103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordering'\n",
            "Warning: Text found before any chapter, section, or subsection: 'class-based, 358'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordinal attributes, 42, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dissimilarity between, 75'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 42'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity measures, 74–75'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier analysis, 20–21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering-based techniques, 66'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in noisy data, 90'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier detection, 543–584'\n",
            "Warning: Text found before any chapter, section, or subsection: 'angle-based (ABOD), 580'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application-speciﬁc, 548–549'\n",
            "Warning: Text found before any chapter, section, or subsection: 'categories of, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'CELL method, 562–563'\n",
            "Warning: Text found before any chapter, section, or subsection: 'challenges, 548–549'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering analysis and, 543'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering for, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering-based methods, 552–553, 560–567'\n",
            "Warning: Text found before any chapter, section, or subsection: 'collective, 548, 575–576'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual, 546–547, 573–575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based, 561–562'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extending, 577–578'\n",
            "Warning: Text found before any chapter, section, or subsection: 'global, 545'\n",
            "Warning: Text found before any chapter, section, or subsection: 'handling noise in, 549'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in high-dimensional data, 576–580, 582'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with histograms, 558–560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intrusion detection, 569–570'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 549–553'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mixture of parametric distributions, 556–558'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multivariate, 556'\n",
            "Warning: Text found before any chapter, section, or subsection: 'novelty detection relationship, 545'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity-based methods, 552, 560–567, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised methods, 551'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical methods, 552, 553–560, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supervised methods, 549–550'\n",
            "Warning: Text found before any chapter, section, or subsection: 'understandability, 549'\n",
            "Warning: Text found before any chapter, section, or subsection: 'univariate, 554'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unsupervised methods, 550'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier subgraphs, 576'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outliers'\n",
            "Warning: Text found before any chapter, section, or subsection: 'angle-based, 20, 543, 544, 580'\n",
            "Warning: Text found before any chapter, section, or subsection: 'collective, 547–548, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contextual, 545–547, 573, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based, 564'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based, 561'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 544'\n",
            "Warning: Text found before any chapter, section, or subsection: 'global, 545, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'high-dimensional, modeling, 579–580'\n",
            "Warning: Text found before any chapter, section, or subsection: 'identifying, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretation of, 577'\n",
            "Warning: Text found before any chapter, section, or subsection: 'local proximity-based, 564–565'\n",
            "Warning: Text found before any chapter, section, or subsection: 'modeling, 548'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in small clusters, 571'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 545–548, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visualization with boxplot, 555'\n",
            "Warning: Text found before any chapter, section, or subsection: 'oversampling, 384, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 384–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'P'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pairwise alignment, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pairwise comparison, 372'\n",
            "Warning: Text found before any chapter, section, or subsection: 'PAM. See Partitioning Around Medoids algorithm'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parallel and distributed data-intensive mining'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithms, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parallel coordinates, 59, 62'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parametric data reduction, 105–106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parametric statistical methods, 553–558'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pareto distribution, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partial distance method, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partial materialization, 159–160, 179, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strategies, 192'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partition matrix, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithms, 451–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in Apriori efﬁciency, 255–256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bootstrapping, 371, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'criteria, 447'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cross-validation, 370–371, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Gini index and, 342'\n",
            "Warning: Text found before any chapter, section, or subsection: 'holdout method, 370, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random sampling, 370, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: '696'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recursive, 335'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tuples, 334'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Partitioning Around Medoids (PAM) algorithm,'\n",
            "Warning: Text found before any chapter, section, or subsection: '455–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning methods, 448, 451–457, 491'\n",
            "Warning: Text found before any chapter, section, or subsection: 'centroid-based, 451–454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'global optimality, 449'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iterative relocation techniques, 448'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-means, 451–454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-medoids, 454–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-modes, 454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'object-based, 454–457'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'path-based similarity, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern analysis, in recommender systems,'\n",
            "Warning: Text found before any chapter, section, or subsection: '282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern clustering, 308–310'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern constraints, 297–300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern discovery, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern evaluation, 8'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern evaluation measures, 267–271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'all conﬁdence, 268'\n",
            "Warning: Text found before any chapter, section, or subsection: 'comparison, 269–270'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cosine, 268'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Kulczynski, 268'\n",
            "Warning: Text found before any chapter, section, or subsection: 'max conﬁdence, 268'\n",
            "Warning: Text found before any chapter, section, or subsection: 'null-invariant, 270–271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also measures'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern space pruning, 295'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-based classiﬁcation, 282, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-based clustering, 282, 516'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pattern-Fusion, 302–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'characteristics, 304'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core pattern, 304–305'\n",
            "Warning: Text found before any chapter, section, or subsection: 'initial pool, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'iterative, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'merging subpatterns, 306'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shortcuts identiﬁcation, 304'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also colossal patterns'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-guided mining, 30'\n",
            "Warning: Text found before any chapter, section, or subsection: 'patterns'\n",
            "Warning: Text found before any chapter, section, or subsection: 'actionable, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'co-location, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'colossal, 301–307, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'combined signiﬁcance, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based generation, 296–301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'context modeling of, 314–315'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core, 304–305'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance, 309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evaluation methods, 264–271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expected, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expressed, 309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent, 17'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hidden meaning of, 314'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interesting, 21–23, 33'\n",
            "Warning: Text found before any chapter, section, or subsection: 'metric space, 306–307'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative, 280, 291–294, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negatively correlated, 292, 293'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rare, 280, 291–294, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy between, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relative signiﬁcance, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'representative, 309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'search space, 303'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strongly negatively correlated, 292'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structural, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'type speciﬁcation, 15–23'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unexpected, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also frequent patterns'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern-trees, 264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Pearson’s correlation coefﬁcient, 222'\n",
            "Warning: Text found before any chapter, section, or subsection: 'percentiles, 48'\n",
            "Warning: Text found before any chapter, section, or subsection: 'perception-based classiﬁcation (PBC), 348'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 349'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as interactive visual approach, 607'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pixel-oriented approach, 348–349'\n",
            "Warning: Text found before any chapter, section, or subsection: 'split screen, 349'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tree comparison, 350'\n",
            "Warning: Text found before any chapter, section, or subsection: 'phylogenetic trees, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pivot (rotate) operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pixel-oriented visualization, 57'\n",
            "Warning: Text found before any chapter, section, or subsection: 'planning and analysis tools, 153'\n",
            "Warning: Text found before any chapter, section, or subsection: 'point queries, 216, 217, 220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pool-based approach, 433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'positive correlation, 55, 56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'positive tuples, 364'\n",
            "Warning: Text found before any chapter, section, or subsection: 'positively skewed data, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'possibility theory, 428'\n",
            "Warning: Text found before any chapter, section, or subsection: 'posterior probability, 351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'postpruning, 344–345, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'power law distribution, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'precision measure, 368–369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predicate sets'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent, 288–289'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k, 289'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predicates'\n",
            "Warning: Text found before any chapter, section, or subsection: 'repeated, 288'\n",
            "Warning: Text found before any chapter, section, or subsection: 'variables, 295'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prediction, 19'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'link, 593–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'loan payment, 608–609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with naive Bayesian classiﬁcation, 353–355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'numeric, 328, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '697'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prediction cubes, 227–230, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 228–229'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Probability-Based Ensemble, 229–230'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictive analysis, 18–19'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictive mining tasks, 15'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictive statistics, 24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictors, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prepruning, 344, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prime relations'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contrasting classes, 175, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'deriving, 174'\n",
            "Warning: Text found before any chapter, section, or subsection: 'target classes, 175, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'principle components analysis (PCA), 100, 102–103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'application of, 103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation-based clustering with, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in lower-dimensional space extraction, 578'\n",
            "Warning: Text found before any chapter, section, or subsection: 'procedure, 102–103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prior probability, 351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'privacy-preserving data mining, 33, 621, 626'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distributed, 622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-anonymity method, 621–622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'l-diversity method, 622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as mining trend, 624–625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'randomization methods, 621'\n",
            "Warning: Text found before any chapter, section, or subsection: 'results effectiveness, downgrading, 622'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic clusters, 502–503'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic hierarchical clustering, 467–470'\n",
            "Warning: Text found before any chapter, section, or subsection: 'agglomerative clustering framework, 467,'\n",
            "Warning: Text found before any chapter, section, or subsection: '469'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm, 470'\n",
            "Warning: Text found before any chapter, section, or subsection: 'drawbacks of using, 469–470'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generative model, 467–469'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interpretability, 469'\n",
            "Warning: Text found before any chapter, section, or subsection: 'understanding, 469'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also hierarchical methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probabilistic model-based clustering, 497–508, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expectation-maximization algorithm, 505–508'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fuzzy clusters and, 499–501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'product reviews example, 498'\n",
            "Warning: Text found before any chapter, section, or subsection: 'user search intent example, 498'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probability'\n",
            "Warning: Text found before any chapter, section, or subsection: 'estimation techniques, 355'\n",
            "Warning: Text found before any chapter, section, or subsection: 'posterior, 351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prior, 351'\n",
            "Warning: Text found before any chapter, section, or subsection: 'probability and statistical theory, 601'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Probability-Based Ensemble (PBE), 229–230'\n",
            "Warning: Text found before any chapter, section, or subsection: 'PROCLUS, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proﬁles, 614'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity measures, 67'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for binary attributes, 70–72'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for nominal attributes, 68–70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for ordinal attributes, 74–75'\n",
            "Warning: Text found before any chapter, section, or subsection: 'proximity-based methods, 552, 560–567, 581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'density-based, 564–567'\n",
            "Warning: Text found before any chapter, section, or subsection: 'distance-based, 561–562'\n",
            "Warning: Text found before any chapter, section, or subsection: 'effectiveness, 552'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 552'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grid-based, 562–564'\n",
            "Warning: Text found before any chapter, section, or subsection: 'types of, 552, 560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also outlier detection'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pruning'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cost complexity algorithm, 345'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data space, 300–301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision trees, 331, 344–347'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in k-nearest neighbor classiﬁcation, 425'\n",
            "Warning: Text found before any chapter, section, or subsection: 'network, 406–407'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pattern space, 295, 297–300'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pessimistic, 345'\n",
            "Warning: Text found before any chapter, section, or subsection: 'postpruning, 344–345, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prepruning, 344, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule, 363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'search space, 263, 301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sets, 345'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shared dimensions, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sub-itemset, 263'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pyramid algorithm, 101'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Q'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quality control, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantile plots, 51–52'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantile-quantile plots, 52'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 53–54'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 53'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also graphic displays'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quantitative association rules, 281, 283, 288,'\n",
            "Warning: Text found before any chapter, section, or subsection: '320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering-based mining, 290–291'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data cube-based mining, 289–290'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exceptional behavior disclosure, 291'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 289'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quartiles, 48'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁrst, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'third, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'queries, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intercuboid expansion, 223–225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intracuboid expansion, 221–223'\n",
            "Warning: Text found before any chapter, section, or subsection: 'language, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP, 129, 130'\n",
            "Warning: Text found before any chapter, section, or subsection: 'point, 216, 217, 220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'processing, 163–164, 218–227'\n",
            "Warning: Text found before any chapter, section, or subsection: 'range, 220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational operations, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: '698'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'queries (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subcube, 216, 217–218'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k, 225–227'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query languages, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query models, 149–150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query-driven approach, 128'\n",
            "Warning: Text found before any chapter, section, or subsection: 'querying function, 433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'R'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rag bag criterion, 488'\n",
            "Warning: Text found before any chapter, section, or subsection: 'RainForest, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random forests, 382–383'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random sampling, 370, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random subsampling, 370'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random walk, 526'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity based on, 527'\n",
            "Warning: Text found before any chapter, section, or subsection: 'randomization methods, 621'\n",
            "Warning: Text found before any chapter, section, or subsection: 'range, 48'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interquartile, 49'\n",
            "Warning: Text found before any chapter, section, or subsection: 'range queries, 220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ranking'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cubes, 225–227, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensions, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'function, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous networks, 593'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rare patterns, 280, 283, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 291–292'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 291–294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ratio-scaled attributes, 43–44, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reachability density, 566'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reachability distance, 565'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recall measure, 368–369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recognition rate, 366–367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recommender systems, 282, 615'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advantages, 616'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biclustering for, 514–515'\n",
            "Warning: Text found before any chapter, section, or subsection: 'challenges, 617'\n",
            "Warning: Text found before any chapter, section, or subsection: 'collaborative, 610, 615, 616, 617, 618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'content-based approach, 615, 616'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining and, 615–618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'error types, 617–618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent pattern mining for, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hybrid approaches, 618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'intelligent query answering, 618'\n",
            "Warning: Text found before any chapter, section, or subsection: 'memory-based methods, 617'\n",
            "Warning: Text found before any chapter, section, or subsection: 'use scenarios, 616'\n",
            "Warning: Text found before any chapter, section, or subsection: 'recursive partitioning, 335'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reduced support, 285, 286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in data integration, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'detection by correlations analysis, 94–98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'redundancy-aware top-k patterns, 281, 311, 320'\n",
            "Warning: Text found before any chapter, section, or subsection: 'extracting, 310–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ﬁnding, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strategy comparison, 311–312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trade-offs, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'refresh, in back-end tools/utilities, 134'\n",
            "Warning: Text found before any chapter, section, or subsection: 'regression, 19, 90'\n",
            "Warning: Text found before any chapter, section, or subsection: 'coefﬁcients, 105–106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 19'\n",
            "Warning: Text found before any chapter, section, or subsection: 'linear, 90, 105–106'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in statistical data mining, 599'\n",
            "Warning: Text found before any chapter, section, or subsection: 'regression analysis, 19, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in time-series data, 587–588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational databases, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'components of, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational schema for, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relational OLAP (ROLAP), 132, 164, 165, 179'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relative signiﬁcance, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'relevance analysis, 19'\n",
            "Warning: Text found before any chapter, section, or subsection: 'repetition, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'replication, 347'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 346'\n",
            "Warning: Text found before any chapter, section, or subsection: 'representative patterns, 309'\n",
            "Warning: Text found before any chapter, section, or subsection: 'retail industry, 609–611'\n",
            "Warning: Text found before any chapter, section, or subsection: 'RIPPER, 359, 363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'robustness, classiﬁcation, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ROC curves, 374, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation models, 377'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁer comparison with, 373–377'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 376, 377'\n",
            "Warning: Text found before any chapter, section, or subsection: 'plotting, 375'\n",
            "Warning: Text found before any chapter, section, or subsection: 'roll-up operation, 11, 146'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rough set approach, 428–429, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'row enumeration, 302'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule ordering, 357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule pruning, 363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule quality measures, 361–363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule-based classiﬁcation, 355–363, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'IF-THEN rules, 355–357'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule extraction, 357–359'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule induction, 359–363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule pruning, 363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule quality measures, 361–363'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rules for constraints, 294'\n",
            "Warning: Text found before any chapter, section, or subsection: 'S'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sales campaign analysis, 610'\n",
            "Warning: Text found before any chapter, section, or subsection: 'samples, 218'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster, 108–109'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 219'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '699'\n",
            "Warning: Text found before any chapter, section, or subsection: 'simple random, 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stratiﬁed, 109–110'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sampling'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in Apriori efﬁciency, 256'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as data redundancy technique, 108–110'\n",
            "Warning: Text found before any chapter, section, or subsection: 'methods, 108–110'\n",
            "Warning: Text found before any chapter, section, or subsection: 'oversampling, 384–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with replacement, 380–381'\n",
            "Warning: Text found before any chapter, section, or subsection: 'uncertainty, 433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'undersampling, 384–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sampling cubes, 218–220, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'conﬁdence interval, 219–220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'framework, 219–220'\n",
            "Warning: Text found before any chapter, section, or subsection: 'query expansion with, 221'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SAS Enterprise Miner, 603, 604'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalability'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster analysis, 446'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cluster methods, 445'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining algorithms, 31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'decision tree induction and, 347–348'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimensionality and, 577'\n",
            "Warning: Text found before any chapter, section, or subsection: 'k-means, 454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scalable computation, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SCAN. See Structural Clustering Algorithm for'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Networks'\n",
            "Warning: Text found before any chapter, section, or subsection: 'core vertex, 531'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 532'\n",
            "Warning: Text found before any chapter, section, or subsection: 'scatter plots, 54'\n",
            "Warning: Text found before any chapter, section, or subsection: '2-D data set visualization with, 59'\n",
            "Warning: Text found before any chapter, section, or subsection: '3-D data set visualization with, 60'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlations between attributes, 54–56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 55'\n",
            "Warning: Text found before any chapter, section, or subsection: 'matrix, 56, 59'\n",
            "Warning: Text found before any chapter, section, or subsection: 'schemas'\n",
            "Warning: Text found before any chapter, section, or subsection: 'integration, 94'\n",
            "Warning: Text found before any chapter, section, or subsection: 'snowﬂake, 140–141'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star, 139–140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'science applications, 611–613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'search engines, 28'\n",
            "Warning: Text found before any chapter, section, or subsection: 'search space pruning, 263, 301'\n",
            "Warning: Text found before any chapter, section, or subsection: 'second guess heuristic, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'selection dimensions, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'self-training, 432'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semantic annotations'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 317, 313, 320–321'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with context modeling, 316'\n",
            "Warning: Text found before any chapter, section, or subsection: 'from DBLP data set, 316–317'\n",
            "Warning: Text found before any chapter, section, or subsection: 'effectiveness, 317'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 314–315'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of frequent patterns, 313–317'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mutual information, 315–316'\n",
            "Warning: Text found before any chapter, section, or subsection: 'task deﬁnition, 315'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Semantic Web, 597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-ofﬂine materialization, 226'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised classiﬁcation, 432–433,'\n",
            "Warning: Text found before any chapter, section, or subsection: '437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'alternative approaches, 433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cotraining, 432–433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'self-training, 432'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised learning, 25'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outlier detection by, 572'\n",
            "Warning: Text found before any chapter, section, or subsection: 'semi-supervised outlier detection, 551'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sensitivity analysis, 408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sensitivity measure, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sentiment classiﬁcation, 434'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequence data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequences, 586'\n",
            "Warning: Text found before any chapter, section, or subsection: 'alignment, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biological, 586, 590–591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'classiﬁcation of, 589–590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity searches, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symbolic, 586, 588–590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series, 586, 587–588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequential covering algorithm, 359'\n",
            "Warning: Text found before any chapter, section, or subsection: 'general-to-speciﬁc search, 360'\n",
            "Warning: Text found before any chapter, section, or subsection: 'greedy search, 361'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 359'\n",
            "Warning: Text found before any chapter, section, or subsection: 'rule induction with, 359–361'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequential pattern mining, 589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraint-based, 589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in symbolic sequences, 588–589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shapelets method, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shared dimensions, 204'\n",
            "Warning: Text found before any chapter, section, or subsection: 'pruning, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shared-sorts, 193'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shared-partitions, 193'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shell cubes, 160'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shell fragments, 192, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approach, 211–212'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation algorithm, 212, 213'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation example, 214–215'\n",
            "Warning: Text found before any chapter, section, or subsection: 'precomputing, 210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shrinking diameter, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sigmoid function, 402'\n",
            "Warning: Text found before any chapter, section, or subsection: 'signature-based detection, 614'\n",
            "Warning: Text found before any chapter, section, or subsection: 'signiﬁcance levels, 373'\n",
            "Warning: Text found before any chapter, section, or subsection: 'signiﬁcance measure, 312'\n",
            "Warning: Text found before any chapter, section, or subsection: 'signiﬁcance tests, 372–373, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'silhouette coefﬁcient, 489–490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity'\n",
            "Warning: Text found before any chapter, section, or subsection: 'asymmetric binary, 71'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cosine, 77–78'\n",
            "Warning: Text found before any chapter, section, or subsection: '700'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity (Continued)'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measuring, 65–78, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nominal attributes, 70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity measures, 447–448, 525–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'constraints on, 533'\n",
            "Warning: Text found before any chapter, section, or subsection: 'geodesic distance, 525–526'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SimRank, 526–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'similarity searches, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in information networks, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in multimedia data mining, 596'\n",
            "Warning: Text found before any chapter, section, or subsection: 'simple random sample with replacement'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SRSWR), 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'simple random sample without replacement'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SRSWOR), 108'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SimRank, 526–528, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computation, 527–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random walk, 526–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structural context, 528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'simultaneous aggregation, 195'\n",
            "Warning: Text found before any chapter, section, or subsection: 'single-dimensional association rules, 17, 287'\n",
            "Warning: Text found before any chapter, section, or subsection: 'single-linkage algorithm, 460, 461'\n",
            "Warning: Text found before any chapter, section, or subsection: 'singular value decomposition (SVD), 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'skewed data'\n",
            "Warning: Text found before any chapter, section, or subsection: 'balanced, 271'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negatively, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'positively, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'wavelet transforms on, 102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'slice operation, 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'small-world phenomenon, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'smoothing, 112'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by bin boundaries, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by bin means, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'by bin medians, 89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for data discretization, 90'\n",
            "Warning: Text found before any chapter, section, or subsection: 'snowﬂake schema, 140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 141'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 141'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star schema versus, 140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'social networks, 524–525, 526–528'\n",
            "Warning: Text found before any chapter, section, or subsection: 'densiﬁcation power law, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'evolution of, 594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mining, 623'\n",
            "Warning: Text found before any chapter, section, or subsection: 'small-world phenomenon, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also networks'\n",
            "Warning: Text found before any chapter, section, or subsection: 'social science/social studies data mining,'\n",
            "Warning: Text found before any chapter, section, or subsection: '613'\n",
            "Warning: Text found before any chapter, section, or subsection: 'soft clustering, 501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'soft constraints, 534, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 534'\n",
            "Warning: Text found before any chapter, section, or subsection: 'handling, 536–537'\n",
            "Warning: Text found before any chapter, section, or subsection: 'space-ﬁlling curve, 58'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparse data, 102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparse data cubes, 190'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparsest cuts, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparsity coefﬁcient, 579'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial data, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial data mining, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatiotemporal data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatiotemporal data mining, 595, 623–624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'specialized SQL servers, 165'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speciﬁcity measure, 367'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spectral clustering, 520–522, 539'\n",
            "Warning: Text found before any chapter, section, or subsection: 'effectiveness, 522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'framework, 521'\n",
            "Warning: Text found before any chapter, section, or subsection: 'steps, 520–522'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speech recognition, 430'\n",
            "Warning: Text found before any chapter, section, or subsection: 'speed, classiﬁcation, 369'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spiral method, 152'\n",
            "Warning: Text found before any chapter, section, or subsection: 'split-point, 333, 340, 342'\n",
            "Warning: Text found before any chapter, section, or subsection: 'splitting attributes, 333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'splitting criterion, 333, 342'\n",
            "Warning: Text found before any chapter, section, or subsection: 'splitting rules. See attribute selection measures'\n",
            "Warning: Text found before any chapter, section, or subsection: 'splitting subset, 333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SQL, as relational query language, 10'\n",
            "Warning: Text found before any chapter, section, or subsection: 'square-error function, 454'\n",
            "Warning: Text found before any chapter, section, or subsection: 'squashing function, 403'\n",
            "Warning: Text found before any chapter, section, or subsection: 'standard deviation, 51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'function of, 50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star schema, 139'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 139–140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'snowﬂake schema versus, 140'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Star-Cubing, 204–210, 235'\n",
            "Warning: Text found before any chapter, section, or subsection: 'algorithm illustration, 209'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bottom-up computation, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 207'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for full cube computation, 210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ordering of dimensions and, 210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'performance, 210'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shared dimensions, 204–205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'starnet query model, 149'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 149–150'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star-nodes, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'star-trees, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'compressed base table, 207'\n",
            "Warning: Text found before any chapter, section, or subsection: 'construction, 205'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical data mining, 598–600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'analysis of variance, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discriminant analysis, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'factor analysis, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'generalized linear models, 599–600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'mixed-effect models, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'quality control, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '701'\n",
            "Warning: Text found before any chapter, section, or subsection: 'regression, 599'\n",
            "Warning: Text found before any chapter, section, or subsection: 'survival analysis, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical databases (SDBs), 148'\n",
            "Warning: Text found before any chapter, section, or subsection: 'OLAP systems versus, 148–149'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical descriptions, 24, 79'\n",
            "Warning: Text found before any chapter, section, or subsection: 'graphic displays, 44–45, 51–56'\n",
            "Warning: Text found before any chapter, section, or subsection: 'measuring the dispersion, 48–51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical hypothesis test, 24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical models, 23–24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'of networks, 592–594'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical outlier detection methods, 552, 553–560,'\n",
            "Warning: Text found before any chapter, section, or subsection: '581'\n",
            "Warning: Text found before any chapter, section, or subsection: 'computational cost of, 560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for data analysis, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'effectiveness, 552'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 552'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonparametric, 553, 558–560'\n",
            "Warning: Text found before any chapter, section, or subsection: 'parametric, 553–558'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also outlier detection'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistical theory, in exceptional behavior disclosure,'\n",
            "Warning: Text found before any chapter, section, or subsection: '291'\n",
            "Warning: Text found before any chapter, section, or subsection: 'statistics, 23'\n",
            "Warning: Text found before any chapter, section, or subsection: 'inferential, 24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictive, 24'\n",
            "Warning: Text found before any chapter, section, or subsection: 'StatSoft, 602, 603'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stepwise backward elimination, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stepwise forward selection, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stick ﬁgure visualization, 61–63'\n",
            "Warning: Text found before any chapter, section, or subsection: 'STING, 479–481'\n",
            "Warning: Text found before any chapter, section, or subsection: 'advantages, 480–481'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as density-based clustering method, 480'\n",
            "Warning: Text found before any chapter, section, or subsection: 'hierarchical structure, 479, 480'\n",
            "Warning: Text found before any chapter, section, or subsection: 'multiresolution approach, 481'\n",
            "Warning: Text found before any chapter, section, or subsection: 'See also cluster analysis; grid-based methods'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stratiﬁed cross-validation, 371'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stratiﬁed samples, 109–110'\n",
            "Warning: Text found before any chapter, section, or subsection: 'stream data, 598, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'strong association rules, 272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interestingness and, 264–265'\n",
            "Warning: Text found before any chapter, section, or subsection: 'misleading, 265'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Structural Clustering Algorithm for Networks'\n",
            "Warning: Text found before any chapter, section, or subsection: '(SCAN), 531–532'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structural context-based similarity, 526'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structural data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structural patterns, 282'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structure similarity search, 592'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structures'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as contexts, 575'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discovery of, 318'\n",
            "Warning: Text found before any chapter, section, or subsection: 'indexing, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'substructures, 243'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Student’s t-test, 372'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subcube queries, 216, 217–218'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sub-itemset pruning, 263'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subjective interestingness measures, 22'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subject-oriented data warehouses, 126'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subsequence, 589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'matching, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subset checking, 263–264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subset testing, 250'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace clustering, 448'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent patterns for, 318–319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace clustering methods, 509, 510–511,'\n",
            "Warning: Text found before any chapter, section, or subsection: '538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'biclustering, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'correlation-based, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'examples, 538'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspace search methods, 510–511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subspaces'\n",
            "Warning: Text found before any chapter, section, or subsection: 'bottom-up search, 510–511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cube space, 228–229'\n",
            "Warning: Text found before any chapter, section, or subsection: 'outliers in, 578–579'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down search, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'substitution matrices, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'substructures, 243'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sum of the squared error (SSE), 501'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summary fact tables, 165'\n",
            "Warning: Text found before any chapter, section, or subsection: 'superset checking, 263'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supervised learning, 24, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supervised outlier detection, 549–550'\n",
            "Warning: Text found before any chapter, section, or subsection: 'challenges, 550'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'association rule, 21'\n",
            "Warning: Text found before any chapter, section, or subsection: 'group-based, 286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'reduced, 285, 286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'uniform, 285–286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support, rule, 245, 246'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support vector machines (SVMs), 393, 408–415,'\n",
            "Warning: Text found before any chapter, section, or subsection: '437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interest in, 408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'maximum marginal hyperplane, 409, 412'\n",
            "Warning: Text found before any chapter, section, or subsection: 'nonlinear, 413–415'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for numeric prediction, 408'\n",
            "Warning: Text found before any chapter, section, or subsection: 'with sigmoid kernel, 415'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support vectors, 411'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for test tuples, 412–413'\n",
            "Warning: Text found before any chapter, section, or subsection: 'training/testing speed improvement, 415'\n",
            "Warning: Text found before any chapter, section, or subsection: 'support vectors, 411, 437'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 411'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SVM ﬁnding, 412'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supremum distance, 73–74'\n",
            "Warning: Text found before any chapter, section, or subsection: 'surface web, 597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'survival analysis, 600'\n",
            "Warning: Text found before any chapter, section, or subsection: 'SVMs. See support vector machines'\n",
            "Warning: Text found before any chapter, section, or subsection: '702'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symbolic sequences, 586, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sequential pattern mining in, 588–589'\n",
            "Warning: Text found before any chapter, section, or subsection: 'symmetric binary dissimilarity, 70'\n",
            "Warning: Text found before any chapter, section, or subsection: 'synchronous generalization, 175'\n",
            "Warning: Text found before any chapter, section, or subsection: 'T'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tables, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'attributes, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'contingency, 95'\n",
            "Warning: Text found before any chapter, section, or subsection: 'dimension, 136'\n",
            "Warning: Text found before any chapter, section, or subsection: 'fact, 165'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tuples, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tag clouds, 64, 66'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Tanimoto coefﬁcient, 78'\n",
            "Warning: Text found before any chapter, section, or subsection: 'target classes, 15, 180'\n",
            "Warning: Text found before any chapter, section, or subsection: 'initial working relations, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'prime relation, 175, 177'\n",
            "Warning: Text found before any chapter, section, or subsection: 'targeted marketing, 609'\n",
            "Warning: Text found before any chapter, section, or subsection: 'taxonomy formation, 20'\n",
            "Warning: Text found before any chapter, section, or subsection: 'technologies, 23–27, 33, 34'\n",
            "Warning: Text found before any chapter, section, or subsection: 'telecommunications industry, 611'\n",
            "Warning: Text found before any chapter, section, or subsection: 'temporal data, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'term-frequency vectors, 77'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cosine similarity between, 78'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sparse, 77'\n",
            "Warning: Text found before any chapter, section, or subsection: 'table, 77'\n",
            "Warning: Text found before any chapter, section, or subsection: 'terminating conditions, 404'\n",
            "Warning: Text found before any chapter, section, or subsection: 'test sets, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'test tuples, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'text data, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'text mining, 596–597, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'theoretical foundations, 600–601, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'three-layer neural networks, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'threshold-moving approach, 385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tilted time windows, 598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'timeliness, data, 85'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series data, 586, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'cyclic movements, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discretization and, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrated, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'random movements, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'regression analysis, 587–588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'seasonal variations, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'shapelets method, 590'\n",
            "Warning: Text found before any chapter, section, or subsection: 'subsequence matching, 587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transformation into aggregate approximations,'\n",
            "Warning: Text found before any chapter, section, or subsection: '587'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trend analysis, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trend or long-term movements, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-series forecasting, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'time-variant data warehouses, 127'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down design approach, 133, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down subspace search, 511'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-down view, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'topic model, 26–27'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k patterns/rules, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k queries, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 225–226'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ranking cubes to answer, 226–227'\n",
            "Warning: Text found before any chapter, section, or subsection: 'results, 225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'user-speciﬁed preference components,'\n",
            "Warning: Text found before any chapter, section, or subsection: '225'\n",
            "Warning: Text found before any chapter, section, or subsection: 'top-k strategies'\n",
            "Warning: Text found before any chapter, section, or subsection: 'comparison illustration, 311'\n",
            "Warning: Text found before any chapter, section, or subsection: 'summarized pattern, 311'\n",
            "Warning: Text found before any chapter, section, or subsection: 'traditional, 311'\n",
            "Warning: Text found before any chapter, section, or subsection: 'TrAdaBoost, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'training'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Bayesian belief networks, 396–397'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data, 18'\n",
            "Warning: Text found before any chapter, section, or subsection: 'sets, 328'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tuples, 332–333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transaction reduction, 255'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transactional databases, 13'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 13–14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transactions, components of, 13'\n",
            "Warning: Text found before any chapter, section, or subsection: 'transfer learning, 430, 435, 434–436, 438'\n",
            "Warning: Text found before any chapter, section, or subsection: 'applications, 435'\n",
            "Warning: Text found before any chapter, section, or subsection: 'approaches to, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'heterogeneous, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative transfer and, 436'\n",
            "Warning: Text found before any chapter, section, or subsection: 'target task, 435'\n",
            "Warning: Text found before any chapter, section, or subsection: 'traditional learning versus, 435'\n",
            "Warning: Text found before any chapter, section, or subsection: 'treemaps, 63, 65'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trend analysis'\n",
            "Warning: Text found before any chapter, section, or subsection: 'spatial, 595'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in time-series data, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for time-series forecasting, 588'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trends, data mining, 622–625, 626'\n",
            "Warning: Text found before any chapter, section, or subsection: 'triangle inequality, 73'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trimmed mean, 46'\n",
            "Warning: Text found before any chapter, section, or subsection: 'trimodal, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'true negatives, 365'\n",
            "Warning: Text found before any chapter, section, or subsection: 'true positives, 365'\n",
            "Warning: Text found before any chapter, section, or subsection: 't-test, 372'\n",
            "Warning: Text found before any chapter, section, or subsection: 'tuples, 9'\n",
            "Warning: Text found before any chapter, section, or subsection: 'duplication, 98–99'\n",
            "Warning: Text found before any chapter, section, or subsection: 'negative, 364'\n",
            "Warning: Text found before any chapter, section, or subsection: 'partitioning, 334, 337'\n",
            "Warning: Text found before any chapter, section, or subsection: 'positive, 364'\n",
            "Warning: Text found before any chapter, section, or subsection: 'training, 332–333'\n",
            "Warning: Text found before any chapter, section, or subsection: 'two sample t-test, 373'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Index'\n",
            "Warning: Text found before any chapter, section, or subsection: '703'\n",
            "Warning: Text found before any chapter, section, or subsection: 'two-layer neural networks, 399'\n",
            "Warning: Text found before any chapter, section, or subsection: 'two-level hash index structure, 264'\n",
            "Warning: Text found before any chapter, section, or subsection: 'U'\n",
            "Warning: Text found before any chapter, section, or subsection: 'ubiquitous data mining, 618–620, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'uncertainty sampling, 433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'undersampling, 384, 386'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 384–385'\n",
            "Warning: Text found before any chapter, section, or subsection: 'uniform support, 285–286'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unimodal, 47'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unique rules, 92'\n",
            "Warning: Text found before any chapter, section, or subsection: 'univariate distribution, 40'\n",
            "Warning: Text found before any chapter, section, or subsection: 'univariate Gaussian mixture model, 504'\n",
            "Warning: Text found before any chapter, section, or subsection: 'univariate outlier detection, 554–555'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unordered attributes, 103'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unordered rules, 358'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unsupervised learning, 25, 330, 445, 490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering as, 25, 445, 490'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 25'\n",
            "Warning: Text found before any chapter, section, or subsection: 'supervised learning versus, 330'\n",
            "Warning: Text found before any chapter, section, or subsection: 'unsupervised outlier detection, 550'\n",
            "Warning: Text found before any chapter, section, or subsection: 'assumption, 550'\n",
            "Warning: Text found before any chapter, section, or subsection: 'clustering methods acting as, 551'\n",
            "Warning: Text found before any chapter, section, or subsection: 'upper approximation, 427'\n",
            "Warning: Text found before any chapter, section, or subsection: 'user interaction, 30–31'\n",
            "Warning: Text found before any chapter, section, or subsection: 'V'\n",
            "Warning: Text found before any chapter, section, or subsection: 'values'\n",
            "Warning: Text found before any chapter, section, or subsection: 'exception, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'expected, 97, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'missing, 88–89'\n",
            "Warning: Text found before any chapter, section, or subsection: 'residual, 234'\n",
            "Warning: Text found before any chapter, section, or subsection: 'in rules or patterns, 281'\n",
            "Warning: Text found before any chapter, section, or subsection: 'variables'\n",
            "Warning: Text found before any chapter, section, or subsection: 'grouping, 231'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predicate, 295'\n",
            "Warning: Text found before any chapter, section, or subsection: 'predictor, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'response, 105'\n",
            "Warning: Text found before any chapter, section, or subsection: 'variance, 51, 98'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 51'\n",
            "Warning: Text found before any chapter, section, or subsection: 'function of, 50'\n",
            "Warning: Text found before any chapter, section, or subsection: 'variant graph patterns, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'version space, 433'\n",
            "Warning: Text found before any chapter, section, or subsection: 'vertical data format, 260'\n",
            "Warning: Text found before any chapter, section, or subsection: 'example, 260–262'\n",
            "Warning: Text found before any chapter, section, or subsection: 'frequent itemset mining with, 259–262,'\n",
            "Warning: Text found before any chapter, section, or subsection: '272'\n",
            "Warning: Text found before any chapter, section, or subsection: 'video data analysis, 319'\n",
            "Warning: Text found before any chapter, section, or subsection: 'virtual warehouses, 133'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visibility graphs, 537'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visible points, 537'\n",
            "Warning: Text found before any chapter, section, or subsection: 'visual data mining, 602–604, 625'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining process visualization, 603'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data mining result visualization, 603'\n",
            "Warning: Text found before any chapter, section, or subsection: 'data visualization, 602–603'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as discipline integration, 602'\n",
            "Warning: Text found before any chapter, section, or subsection: 'illustrations, 604–607'\n",
            "Warning: Text found before any chapter, section, or subsection: 'interactive, 604, 607'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as mining trend, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Viterbi algorithm, 591'\n",
            "Warning: Text found before any chapter, section, or subsection: 'W'\n",
            "Warning: Text found before any chapter, section, or subsection: 'warehouse database servers, 131'\n",
            "Warning: Text found before any chapter, section, or subsection: 'warehouse refresh software, 151'\n",
            "Warning: Text found before any chapter, section, or subsection: 'waterfall method, 152'\n",
            "Warning: Text found before any chapter, section, or subsection: 'wavelet coefﬁcients, 100'\n",
            "Warning: Text found before any chapter, section, or subsection: 'wavelet transforms, 99, 100–102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'discrete (DWT), 100–102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'for multidimensional data, 102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'on sparse and skewed data, 102'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web directories, 28'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web mining, 597, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'content, 597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'as mining trend, 624'\n",
            "Warning: Text found before any chapter, section, or subsection: 'structure, 597–598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'usage, 598'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web search engines, 28, 523–524'\n",
            "Warning: Text found before any chapter, section, or subsection: 'web-document classiﬁcation, 435'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weight arithmetic mean, 46'\n",
            "Warning: Text found before any chapter, section, or subsection: 'weighted Euclidean distance, 74'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Wikipedia, 597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'WordNet, 597'\n",
            "Warning: Text found before any chapter, section, or subsection: 'working relations, 172'\n",
            "Warning: Text found before any chapter, section, or subsection: 'initial, 168, 169'\n",
            "Warning: Text found before any chapter, section, or subsection: 'World Wide Web (WWW), 1–2, 4, 14'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Worlds-with-Worlds, 63, 64'\n",
            "Warning: Text found before any chapter, section, or subsection: 'wrappers, 127'\n",
            "Warning: Text found before any chapter, section, or subsection: 'Z'\n",
            "Warning: Text found before any chapter, section, or subsection: 'z-score normalization, 114–115'\n",
            "Warning: Text found before any chapter, section, or subsection: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RankBM25 (uses BM25 algorithm), to rank documents."
      ],
      "metadata": {
        "id": "JswAfzsJKIJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBOCWJOt81NO",
        "outputId": "3ab44520-38e5-4cc9-f8cf-39307c45d435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "from transformers import DPRQuestionEncoderTokenizer, DPRQuestionEncoder\n",
        "import torch\n",
        "\n",
        "# Tokenizer and model for DPR-based retrieval\n",
        "tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "\n",
        "# Function to truncate texts to the maximum input length\n",
        "def truncate_text(text, max_length=512):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    if len(tokens) > max_length:\n",
        "        tokens = tokens[:max_length]\n",
        "    return tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "# Tokenization and embeddings for the content using DPR\n",
        "def embed_texts(texts, max_length=512):\n",
        "    truncated_texts = [truncate_text(text, max_length) for text in texts]\n",
        "    inputs = tokenizer(truncated_texts, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.pooler_output\n",
        "    return embeddings\n",
        "\n",
        "# BM25 retrieval\n",
        "def bm25_retrieve(query, corpus):\n",
        "    if not corpus:\n",
        "        return []\n",
        "    bm25 = BM25Okapi([doc.split() for doc in corpus if doc.strip()])\n",
        "    return bm25.get_top_n(query.split(), corpus, n=5)\n",
        "\n",
        "# DPR-based retrieval\n",
        "def dpr_retrieve(query, corpus):\n",
        "    if not corpus:\n",
        "        return []\n",
        "    query_embedding = embed_texts([query])\n",
        "    corpus_embeddings = embed_texts(corpus)\n",
        "    similarities = torch.nn.functional.cosine_similarity(query_embedding, corpus_embeddings)\n",
        "    top_indices = torch.argsort(similarities, descending=True)[:5]\n",
        "    return [corpus[i] for i in top_indices]\n",
        "\n",
        "# Hybrid retrieval combining BM25 and DPR\n",
        "def hybrid_retrieve(query, corpus):\n",
        "    bm25_results = bm25_retrieve(query, corpus)\n",
        "    dpr_results = dpr_retrieve(query, bm25_results)\n",
        "    return dpr_results\n",
        "\n",
        "# Example corpus and query\n",
        "corpus = [node.content for node in tree_indexes[0].children if node.content.strip()]  # Sample corpus from the first textbook's chapters\n",
        "query = \"What is Support Vector Machine?\"\n",
        "\n",
        "# Retrieval\n",
        "retrieved_content = hybrid_retrieve(query, corpus)\n",
        "print(retrieved_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "7bc3dce6f1f641adb50100a64627fa7b",
            "704f908649744e1c99bfd018b5dbfee3",
            "f0e009f1360844d49719549f262b544a",
            "65654d9397f8428faf3c2552b1107a66",
            "1ce16d0bccad45599e4630f2ee1a0b42",
            "127f93d6dbc94ba799a6c812e83c61e4",
            "73ee7cebde8347559a6320ea1dded9a5",
            "7ee60e7cd4694c14a35c4dcf4c58a69a",
            "7ab069c69a2847c5aa1acf00b0a9cf44",
            "1c0a6baa8a824df49b1883d2b94cde5b",
            "118eac7f5b964f6283d6ccb1f2aeb4b3",
            "b4d631bb8052419382d261409fc1a34b",
            "315a57c63d0e45d6af123e5450679a3a",
            "56bc005594584888894b0dc85c1ad924",
            "7d7477d01370427389672081ebe52a83",
            "bc73ae852c8547c18a32428ec0899f99",
            "8792dadd0ffe4da2a19feae310030d96",
            "226ee214047e40d7a5fb917c44974893",
            "640afff7b14f453f8887161a5537ab53",
            "61950895e4a94883823f9cbcc4256d8b",
            "7b60be01e66746ca9d7e0c18f643eac3",
            "fe0e11d9a73f438189f48e662fddde5a",
            "8ea92e692d0e47bd93003f7d73515272",
            "f065a88fbeb84060a5671fe8e1045ac5",
            "f3303c3890894c9086d301169fce13cb",
            "10797d35675742538caa043735f2493f",
            "1e7e94fb05844bbe886a2912f220f2dd",
            "44418593de1640d6aecc3667e9d572ca",
            "c6fbb5f49025401da1079772c0dd89d6",
            "f22e54f9e12a4edba90a7a80b4883491",
            "187d35b065c04737aa52533feb463e73",
            "2df4ae7c5dd6419ca805bab53badc98a",
            "de02d63dab7d477f8de36c13a8412928",
            "e20c5a39a4c14dd9b0837642cdcc1521",
            "4555aded1dc1466f978a693d7bbaaa3a",
            "213b4d07672346c0a51aafa8f3f41029",
            "ec7232dbdb2d43c9af3d5ee766e68f3b",
            "27aca1de3f5f441cba6d50aca0cf95ea",
            "1111b5a342304154b0d761681e0eca62",
            "c3cbcc42062b4fdd83d0997048b8f74f",
            "5f9fbd976fe7427c8d045541f5feb67e",
            "a76d22598bdf4aa597e885f538a02921",
            "ba29d816e5424a439e3f62b3fcd8e60b",
            "2c71d02a9d8240c7bcdbd4c0e536b84a",
            "e7e2b23d55be4449b20aa4a2ef2da39b",
            "c5dbec0e2def4cf79849c8abbcca73ee",
            "28d16cb7c4ea43f381b791d5760858c5",
            "972638a76c824a15a3d355ec60048f36",
            "d0affec5f6b44e6da5ea9b5bca7867ab",
            "3985edecaa9849b8bf9e2944d8bac08a",
            "c9c50320057c42b5a0b0162da2b04f58",
            "f1dc70e7f5cc452da4b9d532763f747a",
            "0d37fa0e0be946ba8aca909537bb0a9c",
            "0ba05bec7f8e4855832fbcc6ce1de6f4",
            "82f52cfbd9094f13a0b6978bd2b2bacf"
          ]
        },
        "id": "siOjK5tSo9Bw",
        "outputId": "187f94f8-9176-4c74-ec3b-d27fda0e9968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bc3dce6f1f641adb50100a64627fa7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d631bb8052419382d261409fc1a34b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ea92e692d0e47bd93003f7d73515272"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e20c5a39a4c14dd9b0837642cdcc1521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e2b23d55be4449b20aa4a2ef2da39b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1. The fundamental idea behind Support Vector Machines is to fit the widest possible “street” between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances. When performing soft margin classification, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few instances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets. 2. After training an SVM, a support vector is any instance located on the “street” (see the previous answer), including its border. The decision boundary is entirely determined by the support vectors. Any instance that is not a support vector (i.e., off the street) has no influence whatsoever; you could remove them, add more instances, or move them around, and as long as they stay off the street they won’t affect the decision boundary. Computing the predictions only involves the support vectors, not the whole training set. 3. SVMs try to fit the largest possible “street” between the classes (see the first answer), so if the training set is not scaled, the SVM will tend to neglect small features (see Figure 5-2). 4. An SVM classifier can output the distance between the test instance and the decision boundary, and you can use this as a confidence score. However, this score cannot be directly converted into an estimation of the class probability. If you set probability=True when creating an SVM in Scikit-Learn, then after training it will calibrate the probabilities using Logistic Regression on the SVM’s scores (trained by an additional five-fold cross-validation on the training data). This will add the predict_proba() and predict_log_proba() methods to the SVM. 5. This question applies only to linear SVMs since kernelized can only use the dual form. The computational complexity of the primal form of the SVM problem is proportional to the number of training instances m, while the computational complexity of the dual form is proportional to a number between m2 and m3. So if there are millions of instances, you should definitely use the primal form, because the dual form will be much too slow. 6. If an SVM classifier trained with an RBF kernel underfits the training set, there might be too much regularization. To decrease it, you need to increase gamma or C (or both). 7. Let’s call the QP parameters for the hard-margin problem H′, f′, A′ and b′ (see “Quadratic Programming”). The QP parameters for the soft- margin problem have m additional parameters (np = n + 1 + m) and m additional constraints (nc = 2m). They can be defined like so: H is equal to H′, plus m columns of 0s on the right and m rows of 0s at the bottom: f is equal to f′ with m additional elements, all equal to the value of the hyperparameter C. b is equal to b′ with m additional elements, all equal to 0. A is equal to A′, with an extra m × m identity matrix Im appended to the right, – Im just below it, and the rest filled with zeros: For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at https://github.com/ageron/handson-ml. ', 'tf.variable_scope(), Sharing Variables-Sharing Variables, Reusing Models from Other Frameworks, Max-Norm Regularization-Max-Norm Regularization, Sharing State Across Sessions Using Resource Containers, Training a Sequence Classifier, Learning to Play Ms. Pac- Man Using Deep Q-Learning tf.zeros(), Construction Phase, Basic RNNs in TensorFlow, Tying Weights truncated backpropagation through time, The Difficulty of Training over Many Time Steps visualizing graph and training curves, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard TensorFlow Serving, One Neural Network per Device tensorflow.contrib, Construction Phase test set, Testing and Validating, Create a Test Set-Create a Test Set, MNIST testing and validating, Testing and Validating-Testing and Validating text attributes, Handling Text and Categorical Attributes-Handling Text and Categorical Attributes TextLineReader, Reading the training data directly from the graph TF-slim, Up and Running with TensorFlow TF.Learn, Up and Running with TensorFlow, Training an MLP with TensorFlow’s High-Level API thermal equilibrium, Boltzmann Machines thread pools (inter-op/intra-op, in TensorFlow, Parallel Execution threshold variable, Sharing Variables-Sharing Variables Tikhonov regularization, Ridge Regression time series data, Recurrent Neural Networks toarray(), Handling Text and Categorical Attributes tolerance hyperparameter, Computational Complexity trainable, Reusing a TensorFlow Model training data, What Is Machine Learning? insufficient quantities, Insufficient Quantity of Training Data irrelevant features, Irrelevant Features loading, Loading Data Directly from the Graph-Other convenience functions nonrepresentative, Nonrepresentative Training Data overfitting, Overfitting the Training Data-Overfitting the Training Data poor quality, Poor-Quality Data underfitting, Underfitting the Training Data training instance, What Is Machine Learning? training models, Model-based learning, Training Models-Exercises learning curves in, Learning Curves-Learning Curves Linear Regression, Training Models, Linear Regression-Mini-batch Gradient Descent Logistic Regression, Logistic Regression-Softmax Regression overview, Training Models-Training Models Polynomial Regression, Training Models, Polynomial Regression- Polynomial Regression training objectives, Training Objective-Training Objective training set, What Is Machine Learning?, Testing and Validating, Discover and Visualize the Data to Gain Insights, Prepare the Data for Machine Learning Algorithms, Training and Evaluating on the Training Set-Training and Evaluating on the Training Set cost function of, Training and Cost Function-Training and Cost Function shuffling, MNIST transfer learning, Reusing Pretrained Layers-Pretraining on an Auxiliary Task (see also pretrained layers reuse) transform(), Data Cleaning, Transformation Pipelines transformation pipelines, Transformation Pipelines-Select and Train a Model transformers, Data Cleaning transformers, custom, Custom Transformers-Custom Transformers transpose(), Static Unrolling Through Time true negative rate (TNR), The ROC Curve true positive rate (TPR), Confusion Matrix, The ROC Curve truncated backpropagation through time, The Difficulty of Training over Many Time Steps tuples, Queues of tuples tying weights, Tying Weights U underfitting, Underfitting the Training Data, Training and Evaluating on the Training Set, Gaussian RBF Kernel univariate regression, Frame the Problem unstack(), Static Unrolling Through Time unsupervised learning, Unsupervised learning-Unsupervised learning anomaly detection, Unsupervised learning association rule learning, Unsupervised learning, Unsupervised learning clustering, Unsupervised learning dimensionality reduction algorithm, Unsupervised learning visualization algorithms, Unsupervised learning unsupervised pretraining, Unsupervised Pretraining-Unsupervised Pretraining, Unsupervised Pretraining Using Stacked Autoencoders- Unsupervised Pretraining Using Stacked Autoencoders upsampling, ResNet utility function, Model-based learning V validation set, Testing and Validating Value Iteration, Markov Decision Processes value_counts(), Take a Quick Look at the Data Structure vanishing gradients, Vanishing/Exploding Gradients Problems (see also gradients, vanishing and exploding) variables, sharing, Sharing Variables-Sharing Variables variable_scope(), Sharing Variables-Sharing Variables variance bias/variance tradeoff, Learning Curves variance preservation, Preserving the Variance-Preserving the Variance variance_scaling_initializer(), Xavier and He Initialization variational autoencoders, Variational Autoencoders-Generating Digits VGGNet, ResNet visual cortex, The Architecture of the Visual Cortex visualization, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard visualization algorithms, Unsupervised learning-Unsupervised learning voice recognition, Convolutional Neural Networks voting classifiers, Voting Classifiers-Voting Classifiers W warmup phase, Asynchronous updates weak learners, Voting Classifiers weight-tying, Tying Weights weights, Construction Phase, Reusing Models from Other Frameworks freezing, Freezing the Lower Layers while_loop(), Dynamic Unrolling Through Time white box models, Making Predictions worker, Multiple Devices Across Multiple Servers worker service, The Master and Worker Services worker_device, Sharding Variables Across Multiple Parameter Servers workspace directory, Get the Data-Download the Data X Xavier initialization, Vanishing/Exploding Gradients Problems-Xavier and He Initialization Y YouTube, Introduction to Artificial Neural Networks Z zero padding, Convolutional Layer, TensorFlow Implementation About the Author Aurélien Géron is a Machine Learning consultant. A former Googler, he led the YouTube video classification team from 2013 to 2016. He was also a founder and CTO of Wifirst from 2002 to 2012, a leading Wireless ISP in France; and a founder and CTO of Polyconseil in 2001, the firm that now manages the electric car sharing service Autolib’. Before this he worked as an engineer in a variety of domains: finance (JP Morgan and Société Générale), defense (Canada’s DOD), and healthcare (blood transfusion). He published a few technical books (on C++, WiFi, and internet architectures), and was a Computer Science lecturer in a French engineering school. A few fun facts: he taught his three children to count in binary with their fingers (up to 1023), he studied microbiology and evolutionary genetics before going into software engineering, and his parachute didn’t open on the second jump. Colophon The animal on the cover of Hands-On Machine Learning with Scikit-Learn and TensorFlow is the far eastern fire salamander (Salamandra infraimmaculata), an amphibian found in the Middle East. They have black skin featuring large yellow spots on their back and head. These spots are a warning coloration meant to keep predators at bay. Full-grown salamanders can be over a foot in length. Far eastern fire salamanders live in subtropical shrubland and forests near rivers or other freshwater bodies. They spend most of their life on land, but lay their eggs in the water. They subsist mostly on a diet of insects, worms, and small crustaceans, but occasionally eat other salamanders. Males of the species have been known to live up to 23 years, while females can live up to 21 years. Although not yet endangered, the far eastern fire salamander population is in decline. Primary threats include damming of rivers (which disrupts the salamander’s breeding) and pollution. They are also threatened by the recent introduction of predatory fish, such as the mosquitofish. These fish were intended to control the mosquito population, but they also feed on young salamanders. Many of the animals on O’Reilly covers are endangered; all of them are important to the world. To learn more about how you can help, go to animals.oreilly.com. The cover image is from Wood’s Illustrated Natural History. The cover fonts are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu Mono. Preface The Machine Learning Tsunami Machine Learning in Your Projects Objective and Approach Prerequisites Roadmap Other Resources Conventions Used in This Book Using Code Examples O’Reilly Safari How to Contact Us Acknowledgments I. The Fundamentals of Machine Learning 1. The Machine Learning Landscape What Is Machine Learning? Why Use Machine Learning? Types of Machine Learning Systems Supervised/Unsupervised Learning Batch and Online Learning Instance-Based Versus Model-Based Learning Main Challenges of Machine Learning Insufficient Quantity of Training Data Nonrepresentative Training Data Poor-Quality Data Irrelevant Features Overfitting the Training Data Underfitting the Training Data Stepping Back Testing and Validating Exercises 2. End-to-End Machine Learning Project Working with Real Data Look at the Big Picture Frame the Problem Select a Performance Measure Check the Assumptions Get the Data Create the Workspace Download the Data Take a Quick Look at the Data Structure Create a Test Set Discover and Visualize the Data to Gain Insights Visualizing Geographical Data Looking for Correlations Experimenting with Attribute Combinations Prepare the Data for Machine Learning Algorithms Data Cleaning Handling Text and Categorical Attributes Custom Transformers Feature Scaling Transformation Pipelines Select and Train a Model Training and Evaluating on the Training Set Better Evaluation Using Cross-Validation Fine-Tune Your Model Grid Search Randomized Search Ensemble Methods Analyze the Best Models and Their Errors Evaluate Your System on the Test Set Launch, Monitor, and Maintain Your System Try It Out! Exercises 3. Classification MNIST Training a Binary Classifier Performance Measures Measuring Accuracy Using Cross-Validation Confusion Matrix Precision and Recall Precision/Recall Tradeoff The ROC Curve Multiclass Classification Error Analysis Multilabel Classification Multioutput Classification Exercises 4. Training Models Linear Regression The Normal Equation Computational Complexity Gradient Descent Batch Gradient Descent Stochastic Gradient Descent Mini-batch Gradient Descent Polynomial Regression Learning Curves Regularized Linear Models Ridge Regression Lasso Regression Elastic Net Early Stopping Logistic Regression Estimating Probabilities Training and Cost Function Decision Boundaries Softmax Regression Exercises 5. Support Vector Machines Linear SVM Classification Soft Margin Classification Nonlinear SVM Classification Polynomial Kernel Adding Similarity Features Gaussian RBF Kernel Computational Complexity SVM Regression Under the Hood Decision Function and Predictions Training Objective Quadratic Programming The Dual Problem Kernelized SVM Online SVMs Exercises 6. Decision Trees Training and Visualizing a Decision Tree Making Predictions Estimating Class Probabilities The CART Training Algorithm Computational Complexity Gini Impurity or Entropy? Regularization Hyperparameters Regression Instability Exercises 7. Ensemble Learning and Random Forests Voting Classifiers Bagging and Pasting Bagging and Pasting in Scikit-Learn Out-of-Bag Evaluation Random Patches and Random Subspaces Random Forests Extra-Trees Feature Importance Boosting AdaBoost Gradient Boosting Stacking Exercises 8. Dimensionality Reduction The Curse of Dimensionality Main Approaches for Dimensionality Reduction Projection Manifold Learning PCA Preserving the Variance Principal Components Projecting Down to d Dimensions Using Scikit-Learn Explained Variance Ratio Choosing the Right Number of Dimensions PCA for Compression Incremental PCA Randomized PCA Kernel PCA Selecting a Kernel and Tuning Hyperparameters LLE Other Dimensionality Reduction Techniques Exercises II. Neural Networks and Deep Learning 9. Up and Running with TensorFlow Installation Creating Your First Graph and Running It in a Session Managing Graphs Lifecycle of a Node Value Linear Regression with TensorFlow Implementing Gradient Descent Manually Computing the Gradients Using autodiff Using an Optimizer Feeding Data to the Training Algorithm Saving and Restoring Models Visualizing the Graph and Training Curves Using TensorBoard Name Scopes Modularity Sharing Variables Exercises 10. Introduction to Artificial Neural Networks From Biological to Artificial Neurons Biological Neurons Logical Computations with Neurons The Perceptron Multi-Layer Perceptron and Backpropagation Training an MLP with TensorFlow’s High-Level API Training a DNN Using Plain TensorFlow Construction Phase Execution Phase Using the Neural Network Fine-Tuning Neural Network Hyperparameters Number of Hidden Layers Number of Neurons per Hidden Layer Activation Functions Exercises 11. Training Deep Neural Nets Vanishing/Exploding Gradients Problems Xavier and He Initialization Nonsaturating Activation Functions Batch Normalization Gradient Clipping Reusing Pretrained Layers Reusing a TensorFlow Model Reusing Models from Other Frameworks Freezing the Lower Layers Caching the Frozen Layers Tweaking, Dropping, or Replacing the Upper Layers Model Zoos Unsupervised Pretraining Pretraining on an Auxiliary Task Faster Optimizers Momentum optimization Nesterov Accelerated Gradient AdaGrad RMSProp Adam Optimization Learning Rate Scheduling Avoiding Overfitting Through Regularization Early Stopping ℓ1 and ℓ2 Regularization Dropout Max-Norm Regularization Data Augmentation Practical Guidelines Exercises 12. Distributing TensorFlow Across Devices and Servers Multiple Devices on a Single Machine Installation Managing the GPU RAM Placing Operations on Devices Parallel Execution Control Dependencies Multiple Devices Across Multiple Servers Opening a Session The Master and Worker Services Pinning Operations Across Tasks Sharding Variables Across Multiple Parameter Servers Sharing State Across Sessions Using Resource Containers Asynchronous Communication Using TensorFlow Queues Loading Data Directly from the Graph Parallelizing Neural Networks on a TensorFlow Cluster One Neural Network per Device In-Graph Versus Between-Graph Replication Model Parallelism Data Parallelism Exercises 13. Convolutional Neural Networks The Architecture of the Visual Cortex Convolutional Layer Filters Stacking Multiple Feature Maps TensorFlow Implementation Memory Requirements Pooling Layer CNN Architectures LeNet-5 AlexNet GoogLeNet ResNet Exercises 14. Recurrent Neural Networks Recurrent Neurons Memory Cells Input and Output Sequences Basic RNNs in TensorFlow Static Unrolling Through Time Dynamic Unrolling Through Time Handling Variable Length Input Sequences Handling Variable-Length Output Sequences Training RNNs Training a Sequence Classifier Training to Predict Time Series Creative RNN Deep RNNs Distributing a Deep RNN Across Multiple GPUs Applying Dropout The Difficulty of Training over Many Time Steps LSTM Cell Peephole Connections GRU Cell Natural Language Processing Word Embeddings An Encoder–Decoder Network for Machine Translation Exercises 15. Autoencoders Efficient Data Representations Performing PCA with an Undercomplete Linear Autoencoder Stacked Autoencoders TensorFlow Implementation Tying Weights Training One Autoencoder at a Time Visualizing the Reconstructions Visualizing Features Unsupervised Pretraining Using Stacked Autoencoders Denoising Autoencoders TensorFlow Implementation Sparse Autoencoders TensorFlow Implementation Variational Autoencoders Generating Digits Other Autoencoders Exercises 16. Reinforcement Learning Learning to Optimize Rewards Policy Search Introduction to OpenAI Gym Neural Network Policies Evaluating Actions: The Credit Assignment Problem Policy Gradients Markov Decision Processes Temporal Difference Learning and Q-Learning Exploration Policies Approximate Q-Learning Learning to Play Ms. Pac-Man Using Deep Q-Learning Exercises Thank You! A. Exercise Solutions ', '1. If you have a training set with millions of features you can use Stochastic Gradient Descent or Mini-batch Gradient Descent, and perhaps Batch Gradient Descent if the training set fits in memory. But you cannot use the Normal Equation because the computational complexity grows quickly (more than quadratically) with the number of features. 2. If the features in your training set have very different scales, the cost function will have the shape of an elongated bowl, so the Gradient Descent algorithms will take a long time to converge. To solve this you should scale the data before training the model. Note that the Normal Equation will work just fine without scaling. 3. Gradient Descent cannot get stuck in a local minimum when training a Logistic Regression model because the cost function is convex.1 4. If the optimization problem is convex (such as Linear Regression or Logistic Regression), and assuming the learning rate is not too high, then all Gradient Descent algorithms will approach the global optimum and end up producing fairly similar models. However, unless you gradually reduce the learning rate, Stochastic GD and Mini-batch GD will never truly converge; instead, they will keep jumping back and forth around the global optimum. This means that even if you let them run for a very long time, these Gradient Descent algorithms will produce slightly different models. 5. If the validation error consistently goes up after every epoch, then one possibility is that the learning rate is too high and the algorithm is diverging. If the training error also goes up, then this is clearly the problem and you should reduce the learning rate. However, if the training error is not going up, then your model is overfitting the training set and you should stop training. 6. Due to their random nature, neither Stochastic Gradient Descent nor Mini-batch Gradient Descent is guaranteed to make progress at every single training iteration. So if you immediately stop training when the validation error goes up, you may stop much too early, before the optimum is reached. A better option is to save the model at regular intervals, and when it has not improved for a long time (meaning it will probably never beat the record), you can revert to the best saved model. 7. Stochastic Gradient Descent has the fastest training iteration since it considers only one training instance at a time, so it is generally the first to reach the vicinity of the global optimum (or Mini-batch GD with a very small mini-batch size). However, only Batch Gradient Descent will actually converge, given enough training time. As mentioned, Stochastic GD and Mini-batch GD will bounce around the optimum, unless you gradually reduce the learning rate. 8. If the validation error is much higher than the training error, this is likely because your model is overfitting the training set. One way to try to fix this is to reduce the polynomial degree: a model with fewer degrees of freedom is less likely to overfit. Another thing you can try is to regularize the model — for example, by adding an ℓ2 penalty (Ridge) or an ℓ1 penalty (Lasso) to the cost function. This will also reduce the degrees of freedom of the model. Lastly, you can try to increase the size of the training set. 9. If both the training error and the validation error are almost equal and fairly high, the model is likely underfitting the training set, which means it has a high bias. You should try reducing the regularization hyperparameter α. 10. Let’s see: A model with some regularization typically performs better than a model without any regularization, so you should generally prefer Ridge Regression over plain Linear Regression.2 Lasso Regression uses an ℓ1 penalty, which tends to push the weights down to exactly zero. This leads to sparse models, where all weights are zero except for the most important weights. This is a way to perform feature selection automatically, which is good if you suspect that only a few features actually matter. When you are not sure, you should prefer Ridge Regression. Elastic Net is generally preferred over Lasso since Lasso may behave erratically in some cases (when several features are strongly correlated or when there are more features than training instances). However, it does add an extra hyperparameter to tune. If you just want Lasso without the erratic behavior, you can just use Elastic Net with an l1_ratio close to 1. 11. If you want to classify pictures as outdoor/indoor and daytime/nighttime, since these are not exclusive classes (i.e., all four combinations are possible) you should train two Logistic Regression classifiers. 12. See the Jupyter notebooks available at https://github.com/ageron/handson-ml. ', '1. The depth of a well-balanced binary tree containing m leaves is equal to log2(m)3, rounded up. A binary Decision Tree (one that makes only binary decisions, as is the case of all trees in Scikit-Learn) will end up more or less well balanced at the end of training, with one leaf per training instance if it is trained without restrictions. Thus, if the training set contains one million instances, the Decision Tree will have a depth of log2(106) ≈ 20 (actually a bit more since the tree will generally not be perfectly well balanced). 2. A node’s Gini impurity is generally lower than its parent’s. This is ensured by the CART training algorithm’s cost function, which splits each node in a way that minimizes the weighted sum of its children’s Gini impurities. However, if one child is smaller than the other, it is possible for it to have a higher Gini impurity than its parent, as long as this increase is more than compensated for by a decrease of the other child’s impurity. For example, consider a node containing four instances of class A and 1 of class B. Its Gini impurity is = 0.32. Now suppose the dataset is one-dimensional and the instances are lined up in the following order: A, B, A, A, A. You can verify that the algorithm will split this node after the second instance, producing one child node with instances A, B, and the other child node with instances A, A, A. The first child node’s Gini impurity is = 0.5, which is higher than its parent. This is compensated for by the fact that the other node is pure, so the overall weighted Gini impurity is 0.5 + = 0.2 , which is lower than the parent’s Gini impurity. 3. If a Decision Tree is overfitting the training set, it may be a good idea to decrease max_depth, since this will constrain the model, regularizing it. 4. Decision Trees don’t care whether or not the training data is scaled or centered; that’s one of the nice things about them. So if a Decision Tree underfits the training set, scaling the input features will just be a waste of time. 5. The computational complexity of training a Decision Tree is O(n × m log(m)). So if you multiply the training set size by 10, the training time will be multiplied by K = (n × 10m × log(10m)) / (n × m × log(m)) = 10 × log(10m) / log(m). If m = 106, then K ≈ 11.7, so you can expect the training time to be roughly 11.7 hours. 6. Presorting the training set speeds up training only if the dataset is smaller than a few thousand instances. If it contains 100,000 instances, setting presort=True will considerably slow down training. For the solutions to exercises 7 and 8, please see the Jupyter notebooks available at https://github.com/ageron/handson-ml. ', \"1. Reinforcement Learning is an area of Machine Learning aimed at creating agents capable of taking actions in an environment in a way that maximizes rewards over time. There are many differences between RL and regular supervised and unsupervised learning. Here are a few: In supervised and unsupervised learning, the goal is generally to find patterns in the data. In Reinforcement Learning, the goal is to find a good policy. Unlike in supervised learning, the agent is not explicitly given the “right” answer. It must learn by trial and error. Unlike in unsupervised learning, there is a form of supervision, through rewards. We do not tell the agent how to perform the task, but we do tell it when it is making progress or when it is failing. A Reinforcement Learning agent needs to find the right balance between exploring the environment, looking for new ways of getting rewards, and exploiting sources of rewards that it already knows. In contrast, supervised and unsupervised learning systems generally don’t need to worry about exploration; they just feed on the training data they are given. In supervised and unsupervised learning, training instances are typically independent (in fact, they are generally shuffled). In Reinforcement Learning, consecutive observations are generally not independent. An agent may remain in the same region of the environment for a while before it moves on, so consecutive observations will be very correlated. In some cases a replay memory is used to ensure that the training algorithm gets fairly independent observations. 2. Here are a few possible applications of Reinforcement Learning, other than those mentioned in Chapter 16: Music personalization The environment is a user’s personalized web radio. The agent is the software deciding what song to play next for that user. Its possible actions are to play any song in the catalog (it must try to choose a song the user will enjoy) or to play an advertisement (it must try to choose an ad that the user will be interested in). It gets a small reward every time the user listens to a song, a larger reward every time the user listens to an ad, a negative reward when the user skips a song or an ad, and a very negative reward if the user leaves. Marketing The environment is your company’s marketing department. The agent is the software that defines which customers a mailing campaign should be sent to, given their profile and purchase history (for each customer it has two possible actions: send or don’t send). It gets a negative reward for the cost of the mailing campaign, and a positive reward for estimated revenue generated from this campaign. Product delivery Let the agent control a fleet of delivery trucks, deciding what they should pick up at the depots, where they should go, what they should drop off, and so on. They would get positive rewards for each product delivered on time, and negative rewards for late deliveries. 3. When estimating the value of an action, Reinforcement Learning algorithms typically sum all the rewards that this action led to, giving more weight to immediate rewards, and less weight to later rewards (considering that an action has more influence on the near future than on the distant future). To model this, a discount rate is typically applied at each time step. For example, with a discount rate of 0.9, a reward of 100 that is received two time steps later is counted as only 0.92 × 100 = 81 when you are estimating the value of the action. You can think of the discount rate as a measure of how much the future is valued relative to the present: if it is very close to 1, then the future is valued almost as much as the present. If it is close to 0, then only immediate rewards matter. Of course, this impacts the optimal policy tremendously: if you value the future, you may be willing to put up with a lot of immediate pain for the prospect of eventual rewards, while if you don’t value the future, you will just grab any immediate reward you can find, never investing in the future. 4. To measure the performance of a Reinforcement Learning agent, you can simply sum up the rewards it gets. In a simulated environment, you can run many episodes and look at the total rewards it gets on average (and possibly look at the min, max, standard deviation, and so on). 5. The credit assignment problem is the fact that when a Reinforcement Learning agent receives a reward, it has no direct way of knowing which of its previous actions contributed to this reward. It typically occurs when there is a large delay between an action and the resulting rewards (e.g., during a game of Atari’s Pong, there may be a few dozen time steps between the moment the agent hits the ball and the moment it wins the point). One way to alleviate it is to provide the agent with shorter-term rewards, when possible. This usually requires prior knowledge about the task. For example, if we want to build an agent that will learn to play chess, instead of giving it a reward only when it wins the game, we could give it a reward every time it captures one of the opponent’s pieces. 6. An agent can often remain in the same region of its environment for a while, so all of its experiences will be very similar for that period of time. This can introduce some bias in the learning algorithm. It may tune its policy for this region of the environment, but it will not perform well as soon as it moves out of this region. To solve this problem, you can use a replay memory; instead of using only the most immediate experiences for learning, the agent will learn based on a buffer of its past experiences, recent and not so recent (perhaps this is why we dream at night: to replay our experiences of the day and better learn from them?). 7. An off-policy RL algorithm learns the value of the optimal policy (i.e., the sum of discounted rewards that can be expected for each state if the agent acts optimally), independently of how the agent actually acts. Q- Learning is a good example of such an algorithm. In contrast, an on- policy algorithm learns the value of the policy that the agent actually executes, including both exploration and exploitation. For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at https://github.com/ageron/handson-ml. If you draw a straight line between any two points on the curve, the line never crosses the curve. Moreover, the Normal Equation requires computing the inverse of a matrix, but that matrix is not always invertible. In contrast, the matrix for Ridge Regression is always invertible. log2 is the binary log, log2(m) = log(m) / log(2). When the values to predict can vary by many orders of magnitude, then you may want to predict the logarithm of the target value rather than the target value directly. Simply computing the exponential of the neural network’s output will give you the estimated value (since exp(log v) = v). In Chapter 11 we discuss many techniques that introduce additional hyperparameters: type of weight initialization, activation function hyperparameters (e.g., amount of leak in leaky ReLU), Gradient Clipping threshold, type of optimizer and its hyperparameters (e.g., the momentum hyperparameter when using a MomentumOptimizer), type of regularization for each layer, and the regularization hyperparameters (e.g., dropout rate when using dropout) and so on. 1 2 3 4 5 Appendix B. Machine Learning Project Checklist This checklist can guide you through your Machine Learning projects. There are eight main steps: 1. Frame the problem and look at the big picture. 2. Get the data. 3. Explore the data to gain insights. 4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms. 5. Explore many different models and short-list the best ones. 6. Fine-tune your models and combine them into a great solution. 7. Present your solution. 8. Launch, monitor, and maintain your system. Obviously, you should feel free to adapt this checklist to your needs. Frame the Problem and Look at the Big Picture 1. Define the objective in business terms. 2. How will your solution be used? 3. What are the current solutions/workarounds (if any)? 4. How should you frame this problem (supervised/unsupervised, online/offline, etc.)? 5. How should performance be measured? 6. Is the performance measure aligned with the business objective? 7. What would be the minimum performance needed to reach the business objective? 8. What are comparable problems? Can you reuse experience or tools? 9. Is human expertise available? 10. How would you solve the problem manually? 11. List the assumptions you (or others) have made so far. 12. Verify assumptions if possible. Get the Data Note: automate as much as possible so you can easily get fresh data. 1. List the data you need and how much you need. 2. Find and document where you can get that data. 3. Check how much space it will take. 4. Check legal obligations, and get authorization if necessary. 5. Get access authorizations. 6. Create a workspace (with enough storage space). 7. Get the data. 8. Convert the data to a format you can easily manipulate (without changing the data itself). 9. Ensure sensitive information is deleted or protected (e.g., anonymized). 10. Check the size and type of data (time series, sample, geographical, etc.). 11. Sample a test set, put it aside, and never look at it (no data snooping!). Explore the Data Note: try to get insights from a field expert for these steps. 1. Create a copy of the data for exploration (sampling it down to a manageable size if necessary). 2. Create a Jupyter notebook to keep a record of your data exploration. 3. Study each attribute and its characteristics: Name Type (categorical, int/float, bounded/unbounded, text, structured, etc.) % of missing values Noisiness and type of noise (stochastic, outliers, rounding errors, etc.) Possibly useful for the task? Type of distribution (Gaussian, uniform, logarithmic, etc.) 4. For supervised learning tasks, identify the target attribute(s). 5. Visualize the data. 6. Study the correlations between attributes. 7. Study how you would solve the problem manually. 8. Identify the promising transformations you may want to apply. 9. Identify extra data that would be useful (go back to “Get the Data”). 10. Document what you have learned. Prepare the Data Notes: Work on copies of the data (keep the original dataset intact). Write functions for all data transformations you apply, for five reasons: So you can easily prepare the data the next time you get a fresh dataset So you can apply these transformations in future projects To clean and prepare the test set To clean and prepare new data instances once your solution is live To make it easy to treat your preparation choices as hyperparameters 1. Data cleaning: Fix or remove outliers (optional). Fill in missing values (e.g., with zero, mean, median…) or drop their rows (or columns). 2. Feature selection (optional): Drop the attributes that provide no useful information for the task. 3. Feature engineering, where appropriate: Discretize continuous features. Decompose features (e.g., categorical, date/time, etc.). Add promising transformations of features (e.g., log(x), sqrt(x), x^2, etc.). Aggregate features into promising new features. 4. Feature scaling: standardize or normalize features. Short-List Promising Models Notes: If the data is huge, you may want to sample smaller training sets so you can train many different models in a reasonable time (be aware that this penalizes complex models such as large neural nets or Random Forests). Once again, try to automate these steps as much as possible. 1. Train many quick and dirty models from different categories (e.g., linear, naive Bayes, SVM, Random Forests, neural net, etc.) using standard parameters. 2. Measure and compare their performance. For each model, use N-fold cross-validation and compute the mean and standard deviation of the performance measure on the N folds. 3. Analyze the most significant variables for each algorithm. 4. Analyze the types of errors the models make. What data would a human have used to avoid these errors? 5. Have a quick round of feature selection and engineering. 6. Have one or two more quick iterations of the five previous steps. 7. Short-list the top three to five most promising models, preferring models that make different types of errors. Fine-Tune the System Notes: You will want to use as much data as possible for this step, especially as you move toward the end of fine-tuning. As always automate what you can. 1. Fine-tune the hyperparameters using cross-validation. Treat your data transformation choices as hyperparameters, especially when you are not sure about them (e.g., should I replace missing values with zero or with the median value? Or just drop the rows?). Unless there are very few hyperparameter values to explore, prefer random search over grid search. If training is very long, you may prefer a Bayesian optimization approach (e.g., using Gaussian process priors, as described by Jasper Snoek, Hugo Larochelle, and Ryan Adams).1 2. Try Ensemble methods. Combining your best models will often perform better than running them individually. 3. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error. WARNING Don’t tweak your model after measuring the generalization error: you would just start overfitting the test set. Present Your Solution 1. Document what you have done. 2. Create a nice presentation. Make sure you highlight the big picture first. 3. Explain why your solution achieves the business objective. 4. Don’t forget to present interesting points you noticed along the way. Describe what worked and what did not. List your assumptions and your system’s limitations. 5. Ensure your key findings are communicated through beautiful visualizations or easy-to-remember statements (e.g., “the median income is the number-one predictor of housing prices”). Launch! 1. Get your solution ready for production (plug into production data inputs, write unit tests, etc.). 2. Write monitoring code to check your system’s live performance at regular intervals and trigger alerts when it drops. Beware of slow degradation too: models tend to “rot” as data evolves. Measuring performance may require a human pipeline (e.g., via a crowdsourcing service). Also monitor your inputs’ quality (e.g., a malfunctioning sensor sending random values, or another team’s output becoming stale). This is particularly important for online learning systems. 3. Retrain your models on a regular basis on fresh data (automate as much as possible). “Practical Bayesian Optimization of Machine Learning Algorithms,” J. Snoek, H. Larochelle, R. Adams (2012). 1 Appendix C. SVM Dual Problem To understand duality, you first need to understand the Lagrange multipliers method. The general idea is to transform a constrained optimization objective into an unconstrained one, by moving the constraints into the objective function. Let’s look at a simple example. Suppose you want to find the values of x and y that minimize the function f(x,y) = x2 + 2y, subject to an equality constraint: 3x + 2y + 1 = 0. Using the Lagrange multipliers method, we start by defining a new function called the Lagrangian (or Lagrange function): g(x, y, α) = f(x, y) – α(3x + 2y + 1). Each constraint (in this case just one) is subtracted from the original objective, multiplied by a new variable called a Lagrange multiplier. Joseph-Louis Lagrange showed that if is a solution to the constrained optimization problem, then there must exist an  such that is a stationary point of the Lagrangian (a stationary point is a point where all partial derivatives are equal to zero). In other words, we can compute the partial derivatives of g(x, y, α) with regards to x, y, and α; we can find the points where these derivatives are all equal to zero; and the solutions to the constrained optimization problem (if they exist) must be among these stationary points. In this example the partial derivatives are: When all these partial derivatives are equal to 0, we find that , from which we can easily find that , , and . This is the only stationary point, and as it respects the constraint, it must be the solution to the constrained optimization problem. However, this method applies only to equality constraints. Fortunately, under some regularity conditions (which are respected by the SVM objectives), this method can be generalized to inequality constraints as well (e.g., 3x + 2y + 1 ≥ 0). The generalized Lagrangian for the hard margin problem is given by Equation C-1, where the α(i) variables are called the Karush–Kuhn–Tucker (KKT) multipliers, and they must be greater or equal to zero. Equation C-1. Generalized Lagrangian for the hard margin problem Just like with the Lagrange multipliers method, you can compute the partial derivatives and locate the stationary points. If there is a solution, it will necessarily be among the stationary points that respect the KKT conditions: Respect the problem’s constraints: , Verify , Either or the ith constraint must be an active constraint, meaning it must hold by equality: . This condition is called the complementary slackness condition. It implies that either or the ith instance lies on the boundary (it is a support vector). Note that the KKT conditions are necessary conditions for a stationary point to be a solution of the constrained optimization problem. Under some conditions, they are also sufficient conditions. Luckily, the SVM optimization problem happens to meet these conditions, so any stationary point that meets the KKT conditions is guaranteed to be a solution to the constrained optimization problem. We can compute the partial derivatives of the generalized Lagrangian with regards to w and b with Equation C-2. Equation C-2. Partial derivatives of the generalized Lagrangian When these partial derivatives are equal to 0, we have Equation C-3. Equation C-3. Properties of the stationary points If we plug these results into the definition of the generalized Lagrangian, some terms disappear and we find Equation C-4. Equation C-4. Dual form of the SVM problem The goal is now to find the vector  that minimizes this function, with for all instances. This constrained optimization problem is the dual problem we were looking for. Once you find the optimal , you can compute using the first line of Equation C-3. To compute , you can use the fact that a support vector verifies t(i)(wT · x(i) + b) = 1, so if the kth instance is a support vector (i.e., αk > 0), you can use it to compute . However, it is often prefered to compute the average over all support vectors to get a more stable and precise value, as in Equation C-5. Equation C-5. Bias term estimation using the dual form Appendix D. Autodiff This appendix explains how TensorFlow’s autodiff feature works, and how it compares to other solutions. Suppose you define a function f(x,y) = x2y + y + 2, and you need its partial derivatives and , typically to perform Gradient Descent (or some other optimization algorithm). Your main options are manual differentiation, symbolic differentiation, numerical differentiation, forward-mode autodiff, and finally reverse-mode autodiff. TensorFlow implements this last option. Let’s go through each of these options. Manual Differentiation The first approach is to pick up a pencil and a piece of paper and use your calculus knowledge to derive the partial derivatives manually. For the function f(x,y) just defined, it is not too hard; you just need to use five rules: The derivative of a constant is 0. The derivative of λx is λ (where λ is a constant). The derivative of xλ is λxλ – 1, so the derivative of x2 is 2x. The derivative of a sum of functions is the sum of these functions’ derivatives. The derivative of λ times a function is λ times its derivative. From these rules, you can derive Equation D-1: Equation D-1. Partial derivatives of f(x,y) This approach can become very tedious for more complex functions, and you run the risk of making mistakes. The good news is that deriving the mathematical equations for the partial derivatives like we just did can be automated, through a process called symbolic differentiation. Symbolic Differentiation Figure D-1 shows how symbolic differentiation works on an even simpler function, g(x,y) = 5 + xy. The graph for that function is represented on the left. After symbolic differentiation, we get the graph on the right, which represents the partial derivative (we could similarly obtain the partial derivative with regards to y). Figure D-1. Symbolic differentiation The algorithm starts by getting the partial derivative of the leaf nodes. The constant node (5) returns the constant 0, since the derivative of a constant is always 0. The variable x returns the constant 1 since , and the variable y returns the constant 0 since (if we were looking for the partial derivative with regards to y, it would be the reverse). Now we have all we need to move up the graph to the multiplication node in function g. Calculus tells us that the derivative of the product of two functions u and v is . We can therefore construct a large part of the graph on the right, representing 0 × x + y × 1. Finally, we can go up to the addition node in function g. As mentioned, the derivative of a sum of functions is the sum of these functions’ derivatives. So we just need to create an addition node and connect it to the parts of the graph we have already computed. We get the correct partial derivative: . However, it can be simplified (a lot). A few trivial pruning steps can be applied to this graph to get rid of all unnecessary operations, and we get a much smaller graph with just one node: . In this case, simplification is fairly easy, but for a more complex function, symbolic differentiation can produce a huge graph that may be tough to simplify and lead to suboptimal performance. Most importantly, symbolic differentiation cannot deal with functions defined with arbitrary code — for example, the following function discussed in Chapter 9: def my_func(a, b): z = 0 for i in range(100): z = a * np.cos(z + i) + z * np.sin(b - i) return z Numerical Differentiation The simplest solution is to compute an approximation of the derivatives, numerically. Recall that the derivative h′(x0) of a function h(x) at a point x0 is the slope of the function at that point, or more precisely Equation D-2. Equation D-2. Derivative of a function h(x) at point x0 So if we want to calculate the partial derivative of f(x,y) with regards to x, at x = 3 and y = 4, we can simply compute f(3 + ϵ, 4) – f(3, 4) and divide the result by ϵ, using a very small value for ϵ. That’s exactly what the following code does: def f(x, y): return x**2*y + y + 2 def derivative(f, x, y, x_eps, y_eps): return (f(x + x_eps, y + y_eps) - f(x, y)) / (x_eps + y_eps) df_dx = derivative(f, 3, 4, 0.00001, 0) df_dy = derivative(f, 3, 4, 0, 0.00001) Unfortunately, the result is imprecise (and it gets worse for more complex functions). The correct results are respectively 24 and 10, but instead we get: >>> print(df_dx) 24.000039999805264 >>> print(df_dy) 10.000000000331966 Notice that to compute both partial derivatives, we have to call f() at least three times (we called it four times in the preceding code, but it could be optimized). If there were 1,000 parameters, we would need to call f() at least 1,001 times. When you are dealing with large neural networks, this makes numerical differentiation way too inefficient. However, numerical differentiation is so simple to implement that it is a great tool to check that the other methods are implemented correctly. For example, if it disagrees with your manually derived function, then your function probably contains a mistake. Forward-Mode Autodiff Forward-mode autodiff is neither numerical differentiation nor symbolic differentiation, but in some ways it is their love child. It relies on dual numbers, which are (weird but fascinating) numbers of the form a + bϵ where a and b are real numbers and ϵ is an infinitesimal number such that ϵ2 = 0 (but ϵ ≠ 0). You can think of the dual number 42 + 24ϵ as something akin to 42.0000⋯000024 with an infinite number of 0s (but of course this is simplified just to give you some idea of what dual numbers are). A dual number is represented in memory as a pair of floats. For example, 42 + 24ϵ is represented by the pair (42.0, 24.0). Dual numbers can be added, multiplied, and so on, as shown in Equation D-3. Equation D-3. A few operations with dual numbers Most importantly, it can be shown that h(a + bϵ) = h(a) + b × h′(a)ϵ, so computing h(a + ϵ) gives you both h(a) and the derivative h′(a) in just one shot. Figure D-2 shows how forward-mode autodiff computes the partial derivative of f(x,y) with regards to x at x = 3 and y = 4. All we need to do is compute f(3 + ϵ, 4); this will output a dual number whose first component is equal to f(3, 4) and whose second component is equal to . Figure D-2. Forward-mode autodiff To compute we would have to go through the graph again, but this time with x = 3 and y = 4 + ϵ. So forward-mode autodiff is much more accurate than numerical differentiation, but it suffers from the same major flaw: if there were 1,000 parameters, it would require 1,000 passes through the graph to compute all the partial derivatives. This is where reverse-mode autodiff shines: it can compute all of them in just two passes through the graph. Reverse-Mode Autodiff Reverse-mode autodiff is the solution implemented by TensorFlow. It first goes through the graph in the forward direction (i.e., from the inputs to the output) to compute the value of each node. Then it does a second pass, this time in the reverse direction (i.e., from the output to the inputs) to compute all the partial derivatives. Figure D-3 represents the second pass. During the first pass, all the node values were computed, starting from x = 3 and y = 4. You can see those values at the bottom right of each node (e.g., x × x = 9). The nodes are labeled n1 to n7 for clarity. The output node is n7: f(3,4) = n7 = 42. Figure D-3. Reverse-mode autodiff The idea is to gradually go down the graph, computing the partial derivative of f(x,y) with regards to each consecutive node, until we reach the variable nodes. For this, reverse-mode autodiff relies heavily on the chain rule, shown in Equation D-4. Equation D-4. Chain rule Since n7 is the output node, f = n7 so trivially . Let’s continue down the graph to n5: how much does f vary when n5 varies? The answer is . We already know that , so all we need is . Since n7 simply performs the sum n5 + n6, we find that , so . Now we can proceed to node n4: how much does f vary when n4 varies? The answer is . Since n5 = n4 × n2, we find that , so . The process continues until we reach the bottom of the graph. At that point we will have calculated all the partial derivatives of f(x,y) at the point x = 3 and y = 4. In this example, we find and . Sounds about right! Reverse-mode autodiff is a very powerful and accurate technique, especially when there are many inputs and few outputs, since it requires only one forward pass plus one reverse pass per output to compute all the partial derivatives for all outputs with regards to all the inputs. Most importantly, it can deal with functions defined by arbitrary code. It can also handle functions that are not entirely differentiable, as long as you ask it to compute the partial derivatives at points that are differentiable. TIP If you implement a new type of operation in TensorFlow and you want to make it compatible with autodiff, then you need to provide a function that builds a subgraph to compute its partial derivatives with regards to its inputs. For example, suppose you implement a function that computes the square of its input f(x) = x2. In that case you would need to provide the corresponding derivative function f′(x) = 2x. Note that this function does not compute a numerical result, but instead builds a subgraph that will (later) compute the result. This is very useful because it means that you can compute gradients of gradients (to compute second-order derivatives, or even higher-order derivatives). Appendix E. Other Popular ANN Architectures In this appendix we will give a quick overview of a few historically important neural network architectures that are much less used today than deep Multi- Layer Perceptrons (Chapter 10), convolutional neural networks (Chapter 13), recurrent neural networks (Chapter 14), or autoencoders (Chapter 15). They are often mentioned in the literature, and some are still used in many applications, so it is worth knowing about them. Moreover, we will discuss deep belief nets (DBNs), which were the state of the art in Deep Learning until the early 2010s. They are still the subject of very active research, so they may well come back with a vengeance in the near future. Hopfield Networks Hopfield networks were first introduced by W. A. Little in 1974, then popularized by J. Hopfield in 1982. They are associative memory networks: you first teach them some patterns, and then when they see a new pattern they (hopefully) output the closest learned pattern. This has made them useful in particular for character recognition before they were outperformed by other approaches. You first train the network by showing it examples of character images (each binary pixel maps to one neuron), and then when you show it a new character image, after a few iterations it outputs the closest learned character. They are fully connected graphs (see Figure E-1); that is, every neuron is connected to every other neuron. Note that on the diagram the images are 6 × 6 pixels, so the neural network on the left should contain 36 neurons (and 648 connections), but for visual clarity a much smaller network is represented. Figure E-1. Hopfield network The training algorithm works by using Hebb’s rule: for each training image, the weight between two neurons is increased if the corresponding pixels are both on or both off, but decreased if one pixel is on and the other is off. To show a new image to the network, you just activate the neurons that correspond to active pixels. The network then computes the output of every neuron, and this gives you a new image. You can then take this new image and repeat the whole process. After a while, the network reaches a stable state. Generally, this corresponds to the training image that most resembles the input image. A so-called energy function is associated with Hopfield nets. At each iteration, the energy decreases, so the network is guaranteed to eventually stabilize to a low-energy state. The training algorithm tweaks the weights in a way that decreases the energy level of the training patterns, so the network is likely to stabilize in one of these low-energy configurations. Unfortunately, some patterns that were not in the training set also end up with low energy, so the network sometimes stabilizes in a configuration that was not learned. These are called spurious patterns. Another major flaw with Hopfield nets is that they don’t scale very well — their memory capacity is roughly equal to 14% of the number of neurons. For example, to classify 28 × 28 images, you would need a Hopfield net with 784 fully connected neurons and 306,936 weights. Such a network would only be able to learn about 110 different characters (14% of 784). That’s a lot of parameters for such a small memory. Boltzmann Machines Boltzmann machines were invented in 1985 by Geoffrey Hinton and Terrence Sejnowski. Just like Hopfield nets, they are fully connected ANNs, but they are based on stochastic neurons: instead of using a deterministic step function to decide what value to output, these neurons output 1 with some probability, and 0 otherwise. The probability function that these ANNs use is based on the Boltzmann distribution (used in statistical mechanics) hence their name. Equation E-1 gives the probability that a particular neuron will output a 1. Equation E-1. Probability that the ith neuron will output 1 sj is the jth neuron’s state (0 or 1). wi,j is the connection weight between the ith and jth neurons. Note that wi,i = 0. bi is the ith neuron’s bias term. We can implement this term by adding a bias neuron to the network. N is the number of neurons in the network. T is a number called the network’s temperature; the higher the temperature, the more random the output is (i.e., the more the probability approaches 50%). σ is the logistic function. Neurons in Boltzmann machines are separated into two groups: visible units and hidden units (see Figure E-2). All neurons work in the same stochastic way, but the visible units are the ones that receive the inputs and from which outputs are read. Figure E-2. Boltzmann machine Because of its stochastic nature, a Boltzmann machine will never stabilize into a fixed configuration, but instead it will keep switching between many configurations. If it is left running for a sufficiently long time, the probability of observing a particular configuration will only be a function of the connection weights and bias terms, not of the original configuration (similarly, after you shuffle a deck of cards for long enough, the configuration of the deck does not depend on the initial state). When the network reaches this state where the original configuration is “forgotten,” it is said to be in thermal equilibrium (although its configuration keeps changing all the time). By setting the network parameters appropriately, letting the network reach thermal equilibrium, and then observing its state, we can simulate a wide range of probability distributions. This is called a generative model. Training a Boltzmann machine means finding the parameters that will make the network approximate the training set’s probability distribution. For example, if there are three visible neurons and the training set contains 75% (0, 1, 1) triplets, 10% (0, 0, 1) triplets, and 15% (1, 1, 1) triplets, then after training a Boltzmann machine, you could use it to generate random binary triplets with about the same probability distribution. For example, about 75% of the time it would output the (0, 1, 1) triplet. Such a generative model can be used in a variety of ways. For example, if it is trained on images, and you provide an incomplete or noisy image to the network, it will automatically “repair” the image in a reasonable way. You can also use a generative model for classification. Just add a few visible neurons to encode the training image’s class (e.g., add 10 visible neurons and turn on only the fifth neuron when the training image represents a 5). Then, when given a new image, the network will automatically turn on the appropriate visible neurons, indicating the image’s class (e.g., it will turn on the fifth visible neuron if the image represents a 5). Unfortunately, there is no efficient technique to train Boltzmann machines. However, fairly efficient algorithms have been developed to train restricted Boltzmann machines (RBM). Restricted Boltzmann Machines An RBM is simply a Boltzmann machine in which there are no connections between visible units or between hidden units, only between visible and hidden units. For example, Figure E-3 represents an RBM with three visible units and four hidden units. Figure E-3. Restricted Boltzmann machine A very efficient training algorithm, called Contrastive Divergence, was introduced in 2005 by Miguel Á. Carreira-Perpiñán and Geoffrey Hinton.1 Here is how it works: for each training instance x, the algorithm starts by feeding it to the network by setting the state of the visible units to x1, x2, ⋯, xn. Then you compute the state of the hidden units by applying the stochastic equation described before (Equation E-1). This gives you a hidden vector h (where hi is equal to the state of the ith unit). Next you compute the state of the visible units, by applying the same stochastic equation. This gives you a vector . Then once again you compute the state of the hidden units, which gives you a vector . Now you can update each connection weight by applying the rule in Equation E- 2. Equation E-2. Contrastive divergence weight update The great benefit of this algorithm it that it does not require waiting for the network to reach thermal equilibrium: it just goes forward, backward, and forward again, and that’s it. This makes it incomparably more efficient than previous algorithms, and it was a key ingredient to the first success of Deep Learning based on multiple stacked RBMs. Deep Belief Nets Several layers of RBMs can be stacked; the hidden units of the first-level RBM serves as the visible units for the second-layer RBM, and so on. Such an RBM stack is called a deep belief net (DBN). Yee-Whye Teh, one of Geoffrey Hinton’s students, observed that it was possible to train DBNs one layer at a time using Contrastive Divergence, starting with the lower layers and then gradually moving up to the top layers. This led to the groundbreaking article that kickstarted the Deep Learning tsunami in 2006.2 Just like RBMs, DBNs learn to reproduce the probability distribution of their inputs, without any supervision. However, they are much better at it, for the same reason that deep neural networks are more powerful than shallow ones: real-world data is often organized in hierarchical patterns, and DBNs take advantage of that. Their lower layers learn low-level features in the input data, while higher layers learn high-level features. Just like RBMs, DBNs are fundamentally unsupervised, but you can also train them in a supervised manner by adding some visible units to represent the labels. Moreover, one great feature of DBNs is that they can be trained in a semisupervised fashion. Figure E-4 represents such a DBN configured for semisupervised learning. Figure E-4. A deep belief network configured for semisupervised learning First, the RBM 1 is trained without supervision. It learns low-level features in the training data. Then RBM 2 is trained with RBM 1’s hidden units as inputs, again without supervision: it learns higher-level features (note that RBM 2’s hidden units include only the three rightmost units, not the label units). Several more RBMs could be stacked this way, but you get the idea. So far, training was 100% unsupervised. Lastly, RBM 3 is trained using both RBM 2’s hidden units as inputs, as well as extra visible units used to represent the target labels (e.g., a one-hot vector representing the instance class). It learns to associate high-level features with training labels. This is the supervised step. At the end of training, if you feed RBM 1 a new instance, the signal will propagate up to RBM 2, then up to the top of RBM 3, and then back down to the label units; hopefully, the appropriate label will light up. This is how a DBN can be used for classification. One great benefit of this semisupervised approach is that you don’t need much labeled training data. If the unsupervised RBMs do a good enough job, then only a small amount of labeled training instances per class will be necessary. Similarly, a baby learns to recognize objects without supervision, so when you point to a chair and say “chair,” the baby can associate the word “chair” with the class of objects it has already learned to recognize on its own. You don’t need to point to every single chair and say “chair”; only a few examples will suffice (just enough so the baby can be sure that you are indeed referring to the chair, not to its color or one of the chair’s parts). Quite amazingly, DBNs can also work in reverse. If you activate one of the label units, the signal will propagate up to the hidden units of RBM 3, then down to RBM 2, and then RBM 1, and a new instance will be output by the visible units of RBM 1. This new instance will usually look like a regular instance of the class whose label unit you activated. This generative capability of DBNs is quite powerful. For example, it has been used to automatically generate captions for images, and vice versa: first a DBN is trained (without supervision) to learn features in images, and another DBN is trained (again without supervision) to learn features in sets of captions (e.g., “car” often comes with “automobile”). Then an RBM is stacked on top of both DBNs and trained with a set of images along with their captions; it learns to associate high-level features in images with high-level features in captions. Next, if you feed the image DBN an image of a car, the signal will propagate through the network, up to the top-level RBM, and back down to the bottom of the caption DBN, producing a caption. Due to the stochastic nature of RBMs and DBNs, the caption will keep changing randomly, but it will generally be appropriate for the image. If you generate a few hundred captions, the most frequently generated ones will likely be a good description of the image.3 Self-Organizing Maps Self-organizing maps (SOM) are quite different from all the other types of neural networks we have discussed so far. They are used to produce a low-dimensional representation of a high-dimensional dataset, generally for visualization, clustering, or classification. The neurons are spread across a map (typically 2D for visualization, but it can be any number of dimensions you want), as shown in Figure E-5, and each neuron has a weighted connection to every input (note that the diagram shows just two inputs, but there are typically a very large number, since the whole point of SOMs is to reduce dimensionality). Figure E-5. Self-organizing maps Once the network is trained, you can feed it a new instance and this will activate only one neuron (i.e., hence one point on the map): the neuron whose weight vector is closest to the input vector. In general, instances that are nearby in the original input space will activate neurons that are nearby on the map. This makes SOMs useful for visualization (in particular, you can easily identify clusters on the map), but also for applications like speech recognition. For example, if each instance represents the audio recording of a person pronouncing a vowel, then different pronunciations of the vowel “a” will activate neurons in the same area of the map, while instances of the vowel “e” will activate neurons in another area, and intermediate sounds will generally activate intermediate neurons on the map. NOTE One important difference with the other dimensionality reduction techniques discussed in Chapter 8 is that all instances get mapped to a discrete number of points in the low-dimensional space (one point per neuron). When there are very few neurons, this technique is better described as clustering rather than dimensionality reduction. The training algorithm is unsupervised. It works by having all the neurons compete against each other. First, all the weights are initialized randomly. Then a training instance is picked randomly and fed to the network. All neurons compute the distance between their weight vector and the input vector (this is very different from the artificial neurons we have seen so far). The neuron that measures the smallest distance wins and tweaks its weight vector to be even slightly closer to the input vector, making it more likely to win future competitions for other inputs similar to this one. It also recruits its neighboring neurons, and they too update their weight vector to be slightly closer to the input vector (but they don’t update their weights as much as the winner neuron). Then the algorithm picks another training instance and repeats the process, again and again. This algorithm tends to make nearby neurons gradually specialize in similar inputs.4 “On Contrastive Divergence Learning,” M. Á. Carreira-Perpiñán and G. Hinton (2005). 1 2 “A Fast Learning Algorithm for Deep Belief Nets,” G. Hinton, S. Osindero, Y. Teh (2006). See this video by Geoffrey Hinton for more details and a demo: http://goo.gl/7Z5QiS. You can imagine a class of young children with roughly similar skills. One child happens to be slightly better at basketball. This motivates her to practice more, especially with her friends. After a while, this group of friends gets so good at basketball that other kids cannot compete. But that’s okay, because the other kids specialize in other topics. After a while, the class is full of little specialized groups. 2 3 4 Index Symbols __call__(), Static Unrolling Through Time ε-greedy policy, Exploration Policies, Learning to Play Ms. Pac-Man Using Deep Q-Learning ε-insensitive, SVM Regression χ 2 test (see chi square test) ℓ 0 norm, Select a Performance Measure ℓ 1 and ℓ 2 regularization, ℓ1 and ℓ2 Regularization-ℓ1 and ℓ2 Regularization ℓ 1 norm, Select a Performance Measure, Lasso Regression, Decision Boundaries, Adam Optimization, Avoiding Overfitting Through Regularization ℓ 2 norm, Select a Performance Measure, Ridge Regression-Lasso Regression, Decision Boundaries, Softmax Regression, Avoiding Overfitting Through Regularization, Max-Norm Regularization ℓ k norm, Select a Performance Measure ℓ ∞ norm, Select a Performance Measure A accuracy, What Is Machine Learning?, Measuring Accuracy Using Cross- Validation-Measuring Accuracy Using Cross-Validation actions, evaluating, Evaluating Actions: The Credit Assignment Problem- Evaluating Actions: The Credit Assignment Problem activation functions, Multi-Layer Perceptron and Backpropagation-Multi- Layer Perceptron and Backpropagation active constraints, SVM Dual Problem actors, Learning to Play Ms. Pac-Man Using Deep Q-Learning actual class, Confusion Matrix AdaBoost, AdaBoost-AdaBoost Adagrad, AdaGrad-AdaGrad Adam optimization, Faster Optimizers, Adam Optimization-Adam Optimization adaptive learning rate, AdaGrad adaptive moment optimization, Adam Optimization agents, Learning to Optimize Rewards AlexNet architecture, AlexNet-AlexNet algorithms preparing data for, Prepare the Data for Machine Learning Algorithms- Select and Train a Model AlphaGo, Reinforcement Learning, Introduction to Artificial Neural Networks, Reinforcement Learning, Policy Gradients Anaconda, Create the Workspace anomaly detection, Unsupervised learning Apple’s Siri, Introduction to Artificial Neural Networks apply_gradients(), Gradient Clipping, Policy Gradients area under the curve (AUC), The ROC Curve arg_scope(), Implementing Batch Normalization with TensorFlow array_split(), Incremental PCA artificial neural networks (ANNs), Introduction to Artificial Neural Networks-Exercises Boltzmann Machines, Boltzmann Machines-Boltzmann Machines deep belief networks (DBNs), Deep Belief Nets-Deep Belief Nets evolution of, From Biological to Artificial Neurons Hopfield Networks, Hopfield Networks-Hopfield Networks hyperparameter fine-tuning, Fine-Tuning Neural Network Hyperparameters-Activation Functions overview, Introduction to Artificial Neural Networks-From Biological to Artificial Neurons Perceptrons, The Perceptron-Multi-Layer Perceptron and Backpropagation self-organizing maps, Self-Organizing Maps-Self-Organizing Maps training a DNN with TensorFlow, Training a DNN Using Plain TensorFlow-Using the Neural Network artificial neuron, Logical Computations with Neurons (see also artificial neural network (ANN)) assign(), Manually Computing the Gradients association rule learning, Unsupervised learning associative memory networks, Hopfield Networks assumptions, checking, Check the Assumptions asynchronous updates, Asynchronous updates-Asynchronous updates asynchrous communication, Asynchronous Communication Using TensorFlow Queues-PaddingFifoQueue atrous_conv2d(), ResNet attention mechanism, An Encoder–Decoder Network for Machine Translation attributes, Supervised learning, Take a Quick Look at the Data Structure- Take a Quick Look at the Data Structure (see also data structure) combinations of, Experimenting with Attribute Combinations- Experimenting with Attribute Combinations preprocessed, Take a Quick Look at the Data Structure target, Take a Quick Look at the Data Structure autodiff, Using autodiff-Using autodiff, Autodiff-Reverse-Mode Autodiff forward-mode, Forward-Mode Autodiff-Forward-Mode Autodiff manual differentiation, Manual Differentiation numerical differentiation, Numerical Differentiation reverse-mode, Reverse-Mode Autodiff-Reverse-Mode Autodiff symbolic differentiation, Symbolic Differentiation-Numerical Differentiation autoencoders, Autoencoders-Exercises adversarial, Other Autoencoders contractive, Other Autoencoders denoising, Denoising Autoencoders-TensorFlow Implementation efficient data representations, Efficient Data Representations generative stochastic network (GSN), Other Autoencoders overcomplete, Unsupervised Pretraining Using Stacked Autoencoders PCA with undercomplete linear autoencoder, Performing PCA with an Undercomplete Linear Autoencoder reconstructions, Efficient Data Representations sparse, Sparse Autoencoders-TensorFlow Implementation stacked, Stacked Autoencoders-Unsupervised Pretraining Using Stacked Autoencoders stacked convolutional, Other Autoencoders undercomplete, Efficient Data Representations variational, Variational Autoencoders-Generating Digits visualizing features, Visualizing Features-Visualizing Features winner-take-all (WTA), Other Autoencoders automatic differentiating, Up and Running with TensorFlow autonomous driving systems, Recurrent Neural Networks Average Absolute Deviation, Select a Performance Measure average pooling layer, Pooling Layer avg_pool(), Pooling Layer B backpropagation, Multi-Layer Perceptron and Backpropagation-Multi- Layer Perceptron and Backpropagation, Vanishing/Exploding Gradients Problems, Unsupervised Pretraining, Visualizing Features backpropagation through time (BPTT), Training RNNs bagging and pasting, Bagging and Pasting-Out-of-Bag Evaluation out-of-bag evaluation, Out-of-Bag Evaluation-Out-of-Bag Evaluation in Scikit-Learn, Bagging and Pasting in Scikit-Learn-Bagging and Pasting in Scikit-Learn bandwidth saturation, Bandwidth saturation-Bandwidth saturation BasicLSTMCell, LSTM Cell BasicRNNCell, Distributing a Deep RNN Across Multiple GPUs- Distributing a Deep RNN Across Multiple GPUs Batch Gradient Descent, Batch Gradient Descent-Batch Gradient Descent, Lasso Regression batch learning, Batch learning-Batch learning Batch Normalization, Batch Normalization-Implementing Batch Normalization with TensorFlow, ResNet operation summary, Batch Normalization with TensorFlow, Implementing Batch Normalization with TensorFlow- Implementing Batch Normalization with TensorFlow batch(), Other convenience functions batch_join(), Other convenience functions batch_norm(), Implementing Batch Normalization with TensorFlow- Implementing Batch Normalization with TensorFlow Bellman Optimality Equation, Markov Decision Processes between-graph replication, In-Graph Versus Between-Graph Replication bias neurons, The Perceptron bias term, Linear Regression bias/variance tradeoff, Learning Curves biases, Construction Phase binary classifiers, Training a Binary Classifier, Logistic Regression biological neurons, From Biological to Artificial Neurons-Biological Neurons black box models, Making Predictions blending, Stacking-Exercises Boltzmann Machines, Boltzmann Machines-Boltzmann Machines (see also restricted Boltzman machines (RBMs)) boosting, Boosting-Gradient Boosting AdaBoost, AdaBoost-AdaBoost Gradient Boosting, Gradient Boosting-Gradient Boosting bootstrap aggregation (see bagging) bootstrapping, Grid Search, Bagging and Pasting, Introduction to OpenAI Gym, Learning to Play Ms. Pac-Man Using Deep Q-Learning bottleneck layers, GoogLeNet brew, Stacking C Caffe model zoo, Model Zoos call__(), Distributing a Deep RNN Across Multiple GPUs CART (Classification and Regression Tree) algorithm, Making Predictions- The CART Training Algorithm, Regression categorical attributes, Handling Text and Categorical Attributes-Handling Text and Categorical Attributes cell wrapper, Training to Predict Time Series chi square test, Regularization Hyperparameters classification versus regression, Supervised learning, Multioutput Classification classifiers binary, Training a Binary Classifier error analysis, Error Analysis-Error Analysis evaluating, Multiclass Classification MNIST dataset, MNIST-MNIST multiclass, Multiclass Classification-Multiclass Classification multilabel, Multilabel Classification-Multilabel Classification multioutput, Multioutput Classification-Multioutput Classification performance measures, Performance Measures-The ROC Curve precision of, Confusion Matrix voting, Voting Classifiers-Voting Classifiers clip_by_value(), Gradient Clipping closed-form equation, Training Models, Ridge Regression, Training and Cost Function cluster specification, Multiple Devices Across Multiple Servers clustering algorithms, Unsupervised learning clusters, Multiple Devices Across Multiple Servers coding space, Variational Autoencoders codings, Autoencoders complementary slackness condition, SVM Dual Problem components_, Using Scikit-Learn computational complexity, Computational Complexity, Computational Complexity, Computational Complexity compute_gradients(), Gradient Clipping, Policy Gradients concat(), GoogLeNet config.gpu_options, Managing the GPU RAM ConfigProto, Managing the GPU RAM confusion matrix, Confusion Matrix-Confusion Matrix, Error Analysis- Error Analysis connectionism, The Perceptron constrained optimization, Training Objective, SVM Dual Problem Contrastive Divergence, Restricted Boltzmann Machines control dependencies, Control Dependencies conv1d(), ResNet conv2d_transpose(), ResNet conv3d(), ResNet convergence rate, Batch Gradient Descent convex function, Gradient Descent convolution kernels, Filters, CNN Architectures, GoogLeNet convolutional neural networks (CNNs), Convolutional Neural Networks- Exercises architectures, CNN Architectures-ResNet AlexNet, AlexNet-AlexNet GoogleNet, GoogLeNet-GoogLeNet LeNet5, LeNet-5-LeNet-5 ResNet, ResNet-ResNet convolutional layer, Convolutional Layer-Memory Requirements, GoogLeNet, ResNet feature maps, Stacking Multiple Feature Maps-TensorFlow Implementation filters, Filters memory requirement, Memory Requirements-Memory Requirements evolution of, The Architecture of the Visual Cortex pooling layer, Pooling Layer-Pooling Layer TensorFlow implementation, TensorFlow Implementation-TensorFlow Implementation Coordinator class, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner correlation coefficient, Looking for Correlations-Looking for Correlations correlations, finding, Looking for Correlations-Looking for Correlations cost function, Model-based learning, Select a Performance Measure in AdaBoost, AdaBoost in adagrad, AdaGrad in artificial neural networks, Training an MLP with TensorFlow’s High- Level API, Construction Phase-Construction Phase in autodiff, Using autodiff in batch normalization, Implementing Batch Normalization with TensorFlow cross entropy, LeNet-5 deep Q-Learning, Learning to Play Ms. Pac-Man Using Deep Q-Learning in Elastic Net, Elastic Net in Gradient Descent, Training Models, Gradient Descent-Gradient Descent, Batch Gradient Descent, Batch Gradient Descent-Stochastic Gradient Descent, Gradient Boosting, Vanishing/Exploding Gradients Problems in Logistic Regression, Training and Cost Function-Training and Cost Function in PG algorithms, Policy Gradients in variational autoencoders, Variational Autoencoders in Lasso Regression, Lasso Regression-Lasso Regression in Linear Regression, The Normal Equation, Gradient Descent in Momentum optimization, Momentum optimization-Nesterov Accelerated Gradient in pretrained layers reuse, Pretraining on an Auxiliary Task in ridge regression, Ridge Regression-Ridge Regression in RNNs, Training RNNs, Training to Predict Time Series stale gradients and, Asynchronous updates creative sequences, Creative RNN credit assignment problem, Evaluating Actions: The Credit Assignment Problem-Evaluating Actions: The Credit Assignment Problem critics, Learning to Play Ms. Pac-Man Using Deep Q-Learning cross entropy, Softmax Regression-Softmax Regression, Training an MLP with TensorFlow’s High-Level API, TensorFlow Implementation, Policy Gradients cross-validation, Testing and Validating, Better Evaluation Using Cross- Validation-Better Evaluation Using Cross-Validation, Measuring Accuracy Using Cross-Validation-Measuring Accuracy Using Cross-Validation CUDA library, Installation cuDNN library, Installation curse of dimensionality, Dimensionality Reduction-The Curse of Dimensionality (see also dimensionality reduction) custom transformers, Custom Transformers-Custom Transformers D data, Testing and Validating (see also test data; training data) creating workspace for, Get the Data-Download the Data downloading, Download the Data-Download the Data finding correlations in, Looking for Correlations-Looking for Correlations making assumptions about, Testing and Validating preparing for Machine Learning algorithms, Prepare the Data for Machine Learning Algorithms-Select and Train a Model test-set creation, Create a Test Set-Create a Test Set working with real data, Working with Real Data data augmentation, Data Augmentation-Data Augmentation data cleaning, Data Cleaning-Handling Text and Categorical Attributes data mining, Why Use Machine Learning? data parallelism, Data Parallelism-TensorFlow implementation asynchronous updates, Asynchronous updates-Asynchronous updates bandwidth saturation, Bandwidth saturation-Bandwidth saturation synchronous updates, Synchronous updates TensorFlow implementation, TensorFlow implementation data pipeline, Frame the Problem data snooping bias, Create a Test Set data structure, Take a Quick Look at the Data Structure-Take a Quick Look at the Data Structure data visualization, Visualizing Geographical Data-Visualizing Geographical Data DataFrame, Data Cleaning dataquest, Other Resources decay, Implementing Batch Normalization with TensorFlow decision boundaries, Decision Boundaries-Decision Boundaries, Softmax Regression, Making Predictions decision function, Precision/Recall Tradeoff, Decision Function and Predictions-Decision Function and Predictions Decision Stumps, AdaBoost decision threshold, Precision/Recall Tradeoff Decision Trees, Training and Evaluating on the Training Set-Better Evaluation Using Cross-Validation, Decision Trees-Exercises, Ensemble Learning and Random Forests binary trees, Making Predictions class probability estimates, Estimating Class Probabilities computational complexity, Computational Complexity decision boundaries, Making Predictions GINI impurity, Gini Impurity or Entropy? instability with, Instability-Instability numbers of children, Making Predictions predictions, Making Predictions-Estimating Class Probabilities Random Forests (see Random Forests) regression tasks, Regression-Regression regularization hyperparameters, Regularization Hyperparameters- Regularization Hyperparameters training and visualizing, Training and Visualizing a Decision Tree- Making Predictions decoder, Efficient Data Representations deconvolutional layer, ResNet deep autoencoders (see stacked autoencoders) deep belief networks (DBNs), Semisupervised learning, Deep Belief Nets- Deep Belief Nets Deep Learning, Reinforcement Learning (see also Reinforcement Learning; TensorFlow) about, The Machine Learning Tsunami, Roadmap libraries, Up and Running with TensorFlow-Up and Running with TensorFlow deep neural networks (DNNs), Multi-Layer Perceptron and Backpropagation, Training Deep Neural Nets-Exercises (see also Multi-Layer Perceptrons (MLP)) faster optimizers for, Faster Optimizers-Learning Rate Scheduling regularization, Avoiding Overfitting Through Regularization-Data Augmentation reusing pretrained layers, Reusing Pretrained Layers-Pretraining on an Auxiliary Task training guidelines overview, Practical Guidelines training with TensorFlow, Training a DNN Using Plain TensorFlow-Using the Neural Network training with TF.Learn, Training an MLP with TensorFlow’s High-Level API unstable gradients, Vanishing/Exploding Gradients Problems vanishing and exploding gradients, Training Deep Neural Nets-Gradient Clipping Deep Q-Learning, Approximate Q-Learning-Learning to Play Ms. Pac-Man Using Deep Q-Learning Ms. Pac Man example, Learning to Play Ms. Pac-Man Using Deep Q- Learning-Learning to Play Ms. Pac-Man Using Deep Q-Learning deep Q-network, Approximate Q-Learning deep RNNs, Deep RNNs-The Difficulty of Training over Many Time Steps applying dropout, Applying Dropout distributing across multiple GPUs, Distributing a Deep RNN Across Multiple GPUs long sequence difficulties, The Difficulty of Training over Many Time Steps truncated backpropagation through time, The Difficulty of Training over Many Time Steps DeepMind, Reinforcement Learning, Introduction to Artificial Neural Networks, Reinforcement Learning, Approximate Q-Learning degrees of freedom, Overfitting the Training Data, Learning Curves denoising autoencoders, Denoising Autoencoders-TensorFlow Implementation depth concat layer, GoogLeNet depth radius, AlexNet depthwise_conv2d(), ResNet dequeue(), Queues of tuples dequeue_many(), Queues of tuples, PaddingFifoQueue dequeue_up_to(), Closing a queue-PaddingFifoQueue dequeuing data, Dequeuing data describe(), Take a Quick Look at the Data Structure device blocks, Sharding Variables Across Multiple Parameter Servers device(), Simple placement dimensionality reduction, Unsupervised learning, Dimensionality Reduction-Exercises, Autoencoders approaches to Manifold Learning, Manifold Learning projection, Projection-Projection choosing the right number of dimensions, Choosing the Right Number of Dimensions curse of dimensionality, Dimensionality Reduction-The Curse of Dimensionality and data visualization, Dimensionality Reduction Isomap, Other Dimensionality Reduction Techniques LLE (Locally Linear Embedding), LLE-LLE Multidimensional Scaling, Other Dimensionality Reduction Techniques- Other Dimensionality Reduction Techniques PCA (Principal Component Analysis), PCA-Randomized PCA t-Distributed Stochastic Neighbor Embedding (t-SNE), Other Dimensionality Reduction Techniques discount rate, Evaluating Actions: The Credit Assignment Problem distributed computing, Up and Running with TensorFlow distributed sessions, Sharing State Across Sessions Using Resource Containers-Sharing State Across Sessions Using Resource Containers DNNClassifier, Training an MLP with TensorFlow’s High-Level API drop(), Prepare the Data for Machine Learning Algorithms dropconnect, Dropout dropna(), Data Cleaning dropout, Number of Neurons per Hidden Layer, Applying Dropout dropout rate, Dropout dropout(), Dropout DropoutWrapper, Applying Dropout DRY (Don’t Repeat Yourself), Modularity Dual Averaging, Adam Optimization dual numbers, Forward-Mode Autodiff dual problem, The Dual Problem duality, SVM Dual Problem dying ReLUs, Nonsaturating Activation Functions dynamic placements, Dynamic placement function dynamic placer, Placing Operations on Devices Dynamic Programming, Markov Decision Processes dynamic unrolling through time, Dynamic Unrolling Through Time dynamic_rnn(), Dynamic Unrolling Through Time, Distributing a Deep RNN Across Multiple GPUs, An Encoder–Decoder Network for Machine Translation E early stopping, Early Stopping-Early Stopping, Gradient Boosting, Number of Neurons per Hidden Layer, Early Stopping Elastic Net, Elastic Net embedded device blocks, Sharding Variables Across Multiple Parameter Servers Embedded Reber grammars, Exercises embeddings, Word Embeddings-Word Embeddings embedding_lookup(), Word Embeddings encoder, Efficient Data Representations Encoder–Decoder, Input and Output Sequences end-of-sequence (EOS) token, Handling Variable-Length Output Sequences energy functions, Hopfield Networks enqueuing data, Enqueuing data Ensemble Learning, Better Evaluation Using Cross-Validation, Ensemble Methods, Ensemble Learning and Random Forests-Exercises bagging and pasting, Bagging and Pasting-Out-of-Bag Evaluation boosting, Boosting-Gradient Boosting in-graph versus between-graph replication, In-Graph Versus Between- Graph Replication-In-Graph Versus Between-Graph Replication Random Forests, Random Forests-Feature Importance (see also Random Forests) random patches and random subspaces, Random Patches and Random Subspaces stacking, Stacking-Stacking entropy impurity measure, Gini Impurity or Entropy? environments, in reinforcement learning, Learning to Optimize Rewards- Evaluating Actions: The Credit Assignment Problem, Exploration Policies, Learning to Play Ms. Pac-Man Using Deep Q-Learning episodes (in RL), Introduction to OpenAI Gym, Evaluating Actions: The Credit Assignment Problem-Policy Gradients, Policy Gradients-Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning epochs, Stochastic Gradient Descent ε-insensitive, SVM Regression equality contraints, SVM Dual Problem error analysis, Error Analysis-Error Analysis estimators, Data Cleaning Euclidian norm, Select a Performance Measure eval(), Feeding Data to the Training Algorithm evaluating models, Testing and Validating-Testing and Validating explained variance, Choosing the Right Number of Dimensions explained variance ratio, Explained Variance Ratio exploding gradients, Vanishing/Exploding Gradients Problems (see also gradients, vanishing and exploding) exploration policies, Exploration Policies exponential decay, Implementing Batch Normalization with TensorFlow exponential linear unit (ELU), Nonsaturating Activation Functions- Nonsaturating Activation Functions exponential scheduling, Learning Rate Scheduling Extra-Trees, Extra-Trees F F-1 score, Precision and Recall-Precision and Recall face-recognition, Multilabel Classification fake X server, Introduction to OpenAI Gym false positive rate (FPR), The ROC Curve-The ROC Curve fan-in, Xavier and He Initialization, Xavier and He Initialization fan-out, Xavier and He Initialization, Xavier and He Initialization feature detection, Autoencoders feature engineering, Irrelevant Features feature extraction, Unsupervised learning feature importance, Feature Importance-Feature Importance feature maps, Selecting a Kernel and Tuning Hyperparameters, Filters- TensorFlow Implementation, ResNet feature scaling, Feature Scaling feature selection, Irrelevant Features, Grid Search, Lasso Regression, Feature Importance, Prepare the Data feature space, Kernel PCA, Selecting a Kernel and Tuning Hyperparameters feature vector, Select a Performance Measure, Linear Regression, Under the Hood, Implementing Gradient Descent features, Supervised learning FeatureUnion, Transformation Pipelines feedforward neural network (FNN), Multi-Layer Perceptron and Backpropagation feed_dict, Feeding Data to the Training Algorithm FIFOQueue, Asynchronous Communication Using TensorFlow Queues, RandomShuffleQueue fillna(), Data Cleaning first-in first-out (FIFO) queues, Asynchronous Communication Using TensorFlow Queues first-order partial derivatives (Jacobians), Adam Optimization fit(), Data Cleaning, Transformation Pipelines, Incremental PCA fitness function, Model-based learning fit_inverse_transform=, Selecting a Kernel and Tuning Hyperparameters fit_transform(), Data Cleaning, Transformation Pipelines folds, Better Evaluation Using Cross-Validation, MNIST, Measuring Accuracy Using Cross-Validation-Measuring Accuracy Using Cross- Validation Follow The Regularized Leader (FTRL), Adam Optimization forget gate, LSTM Cell forward-mode autodiff, Forward-Mode Autodiff-Forward-Mode Autodiff framing a problem, Frame the Problem-Frame the Problem frozen layers, Freezing the Lower Layers-Caching the Frozen Layers fully_connected(), Construction Phase, Xavier and He Initialization, Implementing Batch Normalization with TensorFlow-Implementing Batch Normalization with TensorFlow, Tying Weights G game play (see reinforcement learning) gamma value, Gaussian RBF Kernel gate controllers, LSTM Cell Gaussian distribution, Select a Performance Measure, Variational Autoencoders, Generating Digits Gaussian RBF, Adding Similarity Features Gaussian RBF kernel, Gaussian RBF Kernel-Gaussian RBF Kernel, Kernelized SVM generalization error, Testing and Validating generalized Lagrangian, SVM Dual Problem-SVM Dual Problem generative autoencoders, Variational Autoencoders generative models, Autoencoders, Boltzmann Machines genetic algorithms, Policy Search geodesic distance, Other Dimensionality Reduction Techniques get_variable(), Sharing Variables-Sharing Variables GINI impurity, Making Predictions, Gini Impurity or Entropy? global average pooling, GoogLeNet global_step, Learning to Play Ms. Pac-Man Using Deep Q-Learning global_variables(), Max-Norm Regularization global_variables_initializer(), Creating Your First Graph and Running It in a Session Glorot initialization, Vanishing/Exploding Gradients Problems-Xavier and He Initialization Google, Up and Running with TensorFlow Google Images, Introduction to Artificial Neural Networks Google Photos, Semisupervised learning GoogleNet architecture, GoogLeNet-GoogLeNet gpu_options.per_process_gpu_memory_fraction, Managing the GPU RAM gradient ascent, Policy Search Gradient Boosted Regression Trees (GBRT), Gradient Boosting Gradient Boosting, Gradient Boosting-Gradient Boosting Gradient Descent (GD), Training Models, Gradient Descent-Mini-batch Gradient Descent, Online SVMs, Training Deep Neural Nets, Momentum optimization, AdaGrad algorithm comparisons, Mini-batch Gradient Descent-Mini-batch Gradient Descent automatically computing gradients, Using autodiff-Using autodiff Batch GD, Batch Gradient Descent-Batch Gradient Descent, Lasso Regression defining, Gradient Descent local minimum versus global minimum, Gradient Descent manually computing gradients, Manually Computing the Gradients Mini-batch GD, Mini-batch Gradient Descent-Mini-batch Gradient Descent, Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm optimizer, Using an Optimizer Stochastic GD, Stochastic Gradient Descent-Stochastic Gradient Descent, Soft Margin Classification with TensorFlow, Implementing Gradient Descent-Using an Optimizer Gradient Tree Boosting, Gradient Boosting GradientDescentOptimizer, Construction Phase gradients(), Using autodiff gradients, vanishing and exploding, Training Deep Neural Nets-Gradient Clipping, The Difficulty of Training over Many Time Steps Batch Normalization, Batch Normalization-Implementing Batch Normalization with TensorFlow Glorot and He initialization, Vanishing/Exploding Gradients Problems- Xavier and He Initialization gradient clipping, Gradient Clipping nonsaturating activation functions, Nonsaturating Activation Functions- Nonsaturating Activation Functions graphviz, Training and Visualizing a Decision Tree greedy algorithm, The CART Training Algorithm grid search, Fine-Tune Your Model-Grid Search, Polynomial Kernel group(), Learning to Play Ms. Pac-Man Using Deep Q-Learning GRU (Gated Recurrent Unit) cell, GRU Cell-GRU Cell H hailstone sequence, Efficient Data Representations hard margin classification, Soft Margin Classification-Soft Margin Classification hard voting classifiers, Voting Classifiers-Voting Classifiers harmonic mean, Precision and Recall He initialization, Vanishing/Exploding Gradients Problems-Xavier and He Initialization Heaviside step function, The Perceptron Hebb's rule, The Perceptron, Hopfield Networks Hebbian learning, The Perceptron hidden layers, Multi-Layer Perceptron and Backpropagation hierarchical clustering, Unsupervised learning hinge loss function, Online SVMs histograms, Take a Quick Look at the Data Structure-Take a Quick Look at the Data Structure hold-out sets, Stacking (see also blenders) Hopfield Networks, Hopfield Networks-Hopfield Networks hyperbolic tangent (htan activation function), Multi-Layer Perceptron and Backpropagation, Activation Functions, Vanishing/Exploding Gradients Problems, Xavier and He Initialization, Recurrent Neurons hyperparameters, Overfitting the Training Data, Custom Transformers, Grid Search-Grid Search, Evaluate Your System on the Test Set, Gradient Descent, Polynomial Kernel, Computational Complexity, Fine-Tuning Neural Network Hyperparameters (see also neural network hyperparameters) hyperplane, Decision Function and Predictions, Manifold Learning-PCA, Projecting Down to d Dimensions, Other Dimensionality Reduction Techniques hypothesis, Select a Performance Measure manifold, Manifold Learning hypothesis boosting (see boosting) hypothesis function, Linear Regression hypothesis, null, Regularization Hyperparameters I identity matrix, Ridge Regression, Quadratic Programming ILSVRC ImageNet challenge, CNN Architectures image classification, CNN Architectures impurity measures, Making Predictions, Gini Impurity or Entropy? in-graph replication, In-Graph Versus Between-Graph Replication inception modules, GoogLeNet Inception-v4, ResNet incremental learning, Online learning, Incremental PCA inequality constraints, SVM Dual Problem inference, Model-based learning, Exercises, Memory Requirements, An Encoder–Decoder Network for Machine Translation info(), Take a Quick Look at the Data Structure information gain, Gini Impurity or Entropy? information theory, Gini Impurity or Entropy? init node, Saving and Restoring Models input gate, LSTM Cell input neurons, The Perceptron input_put_keep_prob, Applying Dropout instance-based learning, Instance-based learning, Model-based learning InteractiveSession, Creating Your First Graph and Running It in a Session intercept term, Linear Regression Internal Covariate Shift problem, Batch Normalization inter_op_parallelism_threads, Parallel Execution intra_op_parallelism_threads, Parallel Execution inverse_transform(), Selecting a Kernel and Tuning Hyperparameters in_top_k(), Construction Phase irreducible error, Learning Curves isolated environment, Create the Workspace-Create the Workspace Isomap, Other Dimensionality Reduction Techniques is_training, Implementing Batch Normalization with TensorFlow- Implementing Batch Normalization with TensorFlow, Applying Dropout J jobs, Multiple Devices Across Multiple Servers join(), Multiple Devices Across Multiple Servers, Multithreaded readers using a Coordinator and a QueueRunner Jupyter, Create the Workspace, Create the Workspace, Take a Quick Look at the Data Structure K K-fold cross-validation, Better Evaluation Using Cross-Validation-Better Evaluation Using Cross-Validation, Measuring Accuracy Using Cross- Validation k-Nearest Neighbors, Model-based learning, Multilabel Classification Karush–Kuhn–Tucker (KKT) conditions, SVM Dual Problem keep probability, Dropout Keras, Up and Running with TensorFlow Kernel PCA (kPCA), Kernel PCA-Selecting a Kernel and Tuning Hyperparameters kernel trick, Polynomial Kernel, Gaussian RBF Kernel, The Dual Problem- Kernelized SVM, Kernel PCA kernelized SVM, Kernelized SVM-Kernelized SVM kernels, Polynomial Kernel-Gaussian RBF Kernel, Operations and kernels Kullback–Leibler divergence, Softmax Regression, Sparse Autoencoders L l1_l2_regularizer(), ℓ1 and ℓ2 Regularization LabelBinarizer, Transformation Pipelines labels, Supervised learning, Frame the Problem Lagrange function, SVM Dual Problem-SVM Dual Problem Lagrange multiplier, SVM Dual Problem landmarks, Adding Similarity Features-Adding Similarity Features large margin classification, Linear SVM Classification-Linear SVM Classification Lasso Regression, Lasso Regression-Lasso Regression latent loss, Variational Autoencoders latent space, Variational Autoencoders law of large numbers, Voting Classifiers leaky ReLU, Nonsaturating Activation Functions learning rate, Online learning, Gradient Descent, Batch Gradient Descent- Stochastic Gradient Descent learning rate scheduling, Stochastic Gradient Descent, Learning Rate Scheduling-Learning Rate Scheduling LeNet-5 architecture, The Architecture of the Visual Cortex, LeNet-5- LeNet-5 Levenshtein distance, Gaussian RBF Kernel liblinear library, Computational Complexity libsvm library, Computational Complexity Linear Discriminant Analysis (LDA), Other Dimensionality Reduction Techniques linear models early stopping, Early Stopping-Early Stopping Elastic Net, Elastic Net Lasso Regression, Lasso Regression-Lasso Regression Linear Regression (see Linear Regression) regression (see Linear Regression) Ridge Regression, Ridge Regression-Ridge Regression, Elastic Net SVM, Linear SVM Classification-Soft Margin Classification Linear Regression, Model-based learning, Training and Evaluating on the Training Set, Training Models-Mini-batch Gradient Descent, Elastic Net computational complexity, Computational Complexity Gradient Descent in, Gradient Descent-Mini-batch Gradient Descent learning curves in, Learning Curves-Learning Curves Normal Equation, The Normal Equation-Computational Complexity regularizing models (see regularization) using Stochastic Gradient Descent (SGD), Stochastic Gradient Descent with TensorFlow, Linear Regression with TensorFlow-Linear Regression with TensorFlow linear SVM classification, Linear SVM Classification-Soft Margin Classification linear threshold units (LTUs), The Perceptron Lipschitz continuous, Gradient Descent LLE (Locally Linear Embedding), LLE-LLE load_sample_images(), TensorFlow Implementation local receptive field, The Architecture of the Visual Cortex local response normalization, AlexNet local sessions, Sharing State Across Sessions Using Resource Containers location invariance, Pooling Layer log loss, Training and Cost Function logging placements, Logging placements-Logging placements logistic function, Estimating Probabilities Logistic Regression, Supervised learning, Logistic Regression-Softmax Regression decision boundaries, Decision Boundaries-Decision Boundaries estimating probablities, Estimating Probabilities-Estimating Probabilities Softmax Regression model, Softmax Regression-Softmax Regression training and cost function, Training and Cost Function-Training and Cost Function log_device_placement, Logging placements LSTM (Long Short-Term Memory) cell, LSTM Cell-GRU Cell M machine control (see reinforcement learning) Machine Learning large-scale projects (see TensorFlow) notations, Select a Performance Measure-Select a Performance Measure process example, End-to-End Machine Learning Project-Exercises project checklist, Look at the Big Picture, Machine Learning Project Checklist-Launch! resources on, Other Resources-Other Resources uses for, Machine Learning in Your Projects-Machine Learning in Your Projects Machine Learning basics attributes, Supervised learning challenges, Main Challenges of Machine Learning-Stepping Back algorithm problems, Overfitting the Training Data-Underfitting the Training Data training data problems, Poor-Quality Data definition, What Is Machine Learning? features, Supervised learning overview, The Machine Learning Landscape reasons for using, Why Use Machine Learning?-Why Use Machine Learning? spam filter example, What Is Machine Learning?-Why Use Machine Learning? summary, Stepping Back testing and validating, Testing and Validating-Testing and Validating types of systems, Types of Machine Learning Systems-Model-based learning batch and online learning, Batch and Online Learning-Online learning instance-based versus model-based learning, Instance-Based Versus Model-Based Learning-Model-based learning supervised/unsupervised learning, Supervised/Unsupervised Learning- Reinforcement Learning workflow example, Model-based learning-Model-based learning machine translation (see natural language processing (NLP)) make(), Introduction to OpenAI Gym Manhattan norm, Select a Performance Measure manifold assumption/hypothesis, Manifold Learning Manifold Learning, Manifold Learning, LLE (see also LLE (Locally Linear Embedding) MapReduce, Frame the Problem margin violations, Soft Margin Classification Markov chains, Markov Decision Processes Markov decision processes, Markov Decision Processes-Markov Decision Processes master service, The Master and Worker Services Matplotlib, Create the Workspace, Take a Quick Look at the Data Structure, The ROC Curve, Error Analysis max margin learning, Pretraining on an Auxiliary Task max pooling layer, Pooling Layer max-norm regularization, Max-Norm Regularization-Max-Norm Regularization max_norm(), Max-Norm Regularization max_norm_regularizer(), Max-Norm Regularization max_pool(), Pooling Layer Mean Absolute Error (MAE), Select a Performance Measure-Select a Performance Measure mean coding, Variational Autoencoders Mean Square Error (MSE), Linear Regression, Manually Computing the Gradients, Sparse Autoencoders measure of similarity, Instance-based learning memmap, Incremental PCA memory cells, Model Parallelism, Memory Cells Mercer's theorem, Kernelized SVM meta learner (see blending) min-max scaling, Feature Scaling Mini-batch Gradient Descent, Mini-batch Gradient Descent-Mini-batch Gradient Descent, Training and Cost Function, Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm mini-batches, Online learning minimize(), Gradient Clipping, Freezing the Lower Layers, Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning min_after_dequeue, RandomShuffleQueue MNIST dataset, MNIST-MNIST model parallelism, Model Parallelism-Model Parallelism model parameters, Gradient Descent, Batch Gradient Descent, Early Stopping, Under the Hood, Quadratic Programming, Creating Your First Graph and Running It in a Session, Construction Phase, Training RNNs defining, Model-based learning model selection, Model-based learning model zoos, Model Zoos model-based learning, Model-based learning-Model-based learning models analyzing, Analyze the Best Models and Their Errors-Analyze the Best Models and Their Errors evaluating on test set, Evaluate Your System on the Test Set-Evaluate Your System on the Test Set moments, Adam Optimization Momentum optimization, Momentum optimization-Momentum optimization Monte Carlo tree search, Policy Gradients Multi-Layer Perceptrons (MLP), Introduction to Artificial Neural Networks, The Perceptron-Multi-Layer Perceptron and Backpropagation, Neural Network Policies training with TF.Learn, Training an MLP with TensorFlow’s High-Level API multiclass classifiers, Multiclass Classification-Multiclass Classification Multidimensional Scaling (MDS), Other Dimensionality Reduction Techniques multilabel classifiers, Multilabel Classification-Multilabel Classification Multinomial Logistic Regression (see Softmax Regression) multinomial(), Neural Network Policies multioutput classifiers, Multioutput Classification-Multioutput Classification MultiRNNCell, Distributing a Deep RNN Across Multiple GPUs multithreaded readers, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner multivariate regression, Frame the Problem N naive Bayes classifiers, Multiclass Classification name scopes, Name Scopes natural language processing (NLP), Recurrent Neural Networks, Natural Language Processing-An Encoder–Decoder Network for Machine Translation encoder-decoder network for machine translation, An Encoder–Decoder Network for Machine Translation-An Encoder–Decoder Network for Machine Translation TensorFlow tutorials, Natural Language Processing, An Encoder– Decoder Network for Machine Translation word embeddings, Word Embeddings-Word Embeddings Nesterov Accelerated Gradient (NAG), Nesterov Accelerated Gradient- Nesterov Accelerated Gradient Nesterov momentum optimization, Nesterov Accelerated Gradient-Nesterov Accelerated Gradient network topology, Fine-Tuning Neural Network Hyperparameters neural network hyperparameters, Fine-Tuning Neural Network Hyperparameters-Activation Functions activation functions, Activation Functions neurons per hidden layer, Number of Neurons per Hidden Layer number of hidden layers, Number of Hidden Layers-Number of Hidden Layers neural network policies, Neural Network Policies-Neural Network Policies neurons biological, From Biological to Artificial Neurons-Biological Neurons logical computations with, Logical Computations with Neurons neuron_layer(), Construction Phase next_batch(), Execution Phase No Free Lunch theorem, Testing and Validating node edges, Visualizing the Graph and Training Curves Using TensorBoard nonlinear dimensionality reduction (NLDR), LLE (see also Kernel PCA; LLE (Locally Linear Embedding)) nonlinear SVM classification, Nonlinear SVM Classification-Computational Complexity computational complexity, Computational Complexity Gaussian RBF kernel, Gaussian RBF Kernel-Gaussian RBF Kernel with polynomial features, Nonlinear SVM Classification-Polynomial Kernel polynomial kernel, Polynomial Kernel-Polynomial Kernel similarity features, adding, Adding Similarity Features-Adding Similarity Features nonparametric models, Regularization Hyperparameters nonresponse bias, Nonrepresentative Training Data nonsaturating activation functions, Nonsaturating Activation Functions- Nonsaturating Activation Functions normal distribution (see Gaussian distribution) Normal Equation, The Normal Equation-Computational Complexity normalization, Feature Scaling normalized exponential, Softmax Regression norms, Select a Performance Measure notations, Select a Performance Measure-Select a Performance Measure NP-Complete problems, The CART Training Algorithm null hypothesis, Regularization Hyperparameters numerical differentiation, Numerical Differentiation NumPy, Create the Workspace NumPy arrays, Handling Text and Categorical Attributes NVidia Compute Capability, Installation nvidia-smi, Managing the GPU RAM n_components, Choosing the Right Number of Dimensions O observation space, Neural Network Policies off-policy algorithm, Temporal Difference Learning and Q-Learning offline learning, Batch learning one-hot encoding, Handling Text and Categorical Attributes one-versus-all (OvA) strategy, Multiclass Classification, Softmax Regression, Exercises one-versus-one (OvO) strategy, Multiclass Classification online learning, Online learning-Online learning online SVMs, Online SVMs-Online SVMs OpenAI Gym, Introduction to OpenAI Gym-Introduction to OpenAI Gym operation_timeout_in_ms, In-Graph Versus Between-Graph Replication Optical Character Recognition (OCR), The Machine Learning Landscape optimal state value, Markov Decision Processes optimizers, Faster Optimizers-Learning Rate Scheduling AdaGrad, AdaGrad-AdaGrad Adam optimization, Faster Optimizers, Adam Optimization-Adam Optimization Gradient Descent (see Gradient Descent optimizer) learning rate scheduling, Learning Rate Scheduling-Learning Rate Scheduling Momentum optimization, Momentum optimization-Momentum optimization Nesterov Accelerated Gradient (NAG), Nesterov Accelerated Gradient- Nesterov Accelerated Gradient RMSProp, RMSProp out-of-bag evaluation, Out-of-Bag Evaluation-Out-of-Bag Evaluation out-of-core learning, Online learning out-of-memory (OOM) errors, Static Unrolling Through Time out-of-sample error, Testing and Validating OutOfRangeError, Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner output gate, LSTM Cell output layer, Multi-Layer Perceptron and Backpropagation OutputProjectionWrapper, Training to Predict Time Series-Training to Predict Time Series output_put_keep_prob, Applying Dropout overcomplete autoencoder, Unsupervised Pretraining Using Stacked Autoencoders overfitting, Overfitting the Training Data-Overfitting the Training Data, Create a Test Set, Soft Margin Classification, Gaussian RBF Kernel, Regularization Hyperparameters, Regression, Number of Neurons per Hidden Layer avoiding through regularization, Avoiding Overfitting Through Regularization-Data Augmentation P p-value, Regularization Hyperparameters PaddingFIFOQueue, PaddingFifoQueue Pandas, Create the Workspace, Download the Data scatter_matrix, Looking for Correlations-Looking for Correlations parallel distributed computing, Distributing TensorFlow Across Devices and Servers-Exercises data parallelism, Data Parallelism-TensorFlow implementation in-graph versus between-graph replication, In-Graph Versus Between- Graph Replication-Model Parallelism model parallelism, Model Parallelism-Model Parallelism multiple devices across multiple servers, Multiple Devices Across Multiple Servers-Other convenience functions asynchronous communication using queues, Asynchronous Communication Using TensorFlow Queues-PaddingFifoQueue loading training data, Loading Data Directly from the Graph-Other convenience functions master and worker services, The Master and Worker Services opening a session, Opening a Session pinning operations across tasks, Pinning Operations Across Tasks sharding variables, Sharding Variables Across Multiple Parameter Servers sharing state across sessions, Sharing State Across Sessions Using Resource Containers-Sharing State Across Sessions Using Resource Containers multiple devices on a single machine, Multiple Devices on a Single Machine-Control Dependencies control dependencies, Control Dependencies installation, Installation-Installation managing the GPU RAM, Managing the GPU RAM-Managing the GPU RAM parallel execution, Parallel Execution-Parallel Execution placing operations on devices, Placing Operations on Devices-Soft placement one neural network per device, One Neural Network per Device-One Neural Network per Device parameter efficiency, Number of Hidden Layers parameter matrix, Softmax Regression parameter server (ps), Multiple Devices Across Multiple Servers parameter space, Gradient Descent parameter vector, Linear Regression, Gradient Descent, Training and Cost Function, Softmax Regression parametric models, Regularization Hyperparameters partial derivative, Batch Gradient Descent partial_fit(), Incremental PCA Pearson's r, Looking for Correlations peephole connections, Peephole Connections penalties (see rewards, in RL) percentiles, Take a Quick Look at the Data Structure Perceptron convergence theorem, The Perceptron Perceptrons, The Perceptron-Multi-Layer Perceptron and Backpropagation versus Logistic Regression, The Perceptron training, The Perceptron-The Perceptron performance measures, Select a Performance Measure-Select a Performance Measure confusion matrix, Confusion Matrix-Confusion Matrix cross-validation, Measuring Accuracy Using Cross-Validation-Measuring Accuracy Using Cross-Validation precision and recall, Precision and Recall-Precision/Recall Tradeoff ROC (receiver operating characteristic) curve, The ROC Curve-The ROC Curve performance scheduling, Learning Rate Scheduling permutation(), Create a Test Set PG algorithms, Policy Gradients photo-hosting services, Semisupervised learning pinning operations, Pinning Operations Across Tasks pip, Create the Workspace Pipeline constructor, Transformation Pipelines-Select and Train a Model pipelines, Frame the Problem placeholder nodes, Feeding Data to the Training Algorithm placers (see simple placer; dynamic placer) policy, Policy Search policy gradients, Policy Search (see PG algorithms) policy space, Policy Search polynomial features, adding, Nonlinear SVM Classification-Polynomial Kernel polynomial kernel, Polynomial Kernel-Polynomial Kernel, Kernelized SVM Polynomial Regression, Training Models, Polynomial Regression- Polynomial Regression learning curves in, Learning Curves-Learning Curves pooling kernel, Pooling Layer pooling layer, Pooling Layer-Pooling Layer power scheduling, Learning Rate Scheduling precision, Confusion Matrix precision and recall, Precision and Recall-Precision/Recall Tradeoff F-1 score, Precision and Recall-Precision and Recall precision/recall (PR) curve, The ROC Curve precision/recall tradeoff, Precision/Recall Tradeoff-Precision/Recall Tradeoff predetermined piecewise constant learning rate, Learning Rate Scheduling predict(), Data Cleaning predicted class, Confusion Matrix predictions, Confusion Matrix-Confusion Matrix, Decision Function and Predictions-Decision Function and Predictions, Making Predictions- Estimating Class Probabilities predictors, Supervised learning, Data Cleaning preloading training data, Preload the data into a variable PReLU (parametric leaky ReLU), Nonsaturating Activation Functions preprocessed attributes, Take a Quick Look at the Data Structure pretrained layers reuse, Reusing Pretrained Layers-Pretraining on an Auxiliary Task auxiliary task, Pretraining on an Auxiliary Task-Pretraining on an Auxiliary Task caching frozen layers, Caching the Frozen Layers freezing lower layers, Freezing the Lower Layers model zoos, Model Zoos other frameworks, Reusing Models from Other Frameworks TensorFlow model, Reusing a TensorFlow Model-Reusing a TensorFlow Model unsupervised pretraining, Unsupervised Pretraining-Unsupervised Pretraining upper layers, Tweaking, Dropping, or Replacing the Upper Layers Pretty Tensor, Up and Running with TensorFlow primal problem, The Dual Problem principal component, Principal Components Principal Component Analysis (PCA), PCA-Randomized PCA explained variance ratios, Explained Variance Ratio finding principal components, Principal Components-Principal Components for compression, PCA for Compression-Incremental PCA Incremental PCA, Incremental PCA-Randomized PCA Kernel PCA (kPCA), Kernel PCA-Selecting a Kernel and Tuning Hyperparameters projecting down to d dimensions, Projecting Down to d Dimensions Randomized PCA, Randomized PCA Scikit Learn for, Using Scikit-Learn variance, preserving, Preserving the Variance-Preserving the Variance probabilistic autoencoders, Variational Autoencoders probabilities, estimating, Estimating Probabilities-Estimating Probabilities, Estimating Class Probabilities producer functions, Other convenience functions projection, Projection-Projection propositional logic, From Biological to Artificial Neurons pruning, Regularization Hyperparameters, Symbolic Differentiation Python isolated environment in, Create the Workspace-Create the Workspace notebooks in, Create the Workspace-Download the Data pickle, Better Evaluation Using Cross-Validation pip, Create the Workspace Q Q-Learning algorithm, Temporal Difference Learning and Q-Learning- Learning to Play Ms. Pac-Man Using Deep Q-Learning approximate Q-Learning, Approximate Q-Learning deep Q-Learning, Approximate Q-Learning-Learning to Play Ms. Pac- Man Using Deep Q-Learning Q-Value Iteration Algorithm, Markov Decision Processes Q-Values, Markov Decision Processes Quadratic Programming (QP) Problems, Quadratic Programming- Quadratic Programming quantizing, Bandwidth saturation queries per second (QPS), One Neural Network per Device QueueRunner, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner queues, Asynchronous Communication Using TensorFlow Queues- PaddingFifoQueue closing, Closing a queue dequeuing data, Dequeuing data enqueuing data, Enqueuing data first-in first-out (FIFO), Asynchronous Communication Using TensorFlow Queues of tuples, Queues of tuples PaddingFIFOQueue, PaddingFifoQueue RandomShuffleQueue, RandomShuffleQueue q_network(), Learning to Play Ms. Pac-Man Using Deep Q-Learning R Radial Basis Function (RBF), Adding Similarity Features Random Forests, Better Evaluation Using Cross-Validation-Grid Search, Multiclass Classification, Decision Trees, Instability, Ensemble Learning and Random Forests, Random Forests-Feature Importance Extra-Trees, Extra-Trees feature importance, Feature Importance-Feature Importance random initialization, Gradient Descent, Batch Gradient Descent, Stochastic Gradient Descent, Vanishing/Exploding Gradients Problems Random Patches and Random Subspaces, Random Patches and Random Subspaces randomized leaky ReLU (RReLU), Nonsaturating Activation Functions Randomized PCA, Randomized PCA randomized search, Randomized Search, Fine-Tuning Neural Network Hyperparameters RandomShuffleQueue, RandomShuffleQueue, Reading the training data directly from the graph random_uniform(), Manually Computing the Gradients reader operations, Reading the training data directly from the graph recall, Confusion Matrix recognition network, Efficient Data Representations reconstruction error, PCA for Compression reconstruction loss, Efficient Data Representations, TensorFlow Implementation, Variational Autoencoders reconstruction pre-image, Selecting a Kernel and Tuning Hyperparameters reconstructions, Efficient Data Representations recurrent neural networks (RNNs), Recurrent Neural Networks-Exercises deep RNNs, Deep RNNs-The Difficulty of Training over Many Time Steps exploration policies, Exploration Policies GRU cell, GRU Cell-GRU Cell input and output sequences, Input and Output Sequences-Input and Output Sequences LSTM cell, LSTM Cell-GRU Cell natural language processing (NLP), Natural Language Processing-An Encoder–Decoder Network for Machine Translation in TensorFlow, Basic RNNs in TensorFlow-Handling Variable-Length Output Sequences dynamic unrolling through time, Dynamic Unrolling Through Time static unrolling through time, Static Unrolling Through Time-Static Unrolling Through Time variable length input sequences, Handling Variable Length Input Sequences variable length output sequences, Handling Variable-Length Output Sequences training, Training RNNs-Creative RNN backpropagation through time (BPTT), Training RNNs creative sequences, Creative RNN sequence classifiers, Training a Sequence Classifier-Training a Sequence Classifier time series predictions, Training to Predict Time Series-Training to Predict Time Series recurrent neurons, Recurrent Neurons-Input and Output Sequences memory cells, Memory Cells reduce_mean(), Construction Phase reduce_sum(), TensorFlow Implementation-TensorFlow Implementation, Variational Autoencoders, Learning to Play Ms. Pac-Man Using Deep Q- Learning regression, Supervised learning Decision Trees, Regression-Regression regression models linear, Training and Evaluating on the Training Set regression versus classification, Multioutput Classification regularization, Overfitting the Training Data-Overfitting the Training Data, Testing and Validating, Regularized Linear Models-Early Stopping data augmentation, Data Augmentation-Data Augmentation Decision Trees, Regularization Hyperparameters-Regularization Hyperparameters dropout, Dropout-Dropout early stopping, Early Stopping-Early Stopping, Early Stopping Elastic Net, Elastic Net Lasso Regression, Lasso Regression-Lasso Regression max-norm, Max-Norm Regularization-Max-Norm Regularization Ridge Regression, Ridge Regression-Ridge Regression shrinkage, Gradient Boosting ℓ 1 and ℓ 2 regularization, ℓ1 and ℓ2 Regularization-ℓ1 and ℓ2 Regularization REINFORCE algorithms, Policy Gradients Reinforcement Learning (RL), Reinforcement Learning-Reinforcement Learning, Reinforcement Learning-Thank You! actions, Evaluating Actions: The Credit Assignment Problem-Evaluating Actions: The Credit Assignment Problem credit assignment problem, Evaluating Actions: The Credit Assignment Problem-Evaluating Actions: The Credit Assignment Problem discount rate, Evaluating Actions: The Credit Assignment Problem examples of, Learning to Optimize Rewards Markov decision processes, Markov Decision Processes-Markov Decision Processes neural network policies, Neural Network Policies-Neural Network Policies OpenAI gym, Introduction to OpenAI Gym-Introduction to OpenAI Gym PG algorithms, Policy Gradients-Policy Gradients policy search, Policy Search-Policy Search Q-Learning algorithm, Temporal Difference Learning and Q-Learning- Learning to Play Ms. Pac-Man Using Deep Q-Learning rewards, learning to optimize, Learning to Optimize Rewards-Learning to Optimize Rewards Temporal Difference (TD) Learning, Temporal Difference Learning and Q-Learning-Temporal Difference Learning and Q-Learning ReLU (rectified linear units), Modularity-Modularity ReLU activation, ResNet ReLU function, Multi-Layer Perceptron and Backpropagation, Activation Functions, Xavier and He Initialization-Nonsaturating Activation Functions relu(z), Construction Phase render(), Introduction to OpenAI Gym replay memory, Learning to Play Ms. Pac-Man Using Deep Q-Learning replica_device_setter(), Sharding Variables Across Multiple Parameter Servers request_stop(), Multithreaded readers using a Coordinator and a QueueRunner reset(), Introduction to OpenAI Gym reset_default_graph(), Managing Graphs reshape(), Training to Predict Time Series residual errors, Gradient Boosting-Gradient Boosting residual learning, ResNet residual network (ResNet), Model Zoos, ResNet-ResNet residual units, ResNet ResNet, ResNet-ResNet resource containers, Sharing State Across Sessions Using Resource Containers-Sharing State Across Sessions Using Resource Containers restore(), Saving and Restoring Models restricted Boltzmann machines (RBMs), Semisupervised learning, Unsupervised Pretraining, Boltzmann Machines reuse_variables(), Sharing Variables reverse-mode autodiff, Reverse-Mode Autodiff-Reverse-Mode Autodiff rewards, in RL, Learning to Optimize Rewards-Learning to Optimize Rewards rgb_array, Introduction to OpenAI Gym Ridge Regression, Ridge Regression-Ridge Regression, Elastic Net RMSProp, RMSProp ROC (receiver operating characteristic) curve, The ROC Curve-The ROC Curve Root Mean Square Error (RMSE), Select a Performance Measure-Select a Performance Measure, Linear Regression RReLU (randomized leaky ReLU), Nonsaturating Activation Functions run(), Creating Your First Graph and Running It in a Session, In-Graph Versus Between-Graph Replication S Sampled Softmax, An Encoder–Decoder Network for Machine Translation sampling bias, Nonrepresentative Training Data-Poor-Quality Data, Create a Test Set sampling noise, Nonrepresentative Training Data save(), Saving and Restoring Models Saver node, Saving and Restoring Models Scikit Flow, Up and Running with TensorFlow Scikit-Learn, Create the Workspace about, Objective and Approach bagging and pasting in, Bagging and Pasting in Scikit-Learn-Bagging and Pasting in Scikit-Learn CART algorithm, Making Predictions-The CART Training Algorithm, Regression cross-validation, Better Evaluation Using Cross-Validation-Better Evaluation Using Cross-Validation design principles, Data Cleaning-Data Cleaning imputer, Data Cleaning-Handling Text and Categorical Attributes LinearSVR class, SVM Regression MinMaxScaler, Feature Scaling min_ and max_ hyperparameters, Regularization Hyperparameters PCA implementation, Using Scikit-Learn Perceptron class, The Perceptron Pipeline constructor, Transformation Pipelines-Select and Train a Model, Nonlinear SVM Classification Randomized PCA, Randomized PCA Ridge Regression with, Ridge Regression SAMME, AdaBoost SGDClassifier, Training a Binary Classifier, Precision/Recall Tradeoff- Precision/Recall Tradeoff, Multiclass Classification SGDRegressor, Stochastic Gradient Descent sklearn.base.BaseEstimator, Custom Transformers, Transformation Pipelines, Measuring Accuracy Using Cross-Validation sklearn.base.clone(), Measuring Accuracy Using Cross-Validation, Early Stopping sklearn.base.TransformerMixin, Custom Transformers, Transformation Pipelines sklearn.datasets.fetch_california_housing(), Linear Regression with TensorFlow sklearn.datasets.fetch_mldata(), MNIST sklearn.datasets.load_iris(), Decision Boundaries, Soft Margin Classification, Training and Visualizing a Decision Tree, Feature Importance, The Perceptron sklearn.datasets.load_sample_images(), TensorFlow Implementation- TensorFlow Implementation sklearn.datasets.make_moons(), Nonlinear SVM Classification, Exercises sklearn.decomposition.IncrementalPCA, Incremental PCA sklearn.decomposition.KernelPCA, Kernel PCA-Selecting a Kernel and Tuning Hyperparameters, Selecting a Kernel and Tuning Hyperparameters sklearn.decomposition.PCA, Using Scikit-Learn sklearn.ensemble.AdaBoostClassifier, AdaBoost sklearn.ensemble.BaggingClassifier, Bagging and Pasting in Scikit-Learn- Random Forests sklearn.ensemble.GradientBoostingRegressor, Gradient Boosting, Gradient Boosting-Gradient Boosting sklearn.ensemble.RandomForestClassifier, The ROC Curve, Multiclass Classification, Voting Classifiers sklearn.ensemble.RandomForestRegressor, Better Evaluation Using Cross-Validation, Grid Search-Analyze the Best Models and Their Errors, Random Forests-Extra-Trees, Gradient Boosting sklearn.ensemble.VotingClassifier, Voting Classifiers sklearn.externals.joblib, Better Evaluation Using Cross-Validation sklearn.linear_model.ElasticNet, Elastic Net sklearn.linear_model.Lasso, Lasso Regression sklearn.linear_model.LinearRegression, Model-based learning-Model- based learning, Data Cleaning, Training and Evaluating on the Training Set, The Normal Equation, Mini-batch Gradient Descent, Polynomial Regression, Learning Curves-Learning Curves sklearn.linear_model.LogisticRegression, Decision Boundaries, Decision Boundaries, Softmax Regression, Voting Classifiers, Selecting a Kernel and Tuning Hyperparameters sklearn.linear_model.Perceptron, The Perceptron sklearn.linear_model.Ridge, Ridge Regression sklearn.linear_model.SGDClassifier, Training a Binary Classifier sklearn.linear_model.SGDRegressor, Stochastic Gradient Descent-Mini- batch Gradient Descent, Ridge Regression, Lasso Regression-Early Stopping sklearn.manifold.LocallyLinearEmbedding, LLE-LLE sklearn.metrics.accuracy_score(), Voting Classifiers, Out-of-Bag Evaluation, Training an MLP with TensorFlow’s High-Level API sklearn.metrics.confusion_matrix(), Confusion Matrix, Error Analysis sklearn.metrics.f1_score(), Precision and Recall, Multilabel Classification sklearn.metrics.mean_squared_error(), Training and Evaluating on the Training Set-Training and Evaluating on the Training Set, Evaluate Your System on the Test Set, Learning Curves, Early Stopping, Gradient Boosting-Gradient Boosting, Selecting a Kernel and Tuning Hyperparameters sklearn.metrics.precision_recall_curve(), Precision/Recall Tradeoff sklearn.metrics.precision_score(), Precision and Recall, Precision/Recall Tradeoff sklearn.metrics.recall_score(), Precision and Recall, Precision/Recall Tradeoff sklearn.metrics.roc_auc_score(), The ROC Curve-The ROC Curve sklearn.metrics.roc_curve(), The ROC Curve-The ROC Curve sklearn.model_selection.cross_val_predict(), Confusion Matrix, Precision/Recall Tradeoff, The ROC Curve, Error Analysis, Multilabel Classification sklearn.model_selection.cross_val_score(), Better Evaluation Using Cross- Validation-Better Evaluation Using Cross-Validation, Measuring Accuracy Using Cross-Validation-Confusion Matrix sklearn.model_selection.GridSearchCV, Grid Search-Randomized Search, Exercises, Error Analysis, Exercises, Selecting a Kernel and Tuning Hyperparameters sklearn.model_selection.StratifiedKFold, Measuring Accuracy Using Cross-Validation sklearn.model_selection.StratifiedShuffleSplit, Create a Test Set sklearn.model_selection.train_test_split(), Create a Test Set, Training and Evaluating on the Training Set, Learning Curves, Exercises, Gradient Boosting sklearn.multiclass.OneVsOneClassifier, Multiclass Classification sklearn.neighbors.KNeighborsClassifier, Multilabel Classification, Exercises sklearn.neighbors.KNeighborsRegressor, Model-based learning sklearn.pipeline.FeatureUnion, Transformation Pipelines sklearn.pipeline.Pipeline, Transformation Pipelines, Learning Curves, Soft Margin Classification-Nonlinear SVM Classification, Selecting a Kernel and Tuning Hyperparameters sklearn.preprocessing.Imputer, Data Cleaning, Transformation Pipelines sklearn.preprocessing.LabelBinarizer, Handling Text and Categorical Attributes, Transformation Pipelines sklearn.preprocessing.LabelEncoder, Handling Text and Categorical Attributes sklearn.preprocessing.OneHotEncoder, Handling Text and Categorical Attributes sklearn.preprocessing.PolynomialFeatures, Polynomial Regression- Polynomial Regression, Learning Curves, Ridge Regression, Nonlinear SVM Classification sklearn.preprocessing.StandardScaler, Feature Scaling-Transformation Pipelines, Multiclass Classification, Gradient Descent, Ridge Regression, Linear SVM Classification, Soft Margin Classification-Polynomial Kernel, Gaussian RBF Kernel, Implementing Gradient Descent, Training an MLP with TensorFlow’s High-Level API sklearn.svm.LinearSVC, Soft Margin Classification-Nonlinear SVM Classification, Gaussian RBF Kernel-Computational Complexity, SVM Regression, Exercises sklearn.svm.LinearSVR, SVM Regression-SVM Regression sklearn.svm.SVC, Soft Margin Classification, Polynomial Kernel, Gaussian RBF Kernel-Computational Complexity, SVM Regression, Exercises, Voting Classifiers sklearn.svm.SVR, Exercises, SVM Regression sklearn.tree.DecisionTreeClassifier, Regularization Hyperparameters, Exercises, Bagging and Pasting in Scikit-Learn-Out-of-Bag Evaluation, Random Forests, AdaBoost sklearn.tree.DecisionTreeRegressor, Training and Evaluating on the Training Set, Decision Trees, Regression, Gradient Boosting-Gradient Boosting sklearn.tree.export_graphviz(), Training and Visualizing a Decision Tree StandardScaler, Gradient Descent, Implementing Gradient Descent, Training an MLP with TensorFlow’s High-Level API SVM classification classes, Computational Complexity TF.Learn, Up and Running with TensorFlow user guide, Other Resources score(), Data Cleaning search space, Randomized Search, Fine-Tuning Neural Network Hyperparameters second-order partial derivatives (Hessians), Adam Optimization self-organizing maps (SOMs), Self-Organizing Maps-Self-Organizing Maps semantic hashing, Exercises semisupervised learning, Semisupervised learning sensitivity, Confusion Matrix, The ROC Curve sentiment analysis, Recurrent Neural Networks separable_conv2d(), ResNet sequences, Recurrent Neural Networks sequence_length, Handling Variable Length Input Sequences-Handling Variable-Length Output Sequences, An Encoder–Decoder Network for Machine Translation Shannon's information theory, Gini Impurity or Entropy? shortcut connections, ResNet show(), Take a Quick Look at the Data Structure show_graph(), Visualizing the Graph and Training Curves Using TensorBoard shrinkage, Gradient Boosting shuffle_batch(), Other convenience functions shuffle_batch_join(), Other convenience functions sigmoid function, Estimating Probabilities sigmoid_cross_entropy_with_logits(), TensorFlow Implementation similarity function, Adding Similarity Features-Adding Similarity Features simulated annealing, Stochastic Gradient Descent simulated environments, Introduction to OpenAI Gym (see also OpenAI Gym) Singular Value Decomposition (SVD), Principal Components skewed datasets, Measuring Accuracy Using Cross-Validation skip connections, Data Augmentation, ResNet slack variable, Training Objective smoothing terms, Batch Normalization, AdaGrad, Adam Optimization, Variational Autoencoders soft margin classification, Soft Margin Classification-Soft Margin Classification soft placements, Soft placement soft voting, Voting Classifiers softmax function, Softmax Regression, Multi-Layer Perceptron and Backpropagation, Training an MLP with TensorFlow’s High-Level API Softmax Regression, Softmax Regression-Softmax Regression source ops, Linear Regression with TensorFlow, Parallel Execution spam filters, The Machine Learning Landscape-Why Use Machine Learning?, Supervised learning sparse autoencoders, Sparse Autoencoders-TensorFlow Implementation sparse matrix, Handling Text and Categorical Attributes sparse models, Lasso Regression, Adam Optimization sparse_softmax_cross_entropy_with_logits(), Construction Phase sparsity loss, Sparse Autoencoders specificity, The ROC Curve speech recognition, Why Use Machine Learning? spurious patterns, Hopfield Networks stack(), Static Unrolling Through Time stacked autoencoders, Stacked Autoencoders-Unsupervised Pretraining Using Stacked Autoencoders TensorFlow implementation, TensorFlow Implementation training one-at-a-time, Training One Autoencoder at a Time-Training One Autoencoder at a Time tying weights, Tying Weights-Tying Weights unsupervised pretraining with, Unsupervised Pretraining Using Stacked Autoencoders-Unsupervised Pretraining Using Stacked Autoencoders visualizing the reconstructions, Visualizing the Reconstructions- Visualizing the Reconstructions stacked denoising autoencoders, Visualizing Features, Denoising Autoencoders stacked denoising encoders, Denoising Autoencoders stacked generalization (see stacking) stacking, Stacking-Stacking stale gradients, Asynchronous updates standard correlation coefficient, Looking for Correlations standard deviation, Select a Performance Measure standardization, Feature Scaling StandardScaler, Transformation Pipelines, Implementing Gradient Descent, Training an MLP with TensorFlow’s High-Level API state-action values, Markov Decision Processes states tensor, Handling Variable Length Input Sequences state_is_tuple, Distributing a Deep RNN Across Multiple GPUs, LSTM Cell static unrolling through time, Static Unrolling Through Time-Static Unrolling Through Time static_rnn(), Static Unrolling Through Time-Static Unrolling Through Time, An Encoder–Decoder Network for Machine Translation stationary point, SVM Dual Problem-SVM Dual Problem statistical mode, Bagging and Pasting statistical significance, Regularization Hyperparameters stemming, Exercises step functions, The Perceptron step(), Introduction to OpenAI Gym Stochastic Gradient Boosting, Gradient Boosting Stochastic Gradient Descent (SGD), Stochastic Gradient Descent-Stochastic Gradient Descent, Soft Margin Classification, The Perceptron training, Training and Cost Function Stochastic Gradient Descent (SGD) classifier, Training a Binary Classifier, Ridge Regression stochastic neurons, Boltzmann Machines stochastic policy, Policy Search stratified sampling, Create a Test Set-Create a Test Set, Measuring Accuracy Using Cross-Validation stride, Convolutional Layer string kernels, Gaussian RBF Kernel string_input_producer(), Other convenience functions strong learners, Voting Classifiers subderivatives, Online SVMs subgradient vector, Lasso Regression subsample, Gradient Boosting, Pooling Layer supervised learning, Supervised/Unsupervised Learning-Supervised learning Support Vector Machines (SVMs), Multiclass Classification, Support Vector Machines-Exercises decision function and predictions, Decision Function and Predictions- Decision Function and Predictions dual problem, SVM Dual Problem-SVM Dual Problem kernelized SVM, Kernelized SVM-Kernelized SVM linear classification, Linear SVM Classification-Soft Margin Classification mechanics of, Under the Hood-Online SVMs nonlinear classification, Nonlinear SVM Classification-Computational Complexity online SVMs, Online SVMs-Online SVMs Quadratic Programming (QP) problems, Quadratic Programming- Quadratic Programming SVM regression, SVM Regression-Online SVMs the dual problem, The Dual Problem training objective, Training Objective-Training Objective support vectors, Linear SVM Classification svd(), Principal Components symbolic differentiation, Using autodiff, Symbolic Differentiation- Numerical Differentiation synchronous updates, Synchronous updates T t-Distributed Stochastic Neighbor Embedding (t-SNE), Other Dimensionality Reduction Techniques tail heavy, Take a Quick Look at the Data Structure target attributes, Take a Quick Look at the Data Structure target_weights, An Encoder–Decoder Network for Machine Translation tasks, Multiple Devices Across Multiple Servers Temporal Difference (TD) Learning, Temporal Difference Learning and Q- Learning-Temporal Difference Learning and Q-Learning tensor processing units (TPUs), Installation TensorBoard, Up and Running with TensorFlow TensorFlow, Up and Running with TensorFlow-Exercises about, Objective and Approach autodiff, Using autodiff-Using autodiff, Autodiff-Reverse-Mode Autodiff Batch Normalization with, Implementing Batch Normalization with TensorFlow-Implementing Batch Normalization with TensorFlow construction phase, Creating Your First Graph and Running It in a Session control dependencies, Control Dependencies convenience functions, Other convenience functions convolutional layers, ResNet convolutional neural networks and, TensorFlow Implementation- TensorFlow Implementation data parallelism and, TensorFlow implementation denoising autoencoders, TensorFlow Implementation-TensorFlow Implementation dropout with, Dropout dynamic placer, Placing Operations on Devices execution phase, Creating Your First Graph and Running It in a Session feeding data to the training algorithm, Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm Gradient Descent with, Implementing Gradient Descent-Using an Optimizer graphs, managing, Managing Graphs initial graph creation and session run, Creating Your First Graph and Running It in a Session-Creating Your First Graph and Running It in a Session installation, Installation l1 and l2 regularization with, ℓ1 and ℓ2 Regularization learning schedules in, Learning Rate Scheduling Linear Regression with, Linear Regression with TensorFlow-Linear Regression with TensorFlow max pooling layer in, Pooling Layer max-norm regularization with, Max-Norm Regularization model zoo, Model Zoos modularity, Modularity-Modularity Momentum optimization in, Momentum optimization name scopes, Name Scopes neural network policies, Neural Network Policies NLP tutorials, Natural Language Processing, An Encoder–Decoder Network for Machine Translation node value lifecycle, Lifecycle of a Node Value operations (ops), Linear Regression with TensorFlow optimizer, Using an Optimizer overview, Up and Running with TensorFlow-Up and Running with TensorFlow parallel distributed computing (see parallel distributed computing with TensorFlow) Python API construction, Construction Phase-Construction Phase execution, Execution Phase using the neural network, Using the Neural Network queues (see queues) reusing pretrained layers, Reusing a TensorFlow Model-Reusing a TensorFlow Model RNNs in, Basic RNNs in TensorFlow-Handling Variable-Length Output Sequences (see also recurrent neural networks (RNNs)) saving and restoring models, Saving and Restoring Models-Saving and Restoring Models sharing variables, Sharing Variables-Sharing Variables simple placer, Placing Operations on Devices sklearn.metrics.accuracy_score(), Implementing Batch Normalization with TensorFlow sparse autoencoders with, TensorFlow Implementation and stacked autoencoders, TensorFlow Implementation TensorBoard, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard tf.abs(), ℓ1 and ℓ2 Regularization tf.add(), Modularity, ℓ1 and ℓ2 Regularization-ℓ1 and ℓ2 Regularization tf.add_n(), Modularity-Sharing Variables, Sharing Variables-Sharing Variables tf.add_to_collection(), Max-Norm Regularization tf.assign(), Manually Computing the Gradients, Reusing Models from Other Frameworks, Max-Norm Regularization-Max-Norm Regularization, Chapter 9: Up and Running with TensorFlow tf.bfloat16, Bandwidth saturation tf.bool, Implementing Batch Normalization with TensorFlow, Dropout tf.cast(), Construction Phase, Training a Sequence Classifier tf.clip_by_norm(), Max-Norm Regularization-Max-Norm Regularization tf.clip_by_value(), Gradient Clipping tf.concat(), Exercises, GoogLeNet, Neural Network Policies, Policy Gradients tf.ConfigProto, Managing the GPU RAM, Logging placements-Soft placement, In-Graph Versus Between-Graph Replication, Chapter 12: Distributing TensorFlow Across Devices and Servers tf.constant(), Lifecycle of a Node Value-Manually Computing the Gradients, Simple placement-Dynamic placement function, Control Dependencies, Opening a Session-Pinning Operations Across Tasks tf.constant_initializer(), Sharing Variables-Sharing Variables tf.container(), Sharing State Across Sessions Using Resource Containers- Asynchronous Communication Using TensorFlow Queues, TensorFlow implementation-Exercises, Chapter 9: Up and Running with TensorFlow tf.contrib.framework.arg_scope(), Implementing Batch Normalization with TensorFlow, TensorFlow Implementation, Variational Autoencoders tf.contrib.layers.batch_norm(), Implementing Batch Normalization with TensorFlow-Implementing Batch Normalization with TensorFlow tf.contrib.layers.convolution2d(), Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.contrib.layers.fully_connected(), Construction Phase tf.contrib.layers.l1_regularizer(), ℓ1 and ℓ2 Regularization, Max-Norm Regularization tf.contrib.layers.l2_regularizer(), ℓ1 and ℓ2 Regularization, TensorFlow Implementation-Tying Weights tf.contrib.layers.variance_scaling_initializer(), Xavier and He Initialization-Xavier and He Initialization, Training a Sequence Classifier, TensorFlow Implementation-Tying Weights, Variational Autoencoders, Neural Network Policies, Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.contrib.learn.DNNClassifier, Training an MLP with TensorFlow’s High-Level API tf.contrib.learn.infer_real_valued_columns_from_input(), Training an MLP with TensorFlow’s High-Level API tf.contrib.rnn.BasicLSTMCell, LSTM Cell, Peephole Connections tf.contrib.rnn.BasicRNNCell, Static Unrolling Through Time-Dynamic Unrolling Through Time, Training a Sequence Classifier, Training to Predict Time Series-Training to Predict Time Series, Training to Predict Time Series, Deep RNNs-Applying Dropout, LSTM Cell tf.contrib.rnn.DropoutWrapper, Applying Dropout tf.contrib.rnn.GRUCell, GRU Cell tf.contrib.rnn.LSTMCell, Peephole Connections tf.contrib.rnn.MultiRNNCell, Deep RNNs-Applying Dropout tf.contrib.rnn.OutputProjectionWrapper, Training to Predict Time Series-Training to Predict Time Series tf.contrib.rnn.RNNCell, Distributing a Deep RNN Across Multiple GPUs tf.contrib.rnn.static_rnn(), Basic RNNs in TensorFlow-Handling Variable Length Input Sequences, An Encoder–Decoder Network for Machine Translation-Exercises, Chapter 14: Recurrent Neural Networks- \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRQuestionEncoderTokenizer, DPRQuestionEncoder, pipeline\n",
        "from rank_bm25 import BM25Okapi\n",
        "import torch\n",
        "\n",
        "# Reusing the functions defined in Step 3\n",
        "\n",
        "# RAG system\n",
        "def rag_system(query, tree_indexes):\n",
        "    all_retrieved_content = []\n",
        "    for tree in tree_indexes:\n",
        "        corpus = [node.content for node in tree.children if node.content.strip()]\n",
        "        retrieved_content = hybrid_retrieve(query, corpus)\n",
        "        all_retrieved_content.extend(retrieved_content)\n",
        "    return all_retrieved_content\n",
        "\n",
        "# Example query\n",
        "query = \"Explain the concept of Deep Learning.\"\n",
        "response = rag_system(query, tree_indexes)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjjtkb32pkCA",
        "outputId": "3e901000-7b15-4aeb-ac07-822ce55d55ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Networks tf.nn.elu(), Nonsaturating Activation Functions, TensorFlow Implementation-Tying Weights, Variational Autoencoders, Neural Network Policies, Policy Gradients tf.nn.embedding_lookup(), Word Embeddings tf.nn.in_top_k(), Construction Phase, Training a Sequence Classifier tf.nn.max_pool(), Pooling Layer-Pooling Layer tf.nn.relu(), Construction Phase, Training to Predict Time Series-Training to Predict Time Series, Training to Predict Time Series, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.nn.sigmoid_cross_entropy_with_logits(), TensorFlow Implementation, Generating Digits, Policy Gradients-Policy Gradients tf.nn.sparse_softmax_cross_entropy_with_logits(), Construction Phase- Construction Phase, Training a Sequence Classifier tf.one_hot(), Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.PaddingFIFOQueue, PaddingFifoQueue tf.placeholder(), Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm, Chapter 9: Up and Running with TensorFlow tf.placeholder_with_default(), TensorFlow Implementation tf.RandomShuffleQueue, RandomShuffleQueue, Reading the training data directly from the graph-Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner- Other convenience functions tf.random_normal(), Modularity, Basic RNNs in TensorFlow, TensorFlow Implementation, Variational Autoencoders tf.random_uniform(), Manually Computing the Gradients, Saving and Restoring Models, Word Embeddings, Chapter 9: Up and Running with TensorFlow tf.reduce_mean(), Manually Computing the Gradients, Name Scopes, Construction Phase-Construction Phase, ℓ1 and ℓ2 Regularization, Training a Sequence Classifier-Training a Sequence Classifier, Performing PCA with an Undercomplete Linear Autoencoder, TensorFlow Implementation, Training One Autoencoder at a Time, Training One Autoencoder at a Time, TensorFlow Implementation, TensorFlow Implementation, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.reduce_sum(), ℓ1 and ℓ2 Regularization, TensorFlow Implementation- TensorFlow Implementation, Variational Autoencoders-Generating Digits, Learning to Play Ms. Pac-Man Using Deep Q-Learning-Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.reset_default_graph(), Managing Graphs tf.reshape(), Training to Predict Time Series, Learning to Play Ms. Pac- Man Using Deep Q-Learning tf.RunOptions, In-Graph Versus Between-Graph Replication tf.Session, Creating Your First Graph and Running It in a Session, ', 'tf.variable_scope(), Sharing Variables-Sharing Variables, Reusing Models from Other Frameworks, Max-Norm Regularization-Max-Norm Regularization, Sharing State Across Sessions Using Resource Containers, Training a Sequence Classifier, Learning to Play Ms. Pac- Man Using Deep Q-Learning tf.zeros(), Construction Phase, Basic RNNs in TensorFlow, Tying Weights truncated backpropagation through time, The Difficulty of Training over Many Time Steps visualizing graph and training curves, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard TensorFlow Serving, One Neural Network per Device tensorflow.contrib, Construction Phase test set, Testing and Validating, Create a Test Set-Create a Test Set, MNIST testing and validating, Testing and Validating-Testing and Validating text attributes, Handling Text and Categorical Attributes-Handling Text and Categorical Attributes TextLineReader, Reading the training data directly from the graph TF-slim, Up and Running with TensorFlow TF.Learn, Up and Running with TensorFlow, Training an MLP with TensorFlow’s High-Level API thermal equilibrium, Boltzmann Machines thread pools (inter-op/intra-op, in TensorFlow, Parallel Execution threshold variable, Sharing Variables-Sharing Variables Tikhonov regularization, Ridge Regression time series data, Recurrent Neural Networks toarray(), Handling Text and Categorical Attributes tolerance hyperparameter, Computational Complexity trainable, Reusing a TensorFlow Model training data, What Is Machine Learning? insufficient quantities, Insufficient Quantity of Training Data irrelevant features, Irrelevant Features loading, Loading Data Directly from the Graph-Other convenience functions nonrepresentative, Nonrepresentative Training Data overfitting, Overfitting the Training Data-Overfitting the Training Data poor quality, Poor-Quality Data underfitting, Underfitting the Training Data training instance, What Is Machine Learning? training models, Model-based learning, Training Models-Exercises learning curves in, Learning Curves-Learning Curves Linear Regression, Training Models, Linear Regression-Mini-batch Gradient Descent Logistic Regression, Logistic Regression-Softmax Regression overview, Training Models-Training Models Polynomial Regression, Training Models, Polynomial Regression- Polynomial Regression training objectives, Training Objective-Training Objective training set, What Is Machine Learning?, Testing and Validating, Discover and Visualize the Data to Gain Insights, Prepare the Data for Machine Learning Algorithms, Training and Evaluating on the Training Set-Training and Evaluating on the Training Set cost function of, Training and Cost Function-Training and Cost Function shuffling, MNIST transfer learning, Reusing Pretrained Layers-Pretraining on an Auxiliary Task (see also pretrained layers reuse) transform(), Data Cleaning, Transformation Pipelines transformation pipelines, Transformation Pipelines-Select and Train a Model transformers, Data Cleaning transformers, custom, Custom Transformers-Custom Transformers transpose(), Static Unrolling Through Time true negative rate (TNR), The ROC Curve true positive rate (TPR), Confusion Matrix, The ROC Curve truncated backpropagation through time, The Difficulty of Training over Many Time Steps tuples, Queues of tuples tying weights, Tying Weights U underfitting, Underfitting the Training Data, Training and Evaluating on the Training Set, Gaussian RBF Kernel univariate regression, Frame the Problem unstack(), Static Unrolling Through Time unsupervised learning, Unsupervised learning-Unsupervised learning anomaly detection, Unsupervised learning association rule learning, Unsupervised learning, Unsupervised learning clustering, Unsupervised learning dimensionality reduction algorithm, Unsupervised learning visualization algorithms, Unsupervised learning unsupervised pretraining, Unsupervised Pretraining-Unsupervised Pretraining, Unsupervised Pretraining Using Stacked Autoencoders- Unsupervised Pretraining Using Stacked Autoencoders upsampling, ResNet utility function, Model-based learning V validation set, Testing and Validating Value Iteration, Markov Decision Processes value_counts(), Take a Quick Look at the Data Structure vanishing gradients, Vanishing/Exploding Gradients Problems (see also gradients, vanishing and exploding) variables, sharing, Sharing Variables-Sharing Variables variable_scope(), Sharing Variables-Sharing Variables variance bias/variance tradeoff, Learning Curves variance preservation, Preserving the Variance-Preserving the Variance variance_scaling_initializer(), Xavier and He Initialization variational autoencoders, Variational Autoencoders-Generating Digits VGGNet, ResNet visual cortex, The Architecture of the Visual Cortex visualization, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard visualization algorithms, Unsupervised learning-Unsupervised learning voice recognition, Convolutional Neural Networks voting classifiers, Voting Classifiers-Voting Classifiers W warmup phase, Asynchronous updates weak learners, Voting Classifiers weight-tying, Tying Weights weights, Construction Phase, Reusing Models from Other Frameworks freezing, Freezing the Lower Layers while_loop(), Dynamic Unrolling Through Time white box models, Making Predictions worker, Multiple Devices Across Multiple Servers worker service, The Master and Worker Services worker_device, Sharding Variables Across Multiple Parameter Servers workspace directory, Get the Data-Download the Data X Xavier initialization, Vanishing/Exploding Gradients Problems-Xavier and He Initialization Y YouTube, Introduction to Artificial Neural Networks Z zero padding, Convolutional Layer, TensorFlow Implementation About the Author Aurélien Géron is a Machine Learning consultant. A former Googler, he led the YouTube video classification team from 2013 to 2016. He was also a founder and CTO of Wifirst from 2002 to 2012, a leading Wireless ISP in France; and a founder and CTO of Polyconseil in 2001, the firm that now manages the electric car sharing service Autolib’. Before this he worked as an engineer in a variety of domains: finance (JP Morgan and Société Générale), defense (Canada’s DOD), and healthcare (blood transfusion). He published a few technical books (on C++, WiFi, and internet architectures), and was a Computer Science lecturer in a French engineering school. A few fun facts: he taught his three children to count in binary with their fingers (up to 1023), he studied microbiology and evolutionary genetics before going into software engineering, and his parachute didn’t open on the second jump. Colophon The animal on the cover of Hands-On Machine Learning with Scikit-Learn and TensorFlow is the far eastern fire salamander (Salamandra infraimmaculata), an amphibian found in the Middle East. They have black skin featuring large yellow spots on their back and head. These spots are a warning coloration meant to keep predators at bay. Full-grown salamanders can be over a foot in length. Far eastern fire salamanders live in subtropical shrubland and forests near rivers or other freshwater bodies. They spend most of their life on land, but lay their eggs in the water. They subsist mostly on a diet of insects, worms, and small crustaceans, but occasionally eat other salamanders. Males of the species have been known to live up to 23 years, while females can live up to 21 years. Although not yet endangered, the far eastern fire salamander population is in decline. Primary threats include damming of rivers (which disrupts the salamander’s breeding) and pollution. They are also threatened by the recent introduction of predatory fish, such as the mosquitofish. These fish were intended to control the mosquito population, but they also feed on young salamanders. Many of the animals on O’Reilly covers are endangered; all of them are important to the world. To learn more about how you can help, go to animals.oreilly.com. The cover image is from Wood’s Illustrated Natural History. The cover fonts are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu Mono. Preface The Machine Learning Tsunami Machine Learning in Your Projects Objective and Approach Prerequisites Roadmap Other Resources Conventions Used in This Book Using Code Examples O’Reilly Safari How to Contact Us Acknowledgments I. The Fundamentals of Machine Learning 1. The Machine Learning Landscape What Is Machine Learning? Why Use Machine Learning? Types of Machine Learning Systems Supervised/Unsupervised Learning Batch and Online Learning Instance-Based Versus Model-Based Learning Main Challenges of Machine Learning Insufficient Quantity of Training Data Nonrepresentative Training Data Poor-Quality Data Irrelevant Features Overfitting the Training Data Underfitting the Training Data Stepping Back Testing and Validating Exercises 2. End-to-End Machine Learning Project Working with Real Data Look at the Big Picture Frame the Problem Select a Performance Measure Check the Assumptions Get the Data Create the Workspace Download the Data Take a Quick Look at the Data Structure Create a Test Set Discover and Visualize the Data to Gain Insights Visualizing Geographical Data Looking for Correlations Experimenting with Attribute Combinations Prepare the Data for Machine Learning Algorithms Data Cleaning Handling Text and Categorical Attributes Custom Transformers Feature Scaling Transformation Pipelines Select and Train a Model Training and Evaluating on the Training Set Better Evaluation Using Cross-Validation Fine-Tune Your Model Grid Search Randomized Search Ensemble Methods Analyze the Best Models and Their Errors Evaluate Your System on the Test Set Launch, Monitor, and Maintain Your System Try It Out! Exercises 3. Classification MNIST Training a Binary Classifier Performance Measures Measuring Accuracy Using Cross-Validation Confusion Matrix Precision and Recall Precision/Recall Tradeoff The ROC Curve Multiclass Classification Error Analysis Multilabel Classification Multioutput Classification Exercises 4. Training Models Linear Regression The Normal Equation Computational Complexity Gradient Descent Batch Gradient Descent Stochastic Gradient Descent Mini-batch Gradient Descent Polynomial Regression Learning Curves Regularized Linear Models Ridge Regression Lasso Regression Elastic Net Early Stopping Logistic Regression Estimating Probabilities Training and Cost Function Decision Boundaries Softmax Regression Exercises 5. Support Vector Machines Linear SVM Classification Soft Margin Classification Nonlinear SVM Classification Polynomial Kernel Adding Similarity Features Gaussian RBF Kernel Computational Complexity SVM Regression Under the Hood Decision Function and Predictions Training Objective Quadratic Programming The Dual Problem Kernelized SVM Online SVMs Exercises 6. Decision Trees Training and Visualizing a Decision Tree Making Predictions Estimating Class Probabilities The CART Training Algorithm Computational Complexity Gini Impurity or Entropy? Regularization Hyperparameters Regression Instability Exercises 7. Ensemble Learning and Random Forests Voting Classifiers Bagging and Pasting Bagging and Pasting in Scikit-Learn Out-of-Bag Evaluation Random Patches and Random Subspaces Random Forests Extra-Trees Feature Importance Boosting AdaBoost Gradient Boosting Stacking Exercises 8. Dimensionality Reduction The Curse of Dimensionality Main Approaches for Dimensionality Reduction Projection Manifold Learning PCA Preserving the Variance Principal Components Projecting Down to d Dimensions Using Scikit-Learn Explained Variance Ratio Choosing the Right Number of Dimensions PCA for Compression Incremental PCA Randomized PCA Kernel PCA Selecting a Kernel and Tuning Hyperparameters LLE Other Dimensionality Reduction Techniques Exercises II. Neural Networks and Deep Learning 9. Up and Running with TensorFlow Installation Creating Your First Graph and Running It in a Session Managing Graphs Lifecycle of a Node Value Linear Regression with TensorFlow Implementing Gradient Descent Manually Computing the Gradients Using autodiff Using an Optimizer Feeding Data to the Training Algorithm Saving and Restoring Models Visualizing the Graph and Training Curves Using TensorBoard Name Scopes Modularity Sharing Variables Exercises 10. Introduction to Artificial Neural Networks From Biological to Artificial Neurons Biological Neurons Logical Computations with Neurons The Perceptron Multi-Layer Perceptron and Backpropagation Training an MLP with TensorFlow’s High-Level API Training a DNN Using Plain TensorFlow Construction Phase Execution Phase Using the Neural Network Fine-Tuning Neural Network Hyperparameters Number of Hidden Layers Number of Neurons per Hidden Layer Activation Functions Exercises 11. Training Deep Neural Nets Vanishing/Exploding Gradients Problems Xavier and He Initialization Nonsaturating Activation Functions Batch Normalization Gradient Clipping Reusing Pretrained Layers Reusing a TensorFlow Model Reusing Models from Other Frameworks Freezing the Lower Layers Caching the Frozen Layers Tweaking, Dropping, or Replacing the Upper Layers Model Zoos Unsupervised Pretraining Pretraining on an Auxiliary Task Faster Optimizers Momentum optimization Nesterov Accelerated Gradient AdaGrad RMSProp Adam Optimization Learning Rate Scheduling Avoiding Overfitting Through Regularization Early Stopping ℓ1 and ℓ2 Regularization Dropout Max-Norm Regularization Data Augmentation Practical Guidelines Exercises 12. Distributing TensorFlow Across Devices and Servers Multiple Devices on a Single Machine Installation Managing the GPU RAM Placing Operations on Devices Parallel Execution Control Dependencies Multiple Devices Across Multiple Servers Opening a Session The Master and Worker Services Pinning Operations Across Tasks Sharding Variables Across Multiple Parameter Servers Sharing State Across Sessions Using Resource Containers Asynchronous Communication Using TensorFlow Queues Loading Data Directly from the Graph Parallelizing Neural Networks on a TensorFlow Cluster One Neural Network per Device In-Graph Versus Between-Graph Replication Model Parallelism Data Parallelism Exercises 13. Convolutional Neural Networks The Architecture of the Visual Cortex Convolutional Layer Filters Stacking Multiple Feature Maps TensorFlow Implementation Memory Requirements Pooling Layer CNN Architectures LeNet-5 AlexNet GoogLeNet ResNet Exercises 14. Recurrent Neural Networks Recurrent Neurons Memory Cells Input and Output Sequences Basic RNNs in TensorFlow Static Unrolling Through Time Dynamic Unrolling Through Time Handling Variable Length Input Sequences Handling Variable-Length Output Sequences Training RNNs Training a Sequence Classifier Training to Predict Time Series Creative RNN Deep RNNs Distributing a Deep RNN Across Multiple GPUs Applying Dropout The Difficulty of Training over Many Time Steps LSTM Cell Peephole Connections GRU Cell Natural Language Processing Word Embeddings An Encoder–Decoder Network for Machine Translation Exercises 15. Autoencoders Efficient Data Representations Performing PCA with an Undercomplete Linear Autoencoder Stacked Autoencoders TensorFlow Implementation Tying Weights Training One Autoencoder at a Time Visualizing the Reconstructions Visualizing Features Unsupervised Pretraining Using Stacked Autoencoders Denoising Autoencoders TensorFlow Implementation Sparse Autoencoders TensorFlow Implementation Variational Autoencoders Generating Digits Other Autoencoders Exercises 16. Reinforcement Learning Learning to Optimize Rewards Policy Search Introduction to OpenAI Gym Neural Network Policies Evaluating Actions: The Credit Assignment Problem Policy Gradients Markov Decision Processes Temporal Difference Learning and Q-Learning Exploration Policies Approximate Q-Learning Learning to Play Ms. Pac-Man Using Deep Q-Learning Exercises Thank You! A. Exercise Solutions ', 'tf.shape(), TensorFlow Implementation, Variational Autoencoders tf.square(), Manually Computing the Gradients, Name Scopes, Training to Predict Time Series, Performing PCA with an Undercomplete Linear Autoencoder, TensorFlow Implementation, Training One Autoencoder at a Time, Training One Autoencoder at a Time, TensorFlow Implementation, TensorFlow Implementation, Variational Autoencoders- Generating Digits, Learning to Play Ms. Pac-Man Using Deep Q- Learning tf.stack(), Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner, Static Unrolling Through Time tf.string, Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner tf.summary.FileWriter, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard tf.summary.scalar(), Visualizing the Graph and Training Curves Using TensorBoard tf.tanh(), Basic RNNs in TensorFlow tf.TextLineReader, Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner tf.to_float(), Policy Gradients-Policy Gradients tf.train.AdamOptimizer, Faster Optimizers, Adam Optimization, Training a Sequence Classifier, Training to Predict Time Series, Performing PCA with an Undercomplete Linear Autoencoder, TensorFlow Implementation-Tying Weights, Training One Autoencoder at a Time, TensorFlow Implementation, Generating Digits, Policy Gradients-Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.train.ClusterSpec, Multiple Devices Across Multiple Servers tf.train.Coordinator, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner tf.train.exponential_decay(), Learning Rate Scheduling tf.train.GradientDescentOptimizer, Using an Optimizer, Construction Phase, Gradient Clipping, Faster Optimizers, Momentum optimization tf.train.MomentumOptimizer, Using an Optimizer, Momentum optimization-Nesterov Accelerated Gradient, Learning Rate Scheduling, Exercises, TensorFlow implementation, Chapter 10: Introduction to Artificial Neural Networks-Chapter 11: Training Deep Neural Nets tf.train.QueueRunner, Multithreaded readers using a Coordinator and a QueueRunner-Other convenience functions tf.train.replica_device_setter(), Sharding Variables Across Multiple Parameter Servers-Sharing State Across Sessions Using Resource Containers tf.train.RMSPropOptimizer, RMSProp tf.train.Saver, Saving and Restoring Models-Saving and Restoring Models, Construction Phase, Exercises, Applying Dropout, Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.train.Server, Multiple Devices Across Multiple Servers tf.train.start_queue_runners(), Other convenience functions tf.transpose(), Linear Regression with TensorFlow-Manually Computing the Gradients, Static Unrolling Through Time, Tying Weights tf.truncated_normal(), Construction Phase tf.unstack(), Static Unrolling Through Time-Dynamic Unrolling Through Time, Training to Predict Time Series, Chapter 14: Recurrent Neural Networks tf.Variable, Creating Your First Graph and Running It in a Session, ', \"1. Reinforcement Learning is an area of Machine Learning aimed at creating agents capable of taking actions in an environment in a way that maximizes rewards over time. There are many differences between RL and regular supervised and unsupervised learning. Here are a few: In supervised and unsupervised learning, the goal is generally to find patterns in the data. In Reinforcement Learning, the goal is to find a good policy. Unlike in supervised learning, the agent is not explicitly given the “right” answer. It must learn by trial and error. Unlike in unsupervised learning, there is a form of supervision, through rewards. We do not tell the agent how to perform the task, but we do tell it when it is making progress or when it is failing. A Reinforcement Learning agent needs to find the right balance between exploring the environment, looking for new ways of getting rewards, and exploiting sources of rewards that it already knows. In contrast, supervised and unsupervised learning systems generally don’t need to worry about exploration; they just feed on the training data they are given. In supervised and unsupervised learning, training instances are typically independent (in fact, they are generally shuffled). In Reinforcement Learning, consecutive observations are generally not independent. An agent may remain in the same region of the environment for a while before it moves on, so consecutive observations will be very correlated. In some cases a replay memory is used to ensure that the training algorithm gets fairly independent observations. 2. Here are a few possible applications of Reinforcement Learning, other than those mentioned in Chapter 16: Music personalization The environment is a user’s personalized web radio. The agent is the software deciding what song to play next for that user. Its possible actions are to play any song in the catalog (it must try to choose a song the user will enjoy) or to play an advertisement (it must try to choose an ad that the user will be interested in). It gets a small reward every time the user listens to a song, a larger reward every time the user listens to an ad, a negative reward when the user skips a song or an ad, and a very negative reward if the user leaves. Marketing The environment is your company’s marketing department. The agent is the software that defines which customers a mailing campaign should be sent to, given their profile and purchase history (for each customer it has two possible actions: send or don’t send). It gets a negative reward for the cost of the mailing campaign, and a positive reward for estimated revenue generated from this campaign. Product delivery Let the agent control a fleet of delivery trucks, deciding what they should pick up at the depots, where they should go, what they should drop off, and so on. They would get positive rewards for each product delivered on time, and negative rewards for late deliveries. 3. When estimating the value of an action, Reinforcement Learning algorithms typically sum all the rewards that this action led to, giving more weight to immediate rewards, and less weight to later rewards (considering that an action has more influence on the near future than on the distant future). To model this, a discount rate is typically applied at each time step. For example, with a discount rate of 0.9, a reward of 100 that is received two time steps later is counted as only 0.92 × 100 = 81 when you are estimating the value of the action. You can think of the discount rate as a measure of how much the future is valued relative to the present: if it is very close to 1, then the future is valued almost as much as the present. If it is close to 0, then only immediate rewards matter. Of course, this impacts the optimal policy tremendously: if you value the future, you may be willing to put up with a lot of immediate pain for the prospect of eventual rewards, while if you don’t value the future, you will just grab any immediate reward you can find, never investing in the future. 4. To measure the performance of a Reinforcement Learning agent, you can simply sum up the rewards it gets. In a simulated environment, you can run many episodes and look at the total rewards it gets on average (and possibly look at the min, max, standard deviation, and so on). 5. The credit assignment problem is the fact that when a Reinforcement Learning agent receives a reward, it has no direct way of knowing which of its previous actions contributed to this reward. It typically occurs when there is a large delay between an action and the resulting rewards (e.g., during a game of Atari’s Pong, there may be a few dozen time steps between the moment the agent hits the ball and the moment it wins the point). One way to alleviate it is to provide the agent with shorter-term rewards, when possible. This usually requires prior knowledge about the task. For example, if we want to build an agent that will learn to play chess, instead of giving it a reward only when it wins the game, we could give it a reward every time it captures one of the opponent’s pieces. 6. An agent can often remain in the same region of its environment for a while, so all of its experiences will be very similar for that period of time. This can introduce some bias in the learning algorithm. It may tune its policy for this region of the environment, but it will not perform well as soon as it moves out of this region. To solve this problem, you can use a replay memory; instead of using only the most immediate experiences for learning, the agent will learn based on a buffer of its past experiences, recent and not so recent (perhaps this is why we dream at night: to replay our experiences of the day and better learn from them?). 7. An off-policy RL algorithm learns the value of the optimal policy (i.e., the sum of discounted rewards that can be expected for each state if the agent acts optimally), independently of how the agent actually acts. Q- Learning is a good example of such an algorithm. In contrast, an on- policy algorithm learns the value of the policy that the agent actually executes, including both exploration and exploitation. For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at https://github.com/ageron/handson-ml. If you draw a straight line between any two points on the curve, the line never crosses the curve. Moreover, the Normal Equation requires computing the inverse of a matrix, but that matrix is not always invertible. In contrast, the matrix for Ridge Regression is always invertible. log2 is the binary log, log2(m) = log(m) / log(2). When the values to predict can vary by many orders of magnitude, then you may want to predict the logarithm of the target value rather than the target value directly. Simply computing the exponential of the neural network’s output will give you the estimated value (since exp(log v) = v). In Chapter 11 we discuss many techniques that introduce additional hyperparameters: type of weight initialization, activation function hyperparameters (e.g., amount of leak in leaky ReLU), Gradient Clipping threshold, type of optimizer and its hyperparameters (e.g., the momentum hyperparameter when using a MomentumOptimizer), type of regularization for each layer, and the regularization hyperparameters (e.g., dropout rate when using dropout) and so on. 1 2 3 4 5 Appendix B. Machine Learning Project Checklist This checklist can guide you through your Machine Learning projects. There are eight main steps: 1. Frame the problem and look at the big picture. 2. Get the data. 3. Explore the data to gain insights. 4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms. 5. Explore many different models and short-list the best ones. 6. Fine-tune your models and combine them into a great solution. 7. Present your solution. 8. Launch, monitor, and maintain your system. Obviously, you should feel free to adapt this checklist to your needs. Frame the Problem and Look at the Big Picture 1. Define the objective in business terms. 2. How will your solution be used? 3. What are the current solutions/workarounds (if any)? 4. How should you frame this problem (supervised/unsupervised, online/offline, etc.)? 5. How should performance be measured? 6. Is the performance measure aligned with the business objective? 7. What would be the minimum performance needed to reach the business objective? 8. What are comparable problems? Can you reuse experience or tools? 9. Is human expertise available? 10. How would you solve the problem manually? 11. List the assumptions you (or others) have made so far. 12. Verify assumptions if possible. Get the Data Note: automate as much as possible so you can easily get fresh data. 1. List the data you need and how much you need. 2. Find and document where you can get that data. 3. Check how much space it will take. 4. Check legal obligations, and get authorization if necessary. 5. Get access authorizations. 6. Create a workspace (with enough storage space). 7. Get the data. 8. Convert the data to a format you can easily manipulate (without changing the data itself). 9. Ensure sensitive information is deleted or protected (e.g., anonymized). 10. Check the size and type of data (time series, sample, geographical, etc.). 11. Sample a test set, put it aside, and never look at it (no data snooping!). Explore the Data Note: try to get insights from a field expert for these steps. 1. Create a copy of the data for exploration (sampling it down to a manageable size if necessary). 2. Create a Jupyter notebook to keep a record of your data exploration. 3. Study each attribute and its characteristics: Name Type (categorical, int/float, bounded/unbounded, text, structured, etc.) % of missing values Noisiness and type of noise (stochastic, outliers, rounding errors, etc.) Possibly useful for the task? Type of distribution (Gaussian, uniform, logarithmic, etc.) 4. For supervised learning tasks, identify the target attribute(s). 5. Visualize the data. 6. Study the correlations between attributes. 7. Study how you would solve the problem manually. 8. Identify the promising transformations you may want to apply. 9. Identify extra data that would be useful (go back to “Get the Data”). 10. Document what you have learned. Prepare the Data Notes: Work on copies of the data (keep the original dataset intact). Write functions for all data transformations you apply, for five reasons: So you can easily prepare the data the next time you get a fresh dataset So you can apply these transformations in future projects To clean and prepare the test set To clean and prepare new data instances once your solution is live To make it easy to treat your preparation choices as hyperparameters 1. Data cleaning: Fix or remove outliers (optional). Fill in missing values (e.g., with zero, mean, median…) or drop their rows (or columns). 2. Feature selection (optional): Drop the attributes that provide no useful information for the task. 3. Feature engineering, where appropriate: Discretize continuous features. Decompose features (e.g., categorical, date/time, etc.). Add promising transformations of features (e.g., log(x), sqrt(x), x^2, etc.). Aggregate features into promising new features. 4. Feature scaling: standardize or normalize features. Short-List Promising Models Notes: If the data is huge, you may want to sample smaller training sets so you can train many different models in a reasonable time (be aware that this penalizes complex models such as large neural nets or Random Forests). Once again, try to automate these steps as much as possible. 1. Train many quick and dirty models from different categories (e.g., linear, naive Bayes, SVM, Random Forests, neural net, etc.) using standard parameters. 2. Measure and compare their performance. For each model, use N-fold cross-validation and compute the mean and standard deviation of the performance measure on the N folds. 3. Analyze the most significant variables for each algorithm. 4. Analyze the types of errors the models make. What data would a human have used to avoid these errors? 5. Have a quick round of feature selection and engineering. 6. Have one or two more quick iterations of the five previous steps. 7. Short-list the top three to five most promising models, preferring models that make different types of errors. Fine-Tune the System Notes: You will want to use as much data as possible for this step, especially as you move toward the end of fine-tuning. As always automate what you can. 1. Fine-tune the hyperparameters using cross-validation. Treat your data transformation choices as hyperparameters, especially when you are not sure about them (e.g., should I replace missing values with zero or with the median value? Or just drop the rows?). Unless there are very few hyperparameter values to explore, prefer random search over grid search. If training is very long, you may prefer a Bayesian optimization approach (e.g., using Gaussian process priors, as described by Jasper Snoek, Hugo Larochelle, and Ryan Adams).1 2. Try Ensemble methods. Combining your best models will often perform better than running them individually. 3. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error. WARNING Don’t tweak your model after measuring the generalization error: you would just start overfitting the test set. Present Your Solution 1. Document what you have done. 2. Create a nice presentation. Make sure you highlight the big picture first. 3. Explain why your solution achieves the business objective. 4. Don’t forget to present interesting points you noticed along the way. Describe what worked and what did not. List your assumptions and your system’s limitations. 5. Ensure your key findings are communicated through beautiful visualizations or easy-to-remember statements (e.g., “the median income is the number-one predictor of housing prices”). Launch! 1. Get your solution ready for production (plug into production data inputs, write unit tests, etc.). 2. Write monitoring code to check your system’s live performance at regular intervals and trigger alerts when it drops. Beware of slow degradation too: models tend to “rot” as data evolves. Measuring performance may require a human pipeline (e.g., via a crowdsourcing service). Also monitor your inputs’ quality (e.g., a malfunctioning sensor sending random values, or another team’s output becoming stale). This is particularly important for online learning systems. 3. Retrain your models on a regular basis on fresh data (automate as much as possible). “Practical Bayesian Optimization of Machine Learning Algorithms,” J. Snoek, H. Larochelle, R. Adams (2012). 1 Appendix C. SVM Dual Problem To understand duality, you first need to understand the Lagrange multipliers method. The general idea is to transform a constrained optimization objective into an unconstrained one, by moving the constraints into the objective function. Let’s look at a simple example. Suppose you want to find the values of x and y that minimize the function f(x,y) = x2 + 2y, subject to an equality constraint: 3x + 2y + 1 = 0. Using the Lagrange multipliers method, we start by defining a new function called the Lagrangian (or Lagrange function): g(x, y, α) = f(x, y) – α(3x + 2y + 1). Each constraint (in this case just one) is subtracted from the original objective, multiplied by a new variable called a Lagrange multiplier. Joseph-Louis Lagrange showed that if is a solution to the constrained optimization problem, then there must exist an  such that is a stationary point of the Lagrangian (a stationary point is a point where all partial derivatives are equal to zero). In other words, we can compute the partial derivatives of g(x, y, α) with regards to x, y, and α; we can find the points where these derivatives are all equal to zero; and the solutions to the constrained optimization problem (if they exist) must be among these stationary points. In this example the partial derivatives are: When all these partial derivatives are equal to 0, we find that , from which we can easily find that , , and . This is the only stationary point, and as it respects the constraint, it must be the solution to the constrained optimization problem. However, this method applies only to equality constraints. Fortunately, under some regularity conditions (which are respected by the SVM objectives), this method can be generalized to inequality constraints as well (e.g., 3x + 2y + 1 ≥ 0). The generalized Lagrangian for the hard margin problem is given by Equation C-1, where the α(i) variables are called the Karush–Kuhn–Tucker (KKT) multipliers, and they must be greater or equal to zero. Equation C-1. Generalized Lagrangian for the hard margin problem Just like with the Lagrange multipliers method, you can compute the partial derivatives and locate the stationary points. If there is a solution, it will necessarily be among the stationary points that respect the KKT conditions: Respect the problem’s constraints: , Verify , Either or the ith constraint must be an active constraint, meaning it must hold by equality: . This condition is called the complementary slackness condition. It implies that either or the ith instance lies on the boundary (it is a support vector). Note that the KKT conditions are necessary conditions for a stationary point to be a solution of the constrained optimization problem. Under some conditions, they are also sufficient conditions. Luckily, the SVM optimization problem happens to meet these conditions, so any stationary point that meets the KKT conditions is guaranteed to be a solution to the constrained optimization problem. We can compute the partial derivatives of the generalized Lagrangian with regards to w and b with Equation C-2. Equation C-2. Partial derivatives of the generalized Lagrangian When these partial derivatives are equal to 0, we have Equation C-3. Equation C-3. Properties of the stationary points If we plug these results into the definition of the generalized Lagrangian, some terms disappear and we find Equation C-4. Equation C-4. Dual form of the SVM problem The goal is now to find the vector  that minimizes this function, with for all instances. This constrained optimization problem is the dual problem we were looking for. Once you find the optimal , you can compute using the first line of Equation C-3. To compute , you can use the fact that a support vector verifies t(i)(wT · x(i) + b) = 1, so if the kth instance is a support vector (i.e., αk > 0), you can use it to compute . However, it is often prefered to compute the average over all support vectors to get a more stable and precise value, as in Equation C-5. Equation C-5. Bias term estimation using the dual form Appendix D. Autodiff This appendix explains how TensorFlow’s autodiff feature works, and how it compares to other solutions. Suppose you define a function f(x,y) = x2y + y + 2, and you need its partial derivatives and , typically to perform Gradient Descent (or some other optimization algorithm). Your main options are manual differentiation, symbolic differentiation, numerical differentiation, forward-mode autodiff, and finally reverse-mode autodiff. TensorFlow implements this last option. Let’s go through each of these options. Manual Differentiation The first approach is to pick up a pencil and a piece of paper and use your calculus knowledge to derive the partial derivatives manually. For the function f(x,y) just defined, it is not too hard; you just need to use five rules: The derivative of a constant is 0. The derivative of λx is λ (where λ is a constant). The derivative of xλ is λxλ – 1, so the derivative of x2 is 2x. The derivative of a sum of functions is the sum of these functions’ derivatives. The derivative of λ times a function is λ times its derivative. From these rules, you can derive Equation D-1: Equation D-1. Partial derivatives of f(x,y) This approach can become very tedious for more complex functions, and you run the risk of making mistakes. The good news is that deriving the mathematical equations for the partial derivatives like we just did can be automated, through a process called symbolic differentiation. Symbolic Differentiation Figure D-1 shows how symbolic differentiation works on an even simpler function, g(x,y) = 5 + xy. The graph for that function is represented on the left. After symbolic differentiation, we get the graph on the right, which represents the partial derivative (we could similarly obtain the partial derivative with regards to y). Figure D-1. Symbolic differentiation The algorithm starts by getting the partial derivative of the leaf nodes. The constant node (5) returns the constant 0, since the derivative of a constant is always 0. The variable x returns the constant 1 since , and the variable y returns the constant 0 since (if we were looking for the partial derivative with regards to y, it would be the reverse). Now we have all we need to move up the graph to the multiplication node in function g. Calculus tells us that the derivative of the product of two functions u and v is . We can therefore construct a large part of the graph on the right, representing 0 × x + y × 1. Finally, we can go up to the addition node in function g. As mentioned, the derivative of a sum of functions is the sum of these functions’ derivatives. So we just need to create an addition node and connect it to the parts of the graph we have already computed. We get the correct partial derivative: . However, it can be simplified (a lot). A few trivial pruning steps can be applied to this graph to get rid of all unnecessary operations, and we get a much smaller graph with just one node: . In this case, simplification is fairly easy, but for a more complex function, symbolic differentiation can produce a huge graph that may be tough to simplify and lead to suboptimal performance. Most importantly, symbolic differentiation cannot deal with functions defined with arbitrary code — for example, the following function discussed in Chapter 9: def my_func(a, b): z = 0 for i in range(100): z = a * np.cos(z + i) + z * np.sin(b - i) return z Numerical Differentiation The simplest solution is to compute an approximation of the derivatives, numerically. Recall that the derivative h′(x0) of a function h(x) at a point x0 is the slope of the function at that point, or more precisely Equation D-2. Equation D-2. Derivative of a function h(x) at point x0 So if we want to calculate the partial derivative of f(x,y) with regards to x, at x = 3 and y = 4, we can simply compute f(3 + ϵ, 4) – f(3, 4) and divide the result by ϵ, using a very small value for ϵ. That’s exactly what the following code does: def f(x, y): return x**2*y + y + 2 def derivative(f, x, y, x_eps, y_eps): return (f(x + x_eps, y + y_eps) - f(x, y)) / (x_eps + y_eps) df_dx = derivative(f, 3, 4, 0.00001, 0) df_dy = derivative(f, 3, 4, 0, 0.00001) Unfortunately, the result is imprecise (and it gets worse for more complex functions). The correct results are respectively 24 and 10, but instead we get: >>> print(df_dx) 24.000039999805264 >>> print(df_dy) 10.000000000331966 Notice that to compute both partial derivatives, we have to call f() at least three times (we called it four times in the preceding code, but it could be optimized). If there were 1,000 parameters, we would need to call f() at least 1,001 times. When you are dealing with large neural networks, this makes numerical differentiation way too inefficient. However, numerical differentiation is so simple to implement that it is a great tool to check that the other methods are implemented correctly. For example, if it disagrees with your manually derived function, then your function probably contains a mistake. Forward-Mode Autodiff Forward-mode autodiff is neither numerical differentiation nor symbolic differentiation, but in some ways it is their love child. It relies on dual numbers, which are (weird but fascinating) numbers of the form a + bϵ where a and b are real numbers and ϵ is an infinitesimal number such that ϵ2 = 0 (but ϵ ≠ 0). You can think of the dual number 42 + 24ϵ as something akin to 42.0000⋯000024 with an infinite number of 0s (but of course this is simplified just to give you some idea of what dual numbers are). A dual number is represented in memory as a pair of floats. For example, 42 + 24ϵ is represented by the pair (42.0, 24.0). Dual numbers can be added, multiplied, and so on, as shown in Equation D-3. Equation D-3. A few operations with dual numbers Most importantly, it can be shown that h(a + bϵ) = h(a) + b × h′(a)ϵ, so computing h(a + ϵ) gives you both h(a) and the derivative h′(a) in just one shot. Figure D-2 shows how forward-mode autodiff computes the partial derivative of f(x,y) with regards to x at x = 3 and y = 4. All we need to do is compute f(3 + ϵ, 4); this will output a dual number whose first component is equal to f(3, 4) and whose second component is equal to . Figure D-2. Forward-mode autodiff To compute we would have to go through the graph again, but this time with x = 3 and y = 4 + ϵ. So forward-mode autodiff is much more accurate than numerical differentiation, but it suffers from the same major flaw: if there were 1,000 parameters, it would require 1,000 passes through the graph to compute all the partial derivatives. This is where reverse-mode autodiff shines: it can compute all of them in just two passes through the graph. Reverse-Mode Autodiff Reverse-mode autodiff is the solution implemented by TensorFlow. It first goes through the graph in the forward direction (i.e., from the inputs to the output) to compute the value of each node. Then it does a second pass, this time in the reverse direction (i.e., from the output to the inputs) to compute all the partial derivatives. Figure D-3 represents the second pass. During the first pass, all the node values were computed, starting from x = 3 and y = 4. You can see those values at the bottom right of each node (e.g., x × x = 9). The nodes are labeled n1 to n7 for clarity. The output node is n7: f(3,4) = n7 = 42. Figure D-3. Reverse-mode autodiff The idea is to gradually go down the graph, computing the partial derivative of f(x,y) with regards to each consecutive node, until we reach the variable nodes. For this, reverse-mode autodiff relies heavily on the chain rule, shown in Equation D-4. Equation D-4. Chain rule Since n7 is the output node, f = n7 so trivially . Let’s continue down the graph to n5: how much does f vary when n5 varies? The answer is . We already know that , so all we need is . Since n7 simply performs the sum n5 + n6, we find that , so . Now we can proceed to node n4: how much does f vary when n4 varies? The answer is . Since n5 = n4 × n2, we find that , so . The process continues until we reach the bottom of the graph. At that point we will have calculated all the partial derivatives of f(x,y) at the point x = 3 and y = 4. In this example, we find and . Sounds about right! Reverse-mode autodiff is a very powerful and accurate technique, especially when there are many inputs and few outputs, since it requires only one forward pass plus one reverse pass per output to compute all the partial derivatives for all outputs with regards to all the inputs. Most importantly, it can deal with functions defined by arbitrary code. It can also handle functions that are not entirely differentiable, as long as you ask it to compute the partial derivatives at points that are differentiable. TIP If you implement a new type of operation in TensorFlow and you want to make it compatible with autodiff, then you need to provide a function that builds a subgraph to compute its partial derivatives with regards to its inputs. For example, suppose you implement a function that computes the square of its input f(x) = x2. In that case you would need to provide the corresponding derivative function f′(x) = 2x. Note that this function does not compute a numerical result, but instead builds a subgraph that will (later) compute the result. This is very useful because it means that you can compute gradients of gradients (to compute second-order derivatives, or even higher-order derivatives). Appendix E. Other Popular ANN Architectures In this appendix we will give a quick overview of a few historically important neural network architectures that are much less used today than deep Multi- Layer Perceptrons (Chapter 10), convolutional neural networks (Chapter 13), recurrent neural networks (Chapter 14), or autoencoders (Chapter 15). They are often mentioned in the literature, and some are still used in many applications, so it is worth knowing about them. Moreover, we will discuss deep belief nets (DBNs), which were the state of the art in Deep Learning until the early 2010s. They are still the subject of very active research, so they may well come back with a vengeance in the near future. Hopfield Networks Hopfield networks were first introduced by W. A. Little in 1974, then popularized by J. Hopfield in 1982. They are associative memory networks: you first teach them some patterns, and then when they see a new pattern they (hopefully) output the closest learned pattern. This has made them useful in particular for character recognition before they were outperformed by other approaches. You first train the network by showing it examples of character images (each binary pixel maps to one neuron), and then when you show it a new character image, after a few iterations it outputs the closest learned character. They are fully connected graphs (see Figure E-1); that is, every neuron is connected to every other neuron. Note that on the diagram the images are 6 × 6 pixels, so the neural network on the left should contain 36 neurons (and 648 connections), but for visual clarity a much smaller network is represented. Figure E-1. Hopfield network The training algorithm works by using Hebb’s rule: for each training image, the weight between two neurons is increased if the corresponding pixels are both on or both off, but decreased if one pixel is on and the other is off. To show a new image to the network, you just activate the neurons that correspond to active pixels. The network then computes the output of every neuron, and this gives you a new image. You can then take this new image and repeat the whole process. After a while, the network reaches a stable state. Generally, this corresponds to the training image that most resembles the input image. A so-called energy function is associated with Hopfield nets. At each iteration, the energy decreases, so the network is guaranteed to eventually stabilize to a low-energy state. The training algorithm tweaks the weights in a way that decreases the energy level of the training patterns, so the network is likely to stabilize in one of these low-energy configurations. Unfortunately, some patterns that were not in the training set also end up with low energy, so the network sometimes stabilizes in a configuration that was not learned. These are called spurious patterns. Another major flaw with Hopfield nets is that they don’t scale very well — their memory capacity is roughly equal to 14% of the number of neurons. For example, to classify 28 × 28 images, you would need a Hopfield net with 784 fully connected neurons and 306,936 weights. Such a network would only be able to learn about 110 different characters (14% of 784). That’s a lot of parameters for such a small memory. Boltzmann Machines Boltzmann machines were invented in 1985 by Geoffrey Hinton and Terrence Sejnowski. Just like Hopfield nets, they are fully connected ANNs, but they are based on stochastic neurons: instead of using a deterministic step function to decide what value to output, these neurons output 1 with some probability, and 0 otherwise. The probability function that these ANNs use is based on the Boltzmann distribution (used in statistical mechanics) hence their name. Equation E-1 gives the probability that a particular neuron will output a 1. Equation E-1. Probability that the ith neuron will output 1 sj is the jth neuron’s state (0 or 1). wi,j is the connection weight between the ith and jth neurons. Note that wi,i = 0. bi is the ith neuron’s bias term. We can implement this term by adding a bias neuron to the network. N is the number of neurons in the network. T is a number called the network’s temperature; the higher the temperature, the more random the output is (i.e., the more the probability approaches 50%). σ is the logistic function. Neurons in Boltzmann machines are separated into two groups: visible units and hidden units (see Figure E-2). All neurons work in the same stochastic way, but the visible units are the ones that receive the inputs and from which outputs are read. Figure E-2. Boltzmann machine Because of its stochastic nature, a Boltzmann machine will never stabilize into a fixed configuration, but instead it will keep switching between many configurations. If it is left running for a sufficiently long time, the probability of observing a particular configuration will only be a function of the connection weights and bias terms, not of the original configuration (similarly, after you shuffle a deck of cards for long enough, the configuration of the deck does not depend on the initial state). When the network reaches this state where the original configuration is “forgotten,” it is said to be in thermal equilibrium (although its configuration keeps changing all the time). By setting the network parameters appropriately, letting the network reach thermal equilibrium, and then observing its state, we can simulate a wide range of probability distributions. This is called a generative model. Training a Boltzmann machine means finding the parameters that will make the network approximate the training set’s probability distribution. For example, if there are three visible neurons and the training set contains 75% (0, 1, 1) triplets, 10% (0, 0, 1) triplets, and 15% (1, 1, 1) triplets, then after training a Boltzmann machine, you could use it to generate random binary triplets with about the same probability distribution. For example, about 75% of the time it would output the (0, 1, 1) triplet. Such a generative model can be used in a variety of ways. For example, if it is trained on images, and you provide an incomplete or noisy image to the network, it will automatically “repair” the image in a reasonable way. You can also use a generative model for classification. Just add a few visible neurons to encode the training image’s class (e.g., add 10 visible neurons and turn on only the fifth neuron when the training image represents a 5). Then, when given a new image, the network will automatically turn on the appropriate visible neurons, indicating the image’s class (e.g., it will turn on the fifth visible neuron if the image represents a 5). Unfortunately, there is no efficient technique to train Boltzmann machines. However, fairly efficient algorithms have been developed to train restricted Boltzmann machines (RBM). Restricted Boltzmann Machines An RBM is simply a Boltzmann machine in which there are no connections between visible units or between hidden units, only between visible and hidden units. For example, Figure E-3 represents an RBM with three visible units and four hidden units. Figure E-3. Restricted Boltzmann machine A very efficient training algorithm, called Contrastive Divergence, was introduced in 2005 by Miguel Á. Carreira-Perpiñán and Geoffrey Hinton.1 Here is how it works: for each training instance x, the algorithm starts by feeding it to the network by setting the state of the visible units to x1, x2, ⋯, xn. Then you compute the state of the hidden units by applying the stochastic equation described before (Equation E-1). This gives you a hidden vector h (where hi is equal to the state of the ith unit). Next you compute the state of the visible units, by applying the same stochastic equation. This gives you a vector . Then once again you compute the state of the hidden units, which gives you a vector . Now you can update each connection weight by applying the rule in Equation E- 2. Equation E-2. Contrastive divergence weight update The great benefit of this algorithm it that it does not require waiting for the network to reach thermal equilibrium: it just goes forward, backward, and forward again, and that’s it. This makes it incomparably more efficient than previous algorithms, and it was a key ingredient to the first success of Deep Learning based on multiple stacked RBMs. Deep Belief Nets Several layers of RBMs can be stacked; the hidden units of the first-level RBM serves as the visible units for the second-layer RBM, and so on. Such an RBM stack is called a deep belief net (DBN). Yee-Whye Teh, one of Geoffrey Hinton’s students, observed that it was possible to train DBNs one layer at a time using Contrastive Divergence, starting with the lower layers and then gradually moving up to the top layers. This led to the groundbreaking article that kickstarted the Deep Learning tsunami in 2006.2 Just like RBMs, DBNs learn to reproduce the probability distribution of their inputs, without any supervision. However, they are much better at it, for the same reason that deep neural networks are more powerful than shallow ones: real-world data is often organized in hierarchical patterns, and DBNs take advantage of that. Their lower layers learn low-level features in the input data, while higher layers learn high-level features. Just like RBMs, DBNs are fundamentally unsupervised, but you can also train them in a supervised manner by adding some visible units to represent the labels. Moreover, one great feature of DBNs is that they can be trained in a semisupervised fashion. Figure E-4 represents such a DBN configured for semisupervised learning. Figure E-4. A deep belief network configured for semisupervised learning First, the RBM 1 is trained without supervision. It learns low-level features in the training data. Then RBM 2 is trained with RBM 1’s hidden units as inputs, again without supervision: it learns higher-level features (note that RBM 2’s hidden units include only the three rightmost units, not the label units). Several more RBMs could be stacked this way, but you get the idea. So far, training was 100% unsupervised. Lastly, RBM 3 is trained using both RBM 2’s hidden units as inputs, as well as extra visible units used to represent the target labels (e.g., a one-hot vector representing the instance class). It learns to associate high-level features with training labels. This is the supervised step. At the end of training, if you feed RBM 1 a new instance, the signal will propagate up to RBM 2, then up to the top of RBM 3, and then back down to the label units; hopefully, the appropriate label will light up. This is how a DBN can be used for classification. One great benefit of this semisupervised approach is that you don’t need much labeled training data. If the unsupervised RBMs do a good enough job, then only a small amount of labeled training instances per class will be necessary. Similarly, a baby learns to recognize objects without supervision, so when you point to a chair and say “chair,” the baby can associate the word “chair” with the class of objects it has already learned to recognize on its own. You don’t need to point to every single chair and say “chair”; only a few examples will suffice (just enough so the baby can be sure that you are indeed referring to the chair, not to its color or one of the chair’s parts). Quite amazingly, DBNs can also work in reverse. If you activate one of the label units, the signal will propagate up to the hidden units of RBM 3, then down to RBM 2, and then RBM 1, and a new instance will be output by the visible units of RBM 1. This new instance will usually look like a regular instance of the class whose label unit you activated. This generative capability of DBNs is quite powerful. For example, it has been used to automatically generate captions for images, and vice versa: first a DBN is trained (without supervision) to learn features in images, and another DBN is trained (again without supervision) to learn features in sets of captions (e.g., “car” often comes with “automobile”). Then an RBM is stacked on top of both DBNs and trained with a set of images along with their captions; it learns to associate high-level features in images with high-level features in captions. Next, if you feed the image DBN an image of a car, the signal will propagate through the network, up to the top-level RBM, and back down to the bottom of the caption DBN, producing a caption. Due to the stochastic nature of RBMs and DBNs, the caption will keep changing randomly, but it will generally be appropriate for the image. If you generate a few hundred captions, the most frequently generated ones will likely be a good description of the image.3 Self-Organizing Maps Self-organizing maps (SOM) are quite different from all the other types of neural networks we have discussed so far. They are used to produce a low-dimensional representation of a high-dimensional dataset, generally for visualization, clustering, or classification. The neurons are spread across a map (typically 2D for visualization, but it can be any number of dimensions you want), as shown in Figure E-5, and each neuron has a weighted connection to every input (note that the diagram shows just two inputs, but there are typically a very large number, since the whole point of SOMs is to reduce dimensionality). Figure E-5. Self-organizing maps Once the network is trained, you can feed it a new instance and this will activate only one neuron (i.e., hence one point on the map): the neuron whose weight vector is closest to the input vector. In general, instances that are nearby in the original input space will activate neurons that are nearby on the map. This makes SOMs useful for visualization (in particular, you can easily identify clusters on the map), but also for applications like speech recognition. For example, if each instance represents the audio recording of a person pronouncing a vowel, then different pronunciations of the vowel “a” will activate neurons in the same area of the map, while instances of the vowel “e” will activate neurons in another area, and intermediate sounds will generally activate intermediate neurons on the map. NOTE One important difference with the other dimensionality reduction techniques discussed in Chapter 8 is that all instances get mapped to a discrete number of points in the low-dimensional space (one point per neuron). When there are very few neurons, this technique is better described as clustering rather than dimensionality reduction. The training algorithm is unsupervised. It works by having all the neurons compete against each other. First, all the weights are initialized randomly. Then a training instance is picked randomly and fed to the network. All neurons compute the distance between their weight vector and the input vector (this is very different from the artificial neurons we have seen so far). The neuron that measures the smallest distance wins and tweaks its weight vector to be even slightly closer to the input vector, making it more likely to win future competitions for other inputs similar to this one. It also recruits its neighboring neurons, and they too update their weight vector to be slightly closer to the input vector (but they don’t update their weights as much as the winner neuron). Then the algorithm picks another training instance and repeats the process, again and again. This algorithm tends to make nearby neurons gradually specialize in similar inputs.4 “On Contrastive Divergence Learning,” M. Á. Carreira-Perpiñán and G. Hinton (2005). 1 2 “A Fast Learning Algorithm for Deep Belief Nets,” G. Hinton, S. Osindero, Y. Teh (2006). See this video by Geoffrey Hinton for more details and a demo: http://goo.gl/7Z5QiS. You can imagine a class of young children with roughly similar skills. One child happens to be slightly better at basketball. This motivates her to practice more, especially with her friends. After a while, this group of friends gets so good at basketball that other kids cannot compete. But that’s okay, because the other kids specialize in other topics. After a while, the class is full of little specialized groups. 2 3 4 Index Symbols __call__(), Static Unrolling Through Time ε-greedy policy, Exploration Policies, Learning to Play Ms. Pac-Man Using Deep Q-Learning ε-insensitive, SVM Regression χ 2 test (see chi square test) ℓ 0 norm, Select a Performance Measure ℓ 1 and ℓ 2 regularization, ℓ1 and ℓ2 Regularization-ℓ1 and ℓ2 Regularization ℓ 1 norm, Select a Performance Measure, Lasso Regression, Decision Boundaries, Adam Optimization, Avoiding Overfitting Through Regularization ℓ 2 norm, Select a Performance Measure, Ridge Regression-Lasso Regression, Decision Boundaries, Softmax Regression, Avoiding Overfitting Through Regularization, Max-Norm Regularization ℓ k norm, Select a Performance Measure ℓ ∞ norm, Select a Performance Measure A accuracy, What Is Machine Learning?, Measuring Accuracy Using Cross- Validation-Measuring Accuracy Using Cross-Validation actions, evaluating, Evaluating Actions: The Credit Assignment Problem- Evaluating Actions: The Credit Assignment Problem activation functions, Multi-Layer Perceptron and Backpropagation-Multi- Layer Perceptron and Backpropagation active constraints, SVM Dual Problem actors, Learning to Play Ms. Pac-Man Using Deep Q-Learning actual class, Confusion Matrix AdaBoost, AdaBoost-AdaBoost Adagrad, AdaGrad-AdaGrad Adam optimization, Faster Optimizers, Adam Optimization-Adam Optimization adaptive learning rate, AdaGrad adaptive moment optimization, Adam Optimization agents, Learning to Optimize Rewards AlexNet architecture, AlexNet-AlexNet algorithms preparing data for, Prepare the Data for Machine Learning Algorithms- Select and Train a Model AlphaGo, Reinforcement Learning, Introduction to Artificial Neural Networks, Reinforcement Learning, Policy Gradients Anaconda, Create the Workspace anomaly detection, Unsupervised learning Apple’s Siri, Introduction to Artificial Neural Networks apply_gradients(), Gradient Clipping, Policy Gradients area under the curve (AUC), The ROC Curve arg_scope(), Implementing Batch Normalization with TensorFlow array_split(), Incremental PCA artificial neural networks (ANNs), Introduction to Artificial Neural Networks-Exercises Boltzmann Machines, Boltzmann Machines-Boltzmann Machines deep belief networks (DBNs), Deep Belief Nets-Deep Belief Nets evolution of, From Biological to Artificial Neurons Hopfield Networks, Hopfield Networks-Hopfield Networks hyperparameter fine-tuning, Fine-Tuning Neural Network Hyperparameters-Activation Functions overview, Introduction to Artificial Neural Networks-From Biological to Artificial Neurons Perceptrons, The Perceptron-Multi-Layer Perceptron and Backpropagation self-organizing maps, Self-Organizing Maps-Self-Organizing Maps training a DNN with TensorFlow, Training a DNN Using Plain TensorFlow-Using the Neural Network artificial neuron, Logical Computations with Neurons (see also artificial neural network (ANN)) assign(), Manually Computing the Gradients association rule learning, Unsupervised learning associative memory networks, Hopfield Networks assumptions, checking, Check the Assumptions asynchronous updates, Asynchronous updates-Asynchronous updates asynchrous communication, Asynchronous Communication Using TensorFlow Queues-PaddingFifoQueue atrous_conv2d(), ResNet attention mechanism, An Encoder–Decoder Network for Machine Translation attributes, Supervised learning, Take a Quick Look at the Data Structure- Take a Quick Look at the Data Structure (see also data structure) combinations of, Experimenting with Attribute Combinations- Experimenting with Attribute Combinations preprocessed, Take a Quick Look at the Data Structure target, Take a Quick Look at the Data Structure autodiff, Using autodiff-Using autodiff, Autodiff-Reverse-Mode Autodiff forward-mode, Forward-Mode Autodiff-Forward-Mode Autodiff manual differentiation, Manual Differentiation numerical differentiation, Numerical Differentiation reverse-mode, Reverse-Mode Autodiff-Reverse-Mode Autodiff symbolic differentiation, Symbolic Differentiation-Numerical Differentiation autoencoders, Autoencoders-Exercises adversarial, Other Autoencoders contractive, Other Autoencoders denoising, Denoising Autoencoders-TensorFlow Implementation efficient data representations, Efficient Data Representations generative stochastic network (GSN), Other Autoencoders overcomplete, Unsupervised Pretraining Using Stacked Autoencoders PCA with undercomplete linear autoencoder, Performing PCA with an Undercomplete Linear Autoencoder reconstructions, Efficient Data Representations sparse, Sparse Autoencoders-TensorFlow Implementation stacked, Stacked Autoencoders-Unsupervised Pretraining Using Stacked Autoencoders stacked convolutional, Other Autoencoders undercomplete, Efficient Data Representations variational, Variational Autoencoders-Generating Digits visualizing features, Visualizing Features-Visualizing Features winner-take-all (WTA), Other Autoencoders automatic differentiating, Up and Running with TensorFlow autonomous driving systems, Recurrent Neural Networks Average Absolute Deviation, Select a Performance Measure average pooling layer, Pooling Layer avg_pool(), Pooling Layer B backpropagation, Multi-Layer Perceptron and Backpropagation-Multi- Layer Perceptron and Backpropagation, Vanishing/Exploding Gradients Problems, Unsupervised Pretraining, Visualizing Features backpropagation through time (BPTT), Training RNNs bagging and pasting, Bagging and Pasting-Out-of-Bag Evaluation out-of-bag evaluation, Out-of-Bag Evaluation-Out-of-Bag Evaluation in Scikit-Learn, Bagging and Pasting in Scikit-Learn-Bagging and Pasting in Scikit-Learn bandwidth saturation, Bandwidth saturation-Bandwidth saturation BasicLSTMCell, LSTM Cell BasicRNNCell, Distributing a Deep RNN Across Multiple GPUs- Distributing a Deep RNN Across Multiple GPUs Batch Gradient Descent, Batch Gradient Descent-Batch Gradient Descent, Lasso Regression batch learning, Batch learning-Batch learning Batch Normalization, Batch Normalization-Implementing Batch Normalization with TensorFlow, ResNet operation summary, Batch Normalization with TensorFlow, Implementing Batch Normalization with TensorFlow- Implementing Batch Normalization with TensorFlow batch(), Other convenience functions batch_join(), Other convenience functions batch_norm(), Implementing Batch Normalization with TensorFlow- Implementing Batch Normalization with TensorFlow Bellman Optimality Equation, Markov Decision Processes between-graph replication, In-Graph Versus Between-Graph Replication bias neurons, The Perceptron bias term, Linear Regression bias/variance tradeoff, Learning Curves biases, Construction Phase binary classifiers, Training a Binary Classifier, Logistic Regression biological neurons, From Biological to Artificial Neurons-Biological Neurons black box models, Making Predictions blending, Stacking-Exercises Boltzmann Machines, Boltzmann Machines-Boltzmann Machines (see also restricted Boltzman machines (RBMs)) boosting, Boosting-Gradient Boosting AdaBoost, AdaBoost-AdaBoost Gradient Boosting, Gradient Boosting-Gradient Boosting bootstrap aggregation (see bagging) bootstrapping, Grid Search, Bagging and Pasting, Introduction to OpenAI Gym, Learning to Play Ms. Pac-Man Using Deep Q-Learning bottleneck layers, GoogLeNet brew, Stacking C Caffe model zoo, Model Zoos call__(), Distributing a Deep RNN Across Multiple GPUs CART (Classification and Regression Tree) algorithm, Making Predictions- The CART Training Algorithm, Regression categorical attributes, Handling Text and Categorical Attributes-Handling Text and Categorical Attributes cell wrapper, Training to Predict Time Series chi square test, Regularization Hyperparameters classification versus regression, Supervised learning, Multioutput Classification classifiers binary, Training a Binary Classifier error analysis, Error Analysis-Error Analysis evaluating, Multiclass Classification MNIST dataset, MNIST-MNIST multiclass, Multiclass Classification-Multiclass Classification multilabel, Multilabel Classification-Multilabel Classification multioutput, Multioutput Classification-Multioutput Classification performance measures, Performance Measures-The ROC Curve precision of, Confusion Matrix voting, Voting Classifiers-Voting Classifiers clip_by_value(), Gradient Clipping closed-form equation, Training Models, Ridge Regression, Training and Cost Function cluster specification, Multiple Devices Across Multiple Servers clustering algorithms, Unsupervised learning clusters, Multiple Devices Across Multiple Servers coding space, Variational Autoencoders codings, Autoencoders complementary slackness condition, SVM Dual Problem components_, Using Scikit-Learn computational complexity, Computational Complexity, Computational Complexity, Computational Complexity compute_gradients(), Gradient Clipping, Policy Gradients concat(), GoogLeNet config.gpu_options, Managing the GPU RAM ConfigProto, Managing the GPU RAM confusion matrix, Confusion Matrix-Confusion Matrix, Error Analysis- Error Analysis connectionism, The Perceptron constrained optimization, Training Objective, SVM Dual Problem Contrastive Divergence, Restricted Boltzmann Machines control dependencies, Control Dependencies conv1d(), ResNet conv2d_transpose(), ResNet conv3d(), ResNet convergence rate, Batch Gradient Descent convex function, Gradient Descent convolution kernels, Filters, CNN Architectures, GoogLeNet convolutional neural networks (CNNs), Convolutional Neural Networks- Exercises architectures, CNN Architectures-ResNet AlexNet, AlexNet-AlexNet GoogleNet, GoogLeNet-GoogLeNet LeNet5, LeNet-5-LeNet-5 ResNet, ResNet-ResNet convolutional layer, Convolutional Layer-Memory Requirements, GoogLeNet, ResNet feature maps, Stacking Multiple Feature Maps-TensorFlow Implementation filters, Filters memory requirement, Memory Requirements-Memory Requirements evolution of, The Architecture of the Visual Cortex pooling layer, Pooling Layer-Pooling Layer TensorFlow implementation, TensorFlow Implementation-TensorFlow Implementation Coordinator class, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner correlation coefficient, Looking for Correlations-Looking for Correlations correlations, finding, Looking for Correlations-Looking for Correlations cost function, Model-based learning, Select a Performance Measure in AdaBoost, AdaBoost in adagrad, AdaGrad in artificial neural networks, Training an MLP with TensorFlow’s High- Level API, Construction Phase-Construction Phase in autodiff, Using autodiff in batch normalization, Implementing Batch Normalization with TensorFlow cross entropy, LeNet-5 deep Q-Learning, Learning to Play Ms. Pac-Man Using Deep Q-Learning in Elastic Net, Elastic Net in Gradient Descent, Training Models, Gradient Descent-Gradient Descent, Batch Gradient Descent, Batch Gradient Descent-Stochastic Gradient Descent, Gradient Boosting, Vanishing/Exploding Gradients Problems in Logistic Regression, Training and Cost Function-Training and Cost Function in PG algorithms, Policy Gradients in variational autoencoders, Variational Autoencoders in Lasso Regression, Lasso Regression-Lasso Regression in Linear Regression, The Normal Equation, Gradient Descent in Momentum optimization, Momentum optimization-Nesterov Accelerated Gradient in pretrained layers reuse, Pretraining on an Auxiliary Task in ridge regression, Ridge Regression-Ridge Regression in RNNs, Training RNNs, Training to Predict Time Series stale gradients and, Asynchronous updates creative sequences, Creative RNN credit assignment problem, Evaluating Actions: The Credit Assignment Problem-Evaluating Actions: The Credit Assignment Problem critics, Learning to Play Ms. Pac-Man Using Deep Q-Learning cross entropy, Softmax Regression-Softmax Regression, Training an MLP with TensorFlow’s High-Level API, TensorFlow Implementation, Policy Gradients cross-validation, Testing and Validating, Better Evaluation Using Cross- Validation-Better Evaluation Using Cross-Validation, Measuring Accuracy Using Cross-Validation-Measuring Accuracy Using Cross-Validation CUDA library, Installation cuDNN library, Installation curse of dimensionality, Dimensionality Reduction-The Curse of Dimensionality (see also dimensionality reduction) custom transformers, Custom Transformers-Custom Transformers D data, Testing and Validating (see also test data; training data) creating workspace for, Get the Data-Download the Data downloading, Download the Data-Download the Data finding correlations in, Looking for Correlations-Looking for Correlations making assumptions about, Testing and Validating preparing for Machine Learning algorithms, Prepare the Data for Machine Learning Algorithms-Select and Train a Model test-set creation, Create a Test Set-Create a Test Set working with real data, Working with Real Data data augmentation, Data Augmentation-Data Augmentation data cleaning, Data Cleaning-Handling Text and Categorical Attributes data mining, Why Use Machine Learning? data parallelism, Data Parallelism-TensorFlow implementation asynchronous updates, Asynchronous updates-Asynchronous updates bandwidth saturation, Bandwidth saturation-Bandwidth saturation synchronous updates, Synchronous updates TensorFlow implementation, TensorFlow implementation data pipeline, Frame the Problem data snooping bias, Create a Test Set data structure, Take a Quick Look at the Data Structure-Take a Quick Look at the Data Structure data visualization, Visualizing Geographical Data-Visualizing Geographical Data DataFrame, Data Cleaning dataquest, Other Resources decay, Implementing Batch Normalization with TensorFlow decision boundaries, Decision Boundaries-Decision Boundaries, Softmax Regression, Making Predictions decision function, Precision/Recall Tradeoff, Decision Function and Predictions-Decision Function and Predictions Decision Stumps, AdaBoost decision threshold, Precision/Recall Tradeoff Decision Trees, Training and Evaluating on the Training Set-Better Evaluation Using Cross-Validation, Decision Trees-Exercises, Ensemble Learning and Random Forests binary trees, Making Predictions class probability estimates, Estimating Class Probabilities computational complexity, Computational Complexity decision boundaries, Making Predictions GINI impurity, Gini Impurity or Entropy? instability with, Instability-Instability numbers of children, Making Predictions predictions, Making Predictions-Estimating Class Probabilities Random Forests (see Random Forests) regression tasks, Regression-Regression regularization hyperparameters, Regularization Hyperparameters- Regularization Hyperparameters training and visualizing, Training and Visualizing a Decision Tree- Making Predictions decoder, Efficient Data Representations deconvolutional layer, ResNet deep autoencoders (see stacked autoencoders) deep belief networks (DBNs), Semisupervised learning, Deep Belief Nets- Deep Belief Nets Deep Learning, Reinforcement Learning (see also Reinforcement Learning; TensorFlow) about, The Machine Learning Tsunami, Roadmap libraries, Up and Running with TensorFlow-Up and Running with TensorFlow deep neural networks (DNNs), Multi-Layer Perceptron and Backpropagation, Training Deep Neural Nets-Exercises (see also Multi-Layer Perceptrons (MLP)) faster optimizers for, Faster Optimizers-Learning Rate Scheduling regularization, Avoiding Overfitting Through Regularization-Data Augmentation reusing pretrained layers, Reusing Pretrained Layers-Pretraining on an Auxiliary Task training guidelines overview, Practical Guidelines training with TensorFlow, Training a DNN Using Plain TensorFlow-Using the Neural Network training with TF.Learn, Training an MLP with TensorFlow’s High-Level API unstable gradients, Vanishing/Exploding Gradients Problems vanishing and exploding gradients, Training Deep Neural Nets-Gradient Clipping Deep Q-Learning, Approximate Q-Learning-Learning to Play Ms. Pac-Man Using Deep Q-Learning Ms. Pac Man example, Learning to Play Ms. Pac-Man Using Deep Q- Learning-Learning to Play Ms. Pac-Man Using Deep Q-Learning deep Q-network, Approximate Q-Learning deep RNNs, Deep RNNs-The Difficulty of Training over Many Time Steps applying dropout, Applying Dropout distributing across multiple GPUs, Distributing a Deep RNN Across Multiple GPUs long sequence difficulties, The Difficulty of Training over Many Time Steps truncated backpropagation through time, The Difficulty of Training over Many Time Steps DeepMind, Reinforcement Learning, Introduction to Artificial Neural Networks, Reinforcement Learning, Approximate Q-Learning degrees of freedom, Overfitting the Training Data, Learning Curves denoising autoencoders, Denoising Autoencoders-TensorFlow Implementation depth concat layer, GoogLeNet depth radius, AlexNet depthwise_conv2d(), ResNet dequeue(), Queues of tuples dequeue_many(), Queues of tuples, PaddingFifoQueue dequeue_up_to(), Closing a queue-PaddingFifoQueue dequeuing data, Dequeuing data describe(), Take a Quick Look at the Data Structure device blocks, Sharding Variables Across Multiple Parameter Servers device(), Simple placement dimensionality reduction, Unsupervised learning, Dimensionality Reduction-Exercises, Autoencoders approaches to Manifold Learning, Manifold Learning projection, Projection-Projection choosing the right number of dimensions, Choosing the Right Number of Dimensions curse of dimensionality, Dimensionality Reduction-The Curse of Dimensionality and data visualization, Dimensionality Reduction Isomap, Other Dimensionality Reduction Techniques LLE (Locally Linear Embedding), LLE-LLE Multidimensional Scaling, Other Dimensionality Reduction Techniques- Other Dimensionality Reduction Techniques PCA (Principal Component Analysis), PCA-Randomized PCA t-Distributed Stochastic Neighbor Embedding (t-SNE), Other Dimensionality Reduction Techniques discount rate, Evaluating Actions: The Credit Assignment Problem distributed computing, Up and Running with TensorFlow distributed sessions, Sharing State Across Sessions Using Resource Containers-Sharing State Across Sessions Using Resource Containers DNNClassifier, Training an MLP with TensorFlow’s High-Level API drop(), Prepare the Data for Machine Learning Algorithms dropconnect, Dropout dropna(), Data Cleaning dropout, Number of Neurons per Hidden Layer, Applying Dropout dropout rate, Dropout dropout(), Dropout DropoutWrapper, Applying Dropout DRY (Don’t Repeat Yourself), Modularity Dual Averaging, Adam Optimization dual numbers, Forward-Mode Autodiff dual problem, The Dual Problem duality, SVM Dual Problem dying ReLUs, Nonsaturating Activation Functions dynamic placements, Dynamic placement function dynamic placer, Placing Operations on Devices Dynamic Programming, Markov Decision Processes dynamic unrolling through time, Dynamic Unrolling Through Time dynamic_rnn(), Dynamic Unrolling Through Time, Distributing a Deep RNN Across Multiple GPUs, An Encoder–Decoder Network for Machine Translation E early stopping, Early Stopping-Early Stopping, Gradient Boosting, Number of Neurons per Hidden Layer, Early Stopping Elastic Net, Elastic Net embedded device blocks, Sharding Variables Across Multiple Parameter Servers Embedded Reber grammars, Exercises embeddings, Word Embeddings-Word Embeddings embedding_lookup(), Word Embeddings encoder, Efficient Data Representations Encoder–Decoder, Input and Output Sequences end-of-sequence (EOS) token, Handling Variable-Length Output Sequences energy functions, Hopfield Networks enqueuing data, Enqueuing data Ensemble Learning, Better Evaluation Using Cross-Validation, Ensemble Methods, Ensemble Learning and Random Forests-Exercises bagging and pasting, Bagging and Pasting-Out-of-Bag Evaluation boosting, Boosting-Gradient Boosting in-graph versus between-graph replication, In-Graph Versus Between- Graph Replication-In-Graph Versus Between-Graph Replication Random Forests, Random Forests-Feature Importance (see also Random Forests) random patches and random subspaces, Random Patches and Random Subspaces stacking, Stacking-Stacking entropy impurity measure, Gini Impurity or Entropy? environments, in reinforcement learning, Learning to Optimize Rewards- Evaluating Actions: The Credit Assignment Problem, Exploration Policies, Learning to Play Ms. Pac-Man Using Deep Q-Learning episodes (in RL), Introduction to OpenAI Gym, Evaluating Actions: The Credit Assignment Problem-Policy Gradients, Policy Gradients-Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning epochs, Stochastic Gradient Descent ε-insensitive, SVM Regression equality contraints, SVM Dual Problem error analysis, Error Analysis-Error Analysis estimators, Data Cleaning Euclidian norm, Select a Performance Measure eval(), Feeding Data to the Training Algorithm evaluating models, Testing and Validating-Testing and Validating explained variance, Choosing the Right Number of Dimensions explained variance ratio, Explained Variance Ratio exploding gradients, Vanishing/Exploding Gradients Problems (see also gradients, vanishing and exploding) exploration policies, Exploration Policies exponential decay, Implementing Batch Normalization with TensorFlow exponential linear unit (ELU), Nonsaturating Activation Functions- Nonsaturating Activation Functions exponential scheduling, Learning Rate Scheduling Extra-Trees, Extra-Trees F F-1 score, Precision and Recall-Precision and Recall face-recognition, Multilabel Classification fake X server, Introduction to OpenAI Gym false positive rate (FPR), The ROC Curve-The ROC Curve fan-in, Xavier and He Initialization, Xavier and He Initialization fan-out, Xavier and He Initialization, Xavier and He Initialization feature detection, Autoencoders feature engineering, Irrelevant Features feature extraction, Unsupervised learning feature importance, Feature Importance-Feature Importance feature maps, Selecting a Kernel and Tuning Hyperparameters, Filters- TensorFlow Implementation, ResNet feature scaling, Feature Scaling feature selection, Irrelevant Features, Grid Search, Lasso Regression, Feature Importance, Prepare the Data feature space, Kernel PCA, Selecting a Kernel and Tuning Hyperparameters feature vector, Select a Performance Measure, Linear Regression, Under the Hood, Implementing Gradient Descent features, Supervised learning FeatureUnion, Transformation Pipelines feedforward neural network (FNN), Multi-Layer Perceptron and Backpropagation feed_dict, Feeding Data to the Training Algorithm FIFOQueue, Asynchronous Communication Using TensorFlow Queues, RandomShuffleQueue fillna(), Data Cleaning first-in first-out (FIFO) queues, Asynchronous Communication Using TensorFlow Queues first-order partial derivatives (Jacobians), Adam Optimization fit(), Data Cleaning, Transformation Pipelines, Incremental PCA fitness function, Model-based learning fit_inverse_transform=, Selecting a Kernel and Tuning Hyperparameters fit_transform(), Data Cleaning, Transformation Pipelines folds, Better Evaluation Using Cross-Validation, MNIST, Measuring Accuracy Using Cross-Validation-Measuring Accuracy Using Cross- Validation Follow The Regularized Leader (FTRL), Adam Optimization forget gate, LSTM Cell forward-mode autodiff, Forward-Mode Autodiff-Forward-Mode Autodiff framing a problem, Frame the Problem-Frame the Problem frozen layers, Freezing the Lower Layers-Caching the Frozen Layers fully_connected(), Construction Phase, Xavier and He Initialization, Implementing Batch Normalization with TensorFlow-Implementing Batch Normalization with TensorFlow, Tying Weights G game play (see reinforcement learning) gamma value, Gaussian RBF Kernel gate controllers, LSTM Cell Gaussian distribution, Select a Performance Measure, Variational Autoencoders, Generating Digits Gaussian RBF, Adding Similarity Features Gaussian RBF kernel, Gaussian RBF Kernel-Gaussian RBF Kernel, Kernelized SVM generalization error, Testing and Validating generalized Lagrangian, SVM Dual Problem-SVM Dual Problem generative autoencoders, Variational Autoencoders generative models, Autoencoders, Boltzmann Machines genetic algorithms, Policy Search geodesic distance, Other Dimensionality Reduction Techniques get_variable(), Sharing Variables-Sharing Variables GINI impurity, Making Predictions, Gini Impurity or Entropy? global average pooling, GoogLeNet global_step, Learning to Play Ms. Pac-Man Using Deep Q-Learning global_variables(), Max-Norm Regularization global_variables_initializer(), Creating Your First Graph and Running It in a Session Glorot initialization, Vanishing/Exploding Gradients Problems-Xavier and He Initialization Google, Up and Running with TensorFlow Google Images, Introduction to Artificial Neural Networks Google Photos, Semisupervised learning GoogleNet architecture, GoogLeNet-GoogLeNet gpu_options.per_process_gpu_memory_fraction, Managing the GPU RAM gradient ascent, Policy Search Gradient Boosted Regression Trees (GBRT), Gradient Boosting Gradient Boosting, Gradient Boosting-Gradient Boosting Gradient Descent (GD), Training Models, Gradient Descent-Mini-batch Gradient Descent, Online SVMs, Training Deep Neural Nets, Momentum optimization, AdaGrad algorithm comparisons, Mini-batch Gradient Descent-Mini-batch Gradient Descent automatically computing gradients, Using autodiff-Using autodiff Batch GD, Batch Gradient Descent-Batch Gradient Descent, Lasso Regression defining, Gradient Descent local minimum versus global minimum, Gradient Descent manually computing gradients, Manually Computing the Gradients Mini-batch GD, Mini-batch Gradient Descent-Mini-batch Gradient Descent, Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm optimizer, Using an Optimizer Stochastic GD, Stochastic Gradient Descent-Stochastic Gradient Descent, Soft Margin Classification with TensorFlow, Implementing Gradient Descent-Using an Optimizer Gradient Tree Boosting, Gradient Boosting GradientDescentOptimizer, Construction Phase gradients(), Using autodiff gradients, vanishing and exploding, Training Deep Neural Nets-Gradient Clipping, The Difficulty of Training over Many Time Steps Batch Normalization, Batch Normalization-Implementing Batch Normalization with TensorFlow Glorot and He initialization, Vanishing/Exploding Gradients Problems- Xavier and He Initialization gradient clipping, Gradient Clipping nonsaturating activation functions, Nonsaturating Activation Functions- Nonsaturating Activation Functions graphviz, Training and Visualizing a Decision Tree greedy algorithm, The CART Training Algorithm grid search, Fine-Tune Your Model-Grid Search, Polynomial Kernel group(), Learning to Play Ms. Pac-Man Using Deep Q-Learning GRU (Gated Recurrent Unit) cell, GRU Cell-GRU Cell H hailstone sequence, Efficient Data Representations hard margin classification, Soft Margin Classification-Soft Margin Classification hard voting classifiers, Voting Classifiers-Voting Classifiers harmonic mean, Precision and Recall He initialization, Vanishing/Exploding Gradients Problems-Xavier and He Initialization Heaviside step function, The Perceptron Hebb's rule, The Perceptron, Hopfield Networks Hebbian learning, The Perceptron hidden layers, Multi-Layer Perceptron and Backpropagation hierarchical clustering, Unsupervised learning hinge loss function, Online SVMs histograms, Take a Quick Look at the Data Structure-Take a Quick Look at the Data Structure hold-out sets, Stacking (see also blenders) Hopfield Networks, Hopfield Networks-Hopfield Networks hyperbolic tangent (htan activation function), Multi-Layer Perceptron and Backpropagation, Activation Functions, Vanishing/Exploding Gradients Problems, Xavier and He Initialization, Recurrent Neurons hyperparameters, Overfitting the Training Data, Custom Transformers, Grid Search-Grid Search, Evaluate Your System on the Test Set, Gradient Descent, Polynomial Kernel, Computational Complexity, Fine-Tuning Neural Network Hyperparameters (see also neural network hyperparameters) hyperplane, Decision Function and Predictions, Manifold Learning-PCA, Projecting Down to d Dimensions, Other Dimensionality Reduction Techniques hypothesis, Select a Performance Measure manifold, Manifold Learning hypothesis boosting (see boosting) hypothesis function, Linear Regression hypothesis, null, Regularization Hyperparameters I identity matrix, Ridge Regression, Quadratic Programming ILSVRC ImageNet challenge, CNN Architectures image classification, CNN Architectures impurity measures, Making Predictions, Gini Impurity or Entropy? in-graph replication, In-Graph Versus Between-Graph Replication inception modules, GoogLeNet Inception-v4, ResNet incremental learning, Online learning, Incremental PCA inequality constraints, SVM Dual Problem inference, Model-based learning, Exercises, Memory Requirements, An Encoder–Decoder Network for Machine Translation info(), Take a Quick Look at the Data Structure information gain, Gini Impurity or Entropy? information theory, Gini Impurity or Entropy? init node, Saving and Restoring Models input gate, LSTM Cell input neurons, The Perceptron input_put_keep_prob, Applying Dropout instance-based learning, Instance-based learning, Model-based learning InteractiveSession, Creating Your First Graph and Running It in a Session intercept term, Linear Regression Internal Covariate Shift problem, Batch Normalization inter_op_parallelism_threads, Parallel Execution intra_op_parallelism_threads, Parallel Execution inverse_transform(), Selecting a Kernel and Tuning Hyperparameters in_top_k(), Construction Phase irreducible error, Learning Curves isolated environment, Create the Workspace-Create the Workspace Isomap, Other Dimensionality Reduction Techniques is_training, Implementing Batch Normalization with TensorFlow- Implementing Batch Normalization with TensorFlow, Applying Dropout J jobs, Multiple Devices Across Multiple Servers join(), Multiple Devices Across Multiple Servers, Multithreaded readers using a Coordinator and a QueueRunner Jupyter, Create the Workspace, Create the Workspace, Take a Quick Look at the Data Structure K K-fold cross-validation, Better Evaluation Using Cross-Validation-Better Evaluation Using Cross-Validation, Measuring Accuracy Using Cross- Validation k-Nearest Neighbors, Model-based learning, Multilabel Classification Karush–Kuhn–Tucker (KKT) conditions, SVM Dual Problem keep probability, Dropout Keras, Up and Running with TensorFlow Kernel PCA (kPCA), Kernel PCA-Selecting a Kernel and Tuning Hyperparameters kernel trick, Polynomial Kernel, Gaussian RBF Kernel, The Dual Problem- Kernelized SVM, Kernel PCA kernelized SVM, Kernelized SVM-Kernelized SVM kernels, Polynomial Kernel-Gaussian RBF Kernel, Operations and kernels Kullback–Leibler divergence, Softmax Regression, Sparse Autoencoders L l1_l2_regularizer(), ℓ1 and ℓ2 Regularization LabelBinarizer, Transformation Pipelines labels, Supervised learning, Frame the Problem Lagrange function, SVM Dual Problem-SVM Dual Problem Lagrange multiplier, SVM Dual Problem landmarks, Adding Similarity Features-Adding Similarity Features large margin classification, Linear SVM Classification-Linear SVM Classification Lasso Regression, Lasso Regression-Lasso Regression latent loss, Variational Autoencoders latent space, Variational Autoencoders law of large numbers, Voting Classifiers leaky ReLU, Nonsaturating Activation Functions learning rate, Online learning, Gradient Descent, Batch Gradient Descent- Stochastic Gradient Descent learning rate scheduling, Stochastic Gradient Descent, Learning Rate Scheduling-Learning Rate Scheduling LeNet-5 architecture, The Architecture of the Visual Cortex, LeNet-5- LeNet-5 Levenshtein distance, Gaussian RBF Kernel liblinear library, Computational Complexity libsvm library, Computational Complexity Linear Discriminant Analysis (LDA), Other Dimensionality Reduction Techniques linear models early stopping, Early Stopping-Early Stopping Elastic Net, Elastic Net Lasso Regression, Lasso Regression-Lasso Regression Linear Regression (see Linear Regression) regression (see Linear Regression) Ridge Regression, Ridge Regression-Ridge Regression, Elastic Net SVM, Linear SVM Classification-Soft Margin Classification Linear Regression, Model-based learning, Training and Evaluating on the Training Set, Training Models-Mini-batch Gradient Descent, Elastic Net computational complexity, Computational Complexity Gradient Descent in, Gradient Descent-Mini-batch Gradient Descent learning curves in, Learning Curves-Learning Curves Normal Equation, The Normal Equation-Computational Complexity regularizing models (see regularization) using Stochastic Gradient Descent (SGD), Stochastic Gradient Descent with TensorFlow, Linear Regression with TensorFlow-Linear Regression with TensorFlow linear SVM classification, Linear SVM Classification-Soft Margin Classification linear threshold units (LTUs), The Perceptron Lipschitz continuous, Gradient Descent LLE (Locally Linear Embedding), LLE-LLE load_sample_images(), TensorFlow Implementation local receptive field, The Architecture of the Visual Cortex local response normalization, AlexNet local sessions, Sharing State Across Sessions Using Resource Containers location invariance, Pooling Layer log loss, Training and Cost Function logging placements, Logging placements-Logging placements logistic function, Estimating Probabilities Logistic Regression, Supervised learning, Logistic Regression-Softmax Regression decision boundaries, Decision Boundaries-Decision Boundaries estimating probablities, Estimating Probabilities-Estimating Probabilities Softmax Regression model, Softmax Regression-Softmax Regression training and cost function, Training and Cost Function-Training and Cost Function log_device_placement, Logging placements LSTM (Long Short-Term Memory) cell, LSTM Cell-GRU Cell M machine control (see reinforcement learning) Machine Learning large-scale projects (see TensorFlow) notations, Select a Performance Measure-Select a Performance Measure process example, End-to-End Machine Learning Project-Exercises project checklist, Look at the Big Picture, Machine Learning Project Checklist-Launch! resources on, Other Resources-Other Resources uses for, Machine Learning in Your Projects-Machine Learning in Your Projects Machine Learning basics attributes, Supervised learning challenges, Main Challenges of Machine Learning-Stepping Back algorithm problems, Overfitting the Training Data-Underfitting the Training Data training data problems, Poor-Quality Data definition, What Is Machine Learning? features, Supervised learning overview, The Machine Learning Landscape reasons for using, Why Use Machine Learning?-Why Use Machine Learning? spam filter example, What Is Machine Learning?-Why Use Machine Learning? summary, Stepping Back testing and validating, Testing and Validating-Testing and Validating types of systems, Types of Machine Learning Systems-Model-based learning batch and online learning, Batch and Online Learning-Online learning instance-based versus model-based learning, Instance-Based Versus Model-Based Learning-Model-based learning supervised/unsupervised learning, Supervised/Unsupervised Learning- Reinforcement Learning workflow example, Model-based learning-Model-based learning machine translation (see natural language processing (NLP)) make(), Introduction to OpenAI Gym Manhattan norm, Select a Performance Measure manifold assumption/hypothesis, Manifold Learning Manifold Learning, Manifold Learning, LLE (see also LLE (Locally Linear Embedding) MapReduce, Frame the Problem margin violations, Soft Margin Classification Markov chains, Markov Decision Processes Markov decision processes, Markov Decision Processes-Markov Decision Processes master service, The Master and Worker Services Matplotlib, Create the Workspace, Take a Quick Look at the Data Structure, The ROC Curve, Error Analysis max margin learning, Pretraining on an Auxiliary Task max pooling layer, Pooling Layer max-norm regularization, Max-Norm Regularization-Max-Norm Regularization max_norm(), Max-Norm Regularization max_norm_regularizer(), Max-Norm Regularization max_pool(), Pooling Layer Mean Absolute Error (MAE), Select a Performance Measure-Select a Performance Measure mean coding, Variational Autoencoders Mean Square Error (MSE), Linear Regression, Manually Computing the Gradients, Sparse Autoencoders measure of similarity, Instance-based learning memmap, Incremental PCA memory cells, Model Parallelism, Memory Cells Mercer's theorem, Kernelized SVM meta learner (see blending) min-max scaling, Feature Scaling Mini-batch Gradient Descent, Mini-batch Gradient Descent-Mini-batch Gradient Descent, Training and Cost Function, Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm mini-batches, Online learning minimize(), Gradient Clipping, Freezing the Lower Layers, Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning min_after_dequeue, RandomShuffleQueue MNIST dataset, MNIST-MNIST model parallelism, Model Parallelism-Model Parallelism model parameters, Gradient Descent, Batch Gradient Descent, Early Stopping, Under the Hood, Quadratic Programming, Creating Your First Graph and Running It in a Session, Construction Phase, Training RNNs defining, Model-based learning model selection, Model-based learning model zoos, Model Zoos model-based learning, Model-based learning-Model-based learning models analyzing, Analyze the Best Models and Their Errors-Analyze the Best Models and Their Errors evaluating on test set, Evaluate Your System on the Test Set-Evaluate Your System on the Test Set moments, Adam Optimization Momentum optimization, Momentum optimization-Momentum optimization Monte Carlo tree search, Policy Gradients Multi-Layer Perceptrons (MLP), Introduction to Artificial Neural Networks, The Perceptron-Multi-Layer Perceptron and Backpropagation, Neural Network Policies training with TF.Learn, Training an MLP with TensorFlow’s High-Level API multiclass classifiers, Multiclass Classification-Multiclass Classification Multidimensional Scaling (MDS), Other Dimensionality Reduction Techniques multilabel classifiers, Multilabel Classification-Multilabel Classification Multinomial Logistic Regression (see Softmax Regression) multinomial(), Neural Network Policies multioutput classifiers, Multioutput Classification-Multioutput Classification MultiRNNCell, Distributing a Deep RNN Across Multiple GPUs multithreaded readers, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner multivariate regression, Frame the Problem N naive Bayes classifiers, Multiclass Classification name scopes, Name Scopes natural language processing (NLP), Recurrent Neural Networks, Natural Language Processing-An Encoder–Decoder Network for Machine Translation encoder-decoder network for machine translation, An Encoder–Decoder Network for Machine Translation-An Encoder–Decoder Network for Machine Translation TensorFlow tutorials, Natural Language Processing, An Encoder– Decoder Network for Machine Translation word embeddings, Word Embeddings-Word Embeddings Nesterov Accelerated Gradient (NAG), Nesterov Accelerated Gradient- Nesterov Accelerated Gradient Nesterov momentum optimization, Nesterov Accelerated Gradient-Nesterov Accelerated Gradient network topology, Fine-Tuning Neural Network Hyperparameters neural network hyperparameters, Fine-Tuning Neural Network Hyperparameters-Activation Functions activation functions, Activation Functions neurons per hidden layer, Number of Neurons per Hidden Layer number of hidden layers, Number of Hidden Layers-Number of Hidden Layers neural network policies, Neural Network Policies-Neural Network Policies neurons biological, From Biological to Artificial Neurons-Biological Neurons logical computations with, Logical Computations with Neurons neuron_layer(), Construction Phase next_batch(), Execution Phase No Free Lunch theorem, Testing and Validating node edges, Visualizing the Graph and Training Curves Using TensorBoard nonlinear dimensionality reduction (NLDR), LLE (see also Kernel PCA; LLE (Locally Linear Embedding)) nonlinear SVM classification, Nonlinear SVM Classification-Computational Complexity computational complexity, Computational Complexity Gaussian RBF kernel, Gaussian RBF Kernel-Gaussian RBF Kernel with polynomial features, Nonlinear SVM Classification-Polynomial Kernel polynomial kernel, Polynomial Kernel-Polynomial Kernel similarity features, adding, Adding Similarity Features-Adding Similarity Features nonparametric models, Regularization Hyperparameters nonresponse bias, Nonrepresentative Training Data nonsaturating activation functions, Nonsaturating Activation Functions- Nonsaturating Activation Functions normal distribution (see Gaussian distribution) Normal Equation, The Normal Equation-Computational Complexity normalization, Feature Scaling normalized exponential, Softmax Regression norms, Select a Performance Measure notations, Select a Performance Measure-Select a Performance Measure NP-Complete problems, The CART Training Algorithm null hypothesis, Regularization Hyperparameters numerical differentiation, Numerical Differentiation NumPy, Create the Workspace NumPy arrays, Handling Text and Categorical Attributes NVidia Compute Capability, Installation nvidia-smi, Managing the GPU RAM n_components, Choosing the Right Number of Dimensions O observation space, Neural Network Policies off-policy algorithm, Temporal Difference Learning and Q-Learning offline learning, Batch learning one-hot encoding, Handling Text and Categorical Attributes one-versus-all (OvA) strategy, Multiclass Classification, Softmax Regression, Exercises one-versus-one (OvO) strategy, Multiclass Classification online learning, Online learning-Online learning online SVMs, Online SVMs-Online SVMs OpenAI Gym, Introduction to OpenAI Gym-Introduction to OpenAI Gym operation_timeout_in_ms, In-Graph Versus Between-Graph Replication Optical Character Recognition (OCR), The Machine Learning Landscape optimal state value, Markov Decision Processes optimizers, Faster Optimizers-Learning Rate Scheduling AdaGrad, AdaGrad-AdaGrad Adam optimization, Faster Optimizers, Adam Optimization-Adam Optimization Gradient Descent (see Gradient Descent optimizer) learning rate scheduling, Learning Rate Scheduling-Learning Rate Scheduling Momentum optimization, Momentum optimization-Momentum optimization Nesterov Accelerated Gradient (NAG), Nesterov Accelerated Gradient- Nesterov Accelerated Gradient RMSProp, RMSProp out-of-bag evaluation, Out-of-Bag Evaluation-Out-of-Bag Evaluation out-of-core learning, Online learning out-of-memory (OOM) errors, Static Unrolling Through Time out-of-sample error, Testing and Validating OutOfRangeError, Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner output gate, LSTM Cell output layer, Multi-Layer Perceptron and Backpropagation OutputProjectionWrapper, Training to Predict Time Series-Training to Predict Time Series output_put_keep_prob, Applying Dropout overcomplete autoencoder, Unsupervised Pretraining Using Stacked Autoencoders overfitting, Overfitting the Training Data-Overfitting the Training Data, Create a Test Set, Soft Margin Classification, Gaussian RBF Kernel, Regularization Hyperparameters, Regression, Number of Neurons per Hidden Layer avoiding through regularization, Avoiding Overfitting Through Regularization-Data Augmentation P p-value, Regularization Hyperparameters PaddingFIFOQueue, PaddingFifoQueue Pandas, Create the Workspace, Download the Data scatter_matrix, Looking for Correlations-Looking for Correlations parallel distributed computing, Distributing TensorFlow Across Devices and Servers-Exercises data parallelism, Data Parallelism-TensorFlow implementation in-graph versus between-graph replication, In-Graph Versus Between- Graph Replication-Model Parallelism model parallelism, Model Parallelism-Model Parallelism multiple devices across multiple servers, Multiple Devices Across Multiple Servers-Other convenience functions asynchronous communication using queues, Asynchronous Communication Using TensorFlow Queues-PaddingFifoQueue loading training data, Loading Data Directly from the Graph-Other convenience functions master and worker services, The Master and Worker Services opening a session, Opening a Session pinning operations across tasks, Pinning Operations Across Tasks sharding variables, Sharding Variables Across Multiple Parameter Servers sharing state across sessions, Sharing State Across Sessions Using Resource Containers-Sharing State Across Sessions Using Resource Containers multiple devices on a single machine, Multiple Devices on a Single Machine-Control Dependencies control dependencies, Control Dependencies installation, Installation-Installation managing the GPU RAM, Managing the GPU RAM-Managing the GPU RAM parallel execution, Parallel Execution-Parallel Execution placing operations on devices, Placing Operations on Devices-Soft placement one neural network per device, One Neural Network per Device-One Neural Network per Device parameter efficiency, Number of Hidden Layers parameter matrix, Softmax Regression parameter server (ps), Multiple Devices Across Multiple Servers parameter space, Gradient Descent parameter vector, Linear Regression, Gradient Descent, Training and Cost Function, Softmax Regression parametric models, Regularization Hyperparameters partial derivative, Batch Gradient Descent partial_fit(), Incremental PCA Pearson's r, Looking for Correlations peephole connections, Peephole Connections penalties (see rewards, in RL) percentiles, Take a Quick Look at the Data Structure Perceptron convergence theorem, The Perceptron Perceptrons, The Perceptron-Multi-Layer Perceptron and Backpropagation versus Logistic Regression, The Perceptron training, The Perceptron-The Perceptron performance measures, Select a Performance Measure-Select a Performance Measure confusion matrix, Confusion Matrix-Confusion Matrix cross-validation, Measuring Accuracy Using Cross-Validation-Measuring Accuracy Using Cross-Validation precision and recall, Precision and Recall-Precision/Recall Tradeoff ROC (receiver operating characteristic) curve, The ROC Curve-The ROC Curve performance scheduling, Learning Rate Scheduling permutation(), Create a Test Set PG algorithms, Policy Gradients photo-hosting services, Semisupervised learning pinning operations, Pinning Operations Across Tasks pip, Create the Workspace Pipeline constructor, Transformation Pipelines-Select and Train a Model pipelines, Frame the Problem placeholder nodes, Feeding Data to the Training Algorithm placers (see simple placer; dynamic placer) policy, Policy Search policy gradients, Policy Search (see PG algorithms) policy space, Policy Search polynomial features, adding, Nonlinear SVM Classification-Polynomial Kernel polynomial kernel, Polynomial Kernel-Polynomial Kernel, Kernelized SVM Polynomial Regression, Training Models, Polynomial Regression- Polynomial Regression learning curves in, Learning Curves-Learning Curves pooling kernel, Pooling Layer pooling layer, Pooling Layer-Pooling Layer power scheduling, Learning Rate Scheduling precision, Confusion Matrix precision and recall, Precision and Recall-Precision/Recall Tradeoff F-1 score, Precision and Recall-Precision and Recall precision/recall (PR) curve, The ROC Curve precision/recall tradeoff, Precision/Recall Tradeoff-Precision/Recall Tradeoff predetermined piecewise constant learning rate, Learning Rate Scheduling predict(), Data Cleaning predicted class, Confusion Matrix predictions, Confusion Matrix-Confusion Matrix, Decision Function and Predictions-Decision Function and Predictions, Making Predictions- Estimating Class Probabilities predictors, Supervised learning, Data Cleaning preloading training data, Preload the data into a variable PReLU (parametric leaky ReLU), Nonsaturating Activation Functions preprocessed attributes, Take a Quick Look at the Data Structure pretrained layers reuse, Reusing Pretrained Layers-Pretraining on an Auxiliary Task auxiliary task, Pretraining on an Auxiliary Task-Pretraining on an Auxiliary Task caching frozen layers, Caching the Frozen Layers freezing lower layers, Freezing the Lower Layers model zoos, Model Zoos other frameworks, Reusing Models from Other Frameworks TensorFlow model, Reusing a TensorFlow Model-Reusing a TensorFlow Model unsupervised pretraining, Unsupervised Pretraining-Unsupervised Pretraining upper layers, Tweaking, Dropping, or Replacing the Upper Layers Pretty Tensor, Up and Running with TensorFlow primal problem, The Dual Problem principal component, Principal Components Principal Component Analysis (PCA), PCA-Randomized PCA explained variance ratios, Explained Variance Ratio finding principal components, Principal Components-Principal Components for compression, PCA for Compression-Incremental PCA Incremental PCA, Incremental PCA-Randomized PCA Kernel PCA (kPCA), Kernel PCA-Selecting a Kernel and Tuning Hyperparameters projecting down to d dimensions, Projecting Down to d Dimensions Randomized PCA, Randomized PCA Scikit Learn for, Using Scikit-Learn variance, preserving, Preserving the Variance-Preserving the Variance probabilistic autoencoders, Variational Autoencoders probabilities, estimating, Estimating Probabilities-Estimating Probabilities, Estimating Class Probabilities producer functions, Other convenience functions projection, Projection-Projection propositional logic, From Biological to Artificial Neurons pruning, Regularization Hyperparameters, Symbolic Differentiation Python isolated environment in, Create the Workspace-Create the Workspace notebooks in, Create the Workspace-Download the Data pickle, Better Evaluation Using Cross-Validation pip, Create the Workspace Q Q-Learning algorithm, Temporal Difference Learning and Q-Learning- Learning to Play Ms. Pac-Man Using Deep Q-Learning approximate Q-Learning, Approximate Q-Learning deep Q-Learning, Approximate Q-Learning-Learning to Play Ms. Pac- Man Using Deep Q-Learning Q-Value Iteration Algorithm, Markov Decision Processes Q-Values, Markov Decision Processes Quadratic Programming (QP) Problems, Quadratic Programming- Quadratic Programming quantizing, Bandwidth saturation queries per second (QPS), One Neural Network per Device QueueRunner, Multithreaded readers using a Coordinator and a QueueRunner-Multithreaded readers using a Coordinator and a QueueRunner queues, Asynchronous Communication Using TensorFlow Queues- PaddingFifoQueue closing, Closing a queue dequeuing data, Dequeuing data enqueuing data, Enqueuing data first-in first-out (FIFO), Asynchronous Communication Using TensorFlow Queues of tuples, Queues of tuples PaddingFIFOQueue, PaddingFifoQueue RandomShuffleQueue, RandomShuffleQueue q_network(), Learning to Play Ms. Pac-Man Using Deep Q-Learning R Radial Basis Function (RBF), Adding Similarity Features Random Forests, Better Evaluation Using Cross-Validation-Grid Search, Multiclass Classification, Decision Trees, Instability, Ensemble Learning and Random Forests, Random Forests-Feature Importance Extra-Trees, Extra-Trees feature importance, Feature Importance-Feature Importance random initialization, Gradient Descent, Batch Gradient Descent, Stochastic Gradient Descent, Vanishing/Exploding Gradients Problems Random Patches and Random Subspaces, Random Patches and Random Subspaces randomized leaky ReLU (RReLU), Nonsaturating Activation Functions Randomized PCA, Randomized PCA randomized search, Randomized Search, Fine-Tuning Neural Network Hyperparameters RandomShuffleQueue, RandomShuffleQueue, Reading the training data directly from the graph random_uniform(), Manually Computing the Gradients reader operations, Reading the training data directly from the graph recall, Confusion Matrix recognition network, Efficient Data Representations reconstruction error, PCA for Compression reconstruction loss, Efficient Data Representations, TensorFlow Implementation, Variational Autoencoders reconstruction pre-image, Selecting a Kernel and Tuning Hyperparameters reconstructions, Efficient Data Representations recurrent neural networks (RNNs), Recurrent Neural Networks-Exercises deep RNNs, Deep RNNs-The Difficulty of Training over Many Time Steps exploration policies, Exploration Policies GRU cell, GRU Cell-GRU Cell input and output sequences, Input and Output Sequences-Input and Output Sequences LSTM cell, LSTM Cell-GRU Cell natural language processing (NLP), Natural Language Processing-An Encoder–Decoder Network for Machine Translation in TensorFlow, Basic RNNs in TensorFlow-Handling Variable-Length Output Sequences dynamic unrolling through time, Dynamic Unrolling Through Time static unrolling through time, Static Unrolling Through Time-Static Unrolling Through Time variable length input sequences, Handling Variable Length Input Sequences variable length output sequences, Handling Variable-Length Output Sequences training, Training RNNs-Creative RNN backpropagation through time (BPTT), Training RNNs creative sequences, Creative RNN sequence classifiers, Training a Sequence Classifier-Training a Sequence Classifier time series predictions, Training to Predict Time Series-Training to Predict Time Series recurrent neurons, Recurrent Neurons-Input and Output Sequences memory cells, Memory Cells reduce_mean(), Construction Phase reduce_sum(), TensorFlow Implementation-TensorFlow Implementation, Variational Autoencoders, Learning to Play Ms. Pac-Man Using Deep Q- Learning regression, Supervised learning Decision Trees, Regression-Regression regression models linear, Training and Evaluating on the Training Set regression versus classification, Multioutput Classification regularization, Overfitting the Training Data-Overfitting the Training Data, Testing and Validating, Regularized Linear Models-Early Stopping data augmentation, Data Augmentation-Data Augmentation Decision Trees, Regularization Hyperparameters-Regularization Hyperparameters dropout, Dropout-Dropout early stopping, Early Stopping-Early Stopping, Early Stopping Elastic Net, Elastic Net Lasso Regression, Lasso Regression-Lasso Regression max-norm, Max-Norm Regularization-Max-Norm Regularization Ridge Regression, Ridge Regression-Ridge Regression shrinkage, Gradient Boosting ℓ 1 and ℓ 2 regularization, ℓ1 and ℓ2 Regularization-ℓ1 and ℓ2 Regularization REINFORCE algorithms, Policy Gradients Reinforcement Learning (RL), Reinforcement Learning-Reinforcement Learning, Reinforcement Learning-Thank You! actions, Evaluating Actions: The Credit Assignment Problem-Evaluating Actions: The Credit Assignment Problem credit assignment problem, Evaluating Actions: The Credit Assignment Problem-Evaluating Actions: The Credit Assignment Problem discount rate, Evaluating Actions: The Credit Assignment Problem examples of, Learning to Optimize Rewards Markov decision processes, Markov Decision Processes-Markov Decision Processes neural network policies, Neural Network Policies-Neural Network Policies OpenAI gym, Introduction to OpenAI Gym-Introduction to OpenAI Gym PG algorithms, Policy Gradients-Policy Gradients policy search, Policy Search-Policy Search Q-Learning algorithm, Temporal Difference Learning and Q-Learning- Learning to Play Ms. Pac-Man Using Deep Q-Learning rewards, learning to optimize, Learning to Optimize Rewards-Learning to Optimize Rewards Temporal Difference (TD) Learning, Temporal Difference Learning and Q-Learning-Temporal Difference Learning and Q-Learning ReLU (rectified linear units), Modularity-Modularity ReLU activation, ResNet ReLU function, Multi-Layer Perceptron and Backpropagation, Activation Functions, Xavier and He Initialization-Nonsaturating Activation Functions relu(z), Construction Phase render(), Introduction to OpenAI Gym replay memory, Learning to Play Ms. Pac-Man Using Deep Q-Learning replica_device_setter(), Sharding Variables Across Multiple Parameter Servers request_stop(), Multithreaded readers using a Coordinator and a QueueRunner reset(), Introduction to OpenAI Gym reset_default_graph(), Managing Graphs reshape(), Training to Predict Time Series residual errors, Gradient Boosting-Gradient Boosting residual learning, ResNet residual network (ResNet), Model Zoos, ResNet-ResNet residual units, ResNet ResNet, ResNet-ResNet resource containers, Sharing State Across Sessions Using Resource Containers-Sharing State Across Sessions Using Resource Containers restore(), Saving and Restoring Models restricted Boltzmann machines (RBMs), Semisupervised learning, Unsupervised Pretraining, Boltzmann Machines reuse_variables(), Sharing Variables reverse-mode autodiff, Reverse-Mode Autodiff-Reverse-Mode Autodiff rewards, in RL, Learning to Optimize Rewards-Learning to Optimize Rewards rgb_array, Introduction to OpenAI Gym Ridge Regression, Ridge Regression-Ridge Regression, Elastic Net RMSProp, RMSProp ROC (receiver operating characteristic) curve, The ROC Curve-The ROC Curve Root Mean Square Error (RMSE), Select a Performance Measure-Select a Performance Measure, Linear Regression RReLU (randomized leaky ReLU), Nonsaturating Activation Functions run(), Creating Your First Graph and Running It in a Session, In-Graph Versus Between-Graph Replication S Sampled Softmax, An Encoder–Decoder Network for Machine Translation sampling bias, Nonrepresentative Training Data-Poor-Quality Data, Create a Test Set sampling noise, Nonrepresentative Training Data save(), Saving and Restoring Models Saver node, Saving and Restoring Models Scikit Flow, Up and Running with TensorFlow Scikit-Learn, Create the Workspace about, Objective and Approach bagging and pasting in, Bagging and Pasting in Scikit-Learn-Bagging and Pasting in Scikit-Learn CART algorithm, Making Predictions-The CART Training Algorithm, Regression cross-validation, Better Evaluation Using Cross-Validation-Better Evaluation Using Cross-Validation design principles, Data Cleaning-Data Cleaning imputer, Data Cleaning-Handling Text and Categorical Attributes LinearSVR class, SVM Regression MinMaxScaler, Feature Scaling min_ and max_ hyperparameters, Regularization Hyperparameters PCA implementation, Using Scikit-Learn Perceptron class, The Perceptron Pipeline constructor, Transformation Pipelines-Select and Train a Model, Nonlinear SVM Classification Randomized PCA, Randomized PCA Ridge Regression with, Ridge Regression SAMME, AdaBoost SGDClassifier, Training a Binary Classifier, Precision/Recall Tradeoff- Precision/Recall Tradeoff, Multiclass Classification SGDRegressor, Stochastic Gradient Descent sklearn.base.BaseEstimator, Custom Transformers, Transformation Pipelines, Measuring Accuracy Using Cross-Validation sklearn.base.clone(), Measuring Accuracy Using Cross-Validation, Early Stopping sklearn.base.TransformerMixin, Custom Transformers, Transformation Pipelines sklearn.datasets.fetch_california_housing(), Linear Regression with TensorFlow sklearn.datasets.fetch_mldata(), MNIST sklearn.datasets.load_iris(), Decision Boundaries, Soft Margin Classification, Training and Visualizing a Decision Tree, Feature Importance, The Perceptron sklearn.datasets.load_sample_images(), TensorFlow Implementation- TensorFlow Implementation sklearn.datasets.make_moons(), Nonlinear SVM Classification, Exercises sklearn.decomposition.IncrementalPCA, Incremental PCA sklearn.decomposition.KernelPCA, Kernel PCA-Selecting a Kernel and Tuning Hyperparameters, Selecting a Kernel and Tuning Hyperparameters sklearn.decomposition.PCA, Using Scikit-Learn sklearn.ensemble.AdaBoostClassifier, AdaBoost sklearn.ensemble.BaggingClassifier, Bagging and Pasting in Scikit-Learn- Random Forests sklearn.ensemble.GradientBoostingRegressor, Gradient Boosting, Gradient Boosting-Gradient Boosting sklearn.ensemble.RandomForestClassifier, The ROC Curve, Multiclass Classification, Voting Classifiers sklearn.ensemble.RandomForestRegressor, Better Evaluation Using Cross-Validation, Grid Search-Analyze the Best Models and Their Errors, Random Forests-Extra-Trees, Gradient Boosting sklearn.ensemble.VotingClassifier, Voting Classifiers sklearn.externals.joblib, Better Evaluation Using Cross-Validation sklearn.linear_model.ElasticNet, Elastic Net sklearn.linear_model.Lasso, Lasso Regression sklearn.linear_model.LinearRegression, Model-based learning-Model- based learning, Data Cleaning, Training and Evaluating on the Training Set, The Normal Equation, Mini-batch Gradient Descent, Polynomial Regression, Learning Curves-Learning Curves sklearn.linear_model.LogisticRegression, Decision Boundaries, Decision Boundaries, Softmax Regression, Voting Classifiers, Selecting a Kernel and Tuning Hyperparameters sklearn.linear_model.Perceptron, The Perceptron sklearn.linear_model.Ridge, Ridge Regression sklearn.linear_model.SGDClassifier, Training a Binary Classifier sklearn.linear_model.SGDRegressor, Stochastic Gradient Descent-Mini- batch Gradient Descent, Ridge Regression, Lasso Regression-Early Stopping sklearn.manifold.LocallyLinearEmbedding, LLE-LLE sklearn.metrics.accuracy_score(), Voting Classifiers, Out-of-Bag Evaluation, Training an MLP with TensorFlow’s High-Level API sklearn.metrics.confusion_matrix(), Confusion Matrix, Error Analysis sklearn.metrics.f1_score(), Precision and Recall, Multilabel Classification sklearn.metrics.mean_squared_error(), Training and Evaluating on the Training Set-Training and Evaluating on the Training Set, Evaluate Your System on the Test Set, Learning Curves, Early Stopping, Gradient Boosting-Gradient Boosting, Selecting a Kernel and Tuning Hyperparameters sklearn.metrics.precision_recall_curve(), Precision/Recall Tradeoff sklearn.metrics.precision_score(), Precision and Recall, Precision/Recall Tradeoff sklearn.metrics.recall_score(), Precision and Recall, Precision/Recall Tradeoff sklearn.metrics.roc_auc_score(), The ROC Curve-The ROC Curve sklearn.metrics.roc_curve(), The ROC Curve-The ROC Curve sklearn.model_selection.cross_val_predict(), Confusion Matrix, Precision/Recall Tradeoff, The ROC Curve, Error Analysis, Multilabel Classification sklearn.model_selection.cross_val_score(), Better Evaluation Using Cross- Validation-Better Evaluation Using Cross-Validation, Measuring Accuracy Using Cross-Validation-Confusion Matrix sklearn.model_selection.GridSearchCV, Grid Search-Randomized Search, Exercises, Error Analysis, Exercises, Selecting a Kernel and Tuning Hyperparameters sklearn.model_selection.StratifiedKFold, Measuring Accuracy Using Cross-Validation sklearn.model_selection.StratifiedShuffleSplit, Create a Test Set sklearn.model_selection.train_test_split(), Create a Test Set, Training and Evaluating on the Training Set, Learning Curves, Exercises, Gradient Boosting sklearn.multiclass.OneVsOneClassifier, Multiclass Classification sklearn.neighbors.KNeighborsClassifier, Multilabel Classification, Exercises sklearn.neighbors.KNeighborsRegressor, Model-based learning sklearn.pipeline.FeatureUnion, Transformation Pipelines sklearn.pipeline.Pipeline, Transformation Pipelines, Learning Curves, Soft Margin Classification-Nonlinear SVM Classification, Selecting a Kernel and Tuning Hyperparameters sklearn.preprocessing.Imputer, Data Cleaning, Transformation Pipelines sklearn.preprocessing.LabelBinarizer, Handling Text and Categorical Attributes, Transformation Pipelines sklearn.preprocessing.LabelEncoder, Handling Text and Categorical Attributes sklearn.preprocessing.OneHotEncoder, Handling Text and Categorical Attributes sklearn.preprocessing.PolynomialFeatures, Polynomial Regression- Polynomial Regression, Learning Curves, Ridge Regression, Nonlinear SVM Classification sklearn.preprocessing.StandardScaler, Feature Scaling-Transformation Pipelines, Multiclass Classification, Gradient Descent, Ridge Regression, Linear SVM Classification, Soft Margin Classification-Polynomial Kernel, Gaussian RBF Kernel, Implementing Gradient Descent, Training an MLP with TensorFlow’s High-Level API sklearn.svm.LinearSVC, Soft Margin Classification-Nonlinear SVM Classification, Gaussian RBF Kernel-Computational Complexity, SVM Regression, Exercises sklearn.svm.LinearSVR, SVM Regression-SVM Regression sklearn.svm.SVC, Soft Margin Classification, Polynomial Kernel, Gaussian RBF Kernel-Computational Complexity, SVM Regression, Exercises, Voting Classifiers sklearn.svm.SVR, Exercises, SVM Regression sklearn.tree.DecisionTreeClassifier, Regularization Hyperparameters, Exercises, Bagging and Pasting in Scikit-Learn-Out-of-Bag Evaluation, Random Forests, AdaBoost sklearn.tree.DecisionTreeRegressor, Training and Evaluating on the Training Set, Decision Trees, Regression, Gradient Boosting-Gradient Boosting sklearn.tree.export_graphviz(), Training and Visualizing a Decision Tree StandardScaler, Gradient Descent, Implementing Gradient Descent, Training an MLP with TensorFlow’s High-Level API SVM classification classes, Computational Complexity TF.Learn, Up and Running with TensorFlow user guide, Other Resources score(), Data Cleaning search space, Randomized Search, Fine-Tuning Neural Network Hyperparameters second-order partial derivatives (Hessians), Adam Optimization self-organizing maps (SOMs), Self-Organizing Maps-Self-Organizing Maps semantic hashing, Exercises semisupervised learning, Semisupervised learning sensitivity, Confusion Matrix, The ROC Curve sentiment analysis, Recurrent Neural Networks separable_conv2d(), ResNet sequences, Recurrent Neural Networks sequence_length, Handling Variable Length Input Sequences-Handling Variable-Length Output Sequences, An Encoder–Decoder Network for Machine Translation Shannon's information theory, Gini Impurity or Entropy? shortcut connections, ResNet show(), Take a Quick Look at the Data Structure show_graph(), Visualizing the Graph and Training Curves Using TensorBoard shrinkage, Gradient Boosting shuffle_batch(), Other convenience functions shuffle_batch_join(), Other convenience functions sigmoid function, Estimating Probabilities sigmoid_cross_entropy_with_logits(), TensorFlow Implementation similarity function, Adding Similarity Features-Adding Similarity Features simulated annealing, Stochastic Gradient Descent simulated environments, Introduction to OpenAI Gym (see also OpenAI Gym) Singular Value Decomposition (SVD), Principal Components skewed datasets, Measuring Accuracy Using Cross-Validation skip connections, Data Augmentation, ResNet slack variable, Training Objective smoothing terms, Batch Normalization, AdaGrad, Adam Optimization, Variational Autoencoders soft margin classification, Soft Margin Classification-Soft Margin Classification soft placements, Soft placement soft voting, Voting Classifiers softmax function, Softmax Regression, Multi-Layer Perceptron and Backpropagation, Training an MLP with TensorFlow’s High-Level API Softmax Regression, Softmax Regression-Softmax Regression source ops, Linear Regression with TensorFlow, Parallel Execution spam filters, The Machine Learning Landscape-Why Use Machine Learning?, Supervised learning sparse autoencoders, Sparse Autoencoders-TensorFlow Implementation sparse matrix, Handling Text and Categorical Attributes sparse models, Lasso Regression, Adam Optimization sparse_softmax_cross_entropy_with_logits(), Construction Phase sparsity loss, Sparse Autoencoders specificity, The ROC Curve speech recognition, Why Use Machine Learning? spurious patterns, Hopfield Networks stack(), Static Unrolling Through Time stacked autoencoders, Stacked Autoencoders-Unsupervised Pretraining Using Stacked Autoencoders TensorFlow implementation, TensorFlow Implementation training one-at-a-time, Training One Autoencoder at a Time-Training One Autoencoder at a Time tying weights, Tying Weights-Tying Weights unsupervised pretraining with, Unsupervised Pretraining Using Stacked Autoencoders-Unsupervised Pretraining Using Stacked Autoencoders visualizing the reconstructions, Visualizing the Reconstructions- Visualizing the Reconstructions stacked denoising autoencoders, Visualizing Features, Denoising Autoencoders stacked denoising encoders, Denoising Autoencoders stacked generalization (see stacking) stacking, Stacking-Stacking stale gradients, Asynchronous updates standard correlation coefficient, Looking for Correlations standard deviation, Select a Performance Measure standardization, Feature Scaling StandardScaler, Transformation Pipelines, Implementing Gradient Descent, Training an MLP with TensorFlow’s High-Level API state-action values, Markov Decision Processes states tensor, Handling Variable Length Input Sequences state_is_tuple, Distributing a Deep RNN Across Multiple GPUs, LSTM Cell static unrolling through time, Static Unrolling Through Time-Static Unrolling Through Time static_rnn(), Static Unrolling Through Time-Static Unrolling Through Time, An Encoder–Decoder Network for Machine Translation stationary point, SVM Dual Problem-SVM Dual Problem statistical mode, Bagging and Pasting statistical significance, Regularization Hyperparameters stemming, Exercises step functions, The Perceptron step(), Introduction to OpenAI Gym Stochastic Gradient Boosting, Gradient Boosting Stochastic Gradient Descent (SGD), Stochastic Gradient Descent-Stochastic Gradient Descent, Soft Margin Classification, The Perceptron training, Training and Cost Function Stochastic Gradient Descent (SGD) classifier, Training a Binary Classifier, Ridge Regression stochastic neurons, Boltzmann Machines stochastic policy, Policy Search stratified sampling, Create a Test Set-Create a Test Set, Measuring Accuracy Using Cross-Validation stride, Convolutional Layer string kernels, Gaussian RBF Kernel string_input_producer(), Other convenience functions strong learners, Voting Classifiers subderivatives, Online SVMs subgradient vector, Lasso Regression subsample, Gradient Boosting, Pooling Layer supervised learning, Supervised/Unsupervised Learning-Supervised learning Support Vector Machines (SVMs), Multiclass Classification, Support Vector Machines-Exercises decision function and predictions, Decision Function and Predictions- Decision Function and Predictions dual problem, SVM Dual Problem-SVM Dual Problem kernelized SVM, Kernelized SVM-Kernelized SVM linear classification, Linear SVM Classification-Soft Margin Classification mechanics of, Under the Hood-Online SVMs nonlinear classification, Nonlinear SVM Classification-Computational Complexity online SVMs, Online SVMs-Online SVMs Quadratic Programming (QP) problems, Quadratic Programming- Quadratic Programming SVM regression, SVM Regression-Online SVMs the dual problem, The Dual Problem training objective, Training Objective-Training Objective support vectors, Linear SVM Classification svd(), Principal Components symbolic differentiation, Using autodiff, Symbolic Differentiation- Numerical Differentiation synchronous updates, Synchronous updates T t-Distributed Stochastic Neighbor Embedding (t-SNE), Other Dimensionality Reduction Techniques tail heavy, Take a Quick Look at the Data Structure target attributes, Take a Quick Look at the Data Structure target_weights, An Encoder–Decoder Network for Machine Translation tasks, Multiple Devices Across Multiple Servers Temporal Difference (TD) Learning, Temporal Difference Learning and Q- Learning-Temporal Difference Learning and Q-Learning tensor processing units (TPUs), Installation TensorBoard, Up and Running with TensorFlow TensorFlow, Up and Running with TensorFlow-Exercises about, Objective and Approach autodiff, Using autodiff-Using autodiff, Autodiff-Reverse-Mode Autodiff Batch Normalization with, Implementing Batch Normalization with TensorFlow-Implementing Batch Normalization with TensorFlow construction phase, Creating Your First Graph and Running It in a Session control dependencies, Control Dependencies convenience functions, Other convenience functions convolutional layers, ResNet convolutional neural networks and, TensorFlow Implementation- TensorFlow Implementation data parallelism and, TensorFlow implementation denoising autoencoders, TensorFlow Implementation-TensorFlow Implementation dropout with, Dropout dynamic placer, Placing Operations on Devices execution phase, Creating Your First Graph and Running It in a Session feeding data to the training algorithm, Feeding Data to the Training Algorithm-Feeding Data to the Training Algorithm Gradient Descent with, Implementing Gradient Descent-Using an Optimizer graphs, managing, Managing Graphs initial graph creation and session run, Creating Your First Graph and Running It in a Session-Creating Your First Graph and Running It in a Session installation, Installation l1 and l2 regularization with, ℓ1 and ℓ2 Regularization learning schedules in, Learning Rate Scheduling Linear Regression with, Linear Regression with TensorFlow-Linear Regression with TensorFlow max pooling layer in, Pooling Layer max-norm regularization with, Max-Norm Regularization model zoo, Model Zoos modularity, Modularity-Modularity Momentum optimization in, Momentum optimization name scopes, Name Scopes neural network policies, Neural Network Policies NLP tutorials, Natural Language Processing, An Encoder–Decoder Network for Machine Translation node value lifecycle, Lifecycle of a Node Value operations (ops), Linear Regression with TensorFlow optimizer, Using an Optimizer overview, Up and Running with TensorFlow-Up and Running with TensorFlow parallel distributed computing (see parallel distributed computing with TensorFlow) Python API construction, Construction Phase-Construction Phase execution, Execution Phase using the neural network, Using the Neural Network queues (see queues) reusing pretrained layers, Reusing a TensorFlow Model-Reusing a TensorFlow Model RNNs in, Basic RNNs in TensorFlow-Handling Variable-Length Output Sequences (see also recurrent neural networks (RNNs)) saving and restoring models, Saving and Restoring Models-Saving and Restoring Models sharing variables, Sharing Variables-Sharing Variables simple placer, Placing Operations on Devices sklearn.metrics.accuracy_score(), Implementing Batch Normalization with TensorFlow sparse autoencoders with, TensorFlow Implementation and stacked autoencoders, TensorFlow Implementation TensorBoard, Visualizing the Graph and Training Curves Using TensorBoard-Visualizing the Graph and Training Curves Using TensorBoard tf.abs(), ℓ1 and ℓ2 Regularization tf.add(), Modularity, ℓ1 and ℓ2 Regularization-ℓ1 and ℓ2 Regularization tf.add_n(), Modularity-Sharing Variables, Sharing Variables-Sharing Variables tf.add_to_collection(), Max-Norm Regularization tf.assign(), Manually Computing the Gradients, Reusing Models from Other Frameworks, Max-Norm Regularization-Max-Norm Regularization, Chapter 9: Up and Running with TensorFlow tf.bfloat16, Bandwidth saturation tf.bool, Implementing Batch Normalization with TensorFlow, Dropout tf.cast(), Construction Phase, Training a Sequence Classifier tf.clip_by_norm(), Max-Norm Regularization-Max-Norm Regularization tf.clip_by_value(), Gradient Clipping tf.concat(), Exercises, GoogLeNet, Neural Network Policies, Policy Gradients tf.ConfigProto, Managing the GPU RAM, Logging placements-Soft placement, In-Graph Versus Between-Graph Replication, Chapter 12: Distributing TensorFlow Across Devices and Servers tf.constant(), Lifecycle of a Node Value-Manually Computing the Gradients, Simple placement-Dynamic placement function, Control Dependencies, Opening a Session-Pinning Operations Across Tasks tf.constant_initializer(), Sharing Variables-Sharing Variables tf.container(), Sharing State Across Sessions Using Resource Containers- Asynchronous Communication Using TensorFlow Queues, TensorFlow implementation-Exercises, Chapter 9: Up and Running with TensorFlow tf.contrib.framework.arg_scope(), Implementing Batch Normalization with TensorFlow, TensorFlow Implementation, Variational Autoencoders tf.contrib.layers.batch_norm(), Implementing Batch Normalization with TensorFlow-Implementing Batch Normalization with TensorFlow tf.contrib.layers.convolution2d(), Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.contrib.layers.fully_connected(), Construction Phase tf.contrib.layers.l1_regularizer(), ℓ1 and ℓ2 Regularization, Max-Norm Regularization tf.contrib.layers.l2_regularizer(), ℓ1 and ℓ2 Regularization, TensorFlow Implementation-Tying Weights tf.contrib.layers.variance_scaling_initializer(), Xavier and He Initialization-Xavier and He Initialization, Training a Sequence Classifier, TensorFlow Implementation-Tying Weights, Variational Autoencoders, Neural Network Policies, Policy Gradients, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.contrib.learn.DNNClassifier, Training an MLP with TensorFlow’s High-Level API tf.contrib.learn.infer_real_valued_columns_from_input(), Training an MLP with TensorFlow’s High-Level API tf.contrib.rnn.BasicLSTMCell, LSTM Cell, Peephole Connections tf.contrib.rnn.BasicRNNCell, Static Unrolling Through Time-Dynamic Unrolling Through Time, Training a Sequence Classifier, Training to Predict Time Series-Training to Predict Time Series, Training to Predict Time Series, Deep RNNs-Applying Dropout, LSTM Cell tf.contrib.rnn.DropoutWrapper, Applying Dropout tf.contrib.rnn.GRUCell, GRU Cell tf.contrib.rnn.LSTMCell, Peephole Connections tf.contrib.rnn.MultiRNNCell, Deep RNNs-Applying Dropout tf.contrib.rnn.OutputProjectionWrapper, Training to Predict Time Series-Training to Predict Time Series tf.contrib.rnn.RNNCell, Distributing a Deep RNN Across Multiple GPUs tf.contrib.rnn.static_rnn(), Basic RNNs in TensorFlow-Handling Variable Length Input Sequences, An Encoder–Decoder Network for Machine Translation-Exercises, Chapter 14: Recurrent Neural Networks- \", 'tf.contrib.slim module, Up and Running with TensorFlow, Exercises tf.contrib.slim.nets module (nets), Exercises tf.control_dependencies(), Control Dependencies tf.decode_csv(), Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner tf.device(), Simple placement-Soft placement, Pinning Operations Across Tasks-Sharding Variables Across Multiple Parameter Servers, Distributing a Deep RNN Across Multiple GPUs-Distributing a Deep RNN Across Multiple GPUs tf.exp(), Variational Autoencoders-Generating Digits tf.FIFOQueue, Asynchronous Communication Using TensorFlow Queues, Queues of tuples-RandomShuffleQueue, Reading the training data directly from the graph, Multithreaded readers using a Coordinator and a QueueRunner tf.float32, Linear Regression with TensorFlow, Chapter 9: Up and Running with TensorFlow tf.get_collection(), Reusing a TensorFlow Model-Freezing the Lower Layers, ℓ1 and ℓ2 Regularization, Max-Norm Regularization, TensorFlow Implementation, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.get_default_graph(), Managing Graphs, Visualizing the Graph and Training Curves Using TensorBoard tf.get_default_session(), Creating Your First Graph and Running It in a Session tf.get_variable(), Sharing Variables-Sharing Variables, Reusing Models from Other Frameworks, ℓ1 and ℓ2 Regularization-Max-Norm Regularization tf.global_variables(), Max-Norm Regularization tf.global_variables_initializer(), Creating Your First Graph and Running It in a Session, Manually Computing the Gradients tf.gradients(), Using autodiff tf.Graph, Creating Your First Graph and Running It in a Session, Managing Graphs, Visualizing the Graph and Training Curves Using TensorBoard, Loading Data Directly from the Graph, In-Graph Versus Between-Graph Replication tf.GraphKeys.REGULARIZATION_LOSSES, ℓ1 and ℓ2 Regularization, TensorFlow Implementation tf.GraphKeys.TRAINABLE_VARIABLES, Reusing a TensorFlow Model-Freezing the Lower Layers, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.group(), Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.int32, Operations and kernels-Queues of tuples, Reading the training data directly from the graph, Handling Variable Length Input Sequences, Training a Sequence Classifier, Word Embeddings, Learning to Play Ms. Pac-Man Using Deep Q-Learning tf.int64, Construction Phase tf.InteractiveSession, Creating Your First Graph and Running It in a Session TF.Learn, Training an MLP with TensorFlow’s High-Level API tf.log(), TensorFlow Implementation, Variational Autoencoders, Neural Network Policies, Policy Gradients tf.matmul(), Linear Regression with TensorFlow-Manually Computing the Gradients, Modularity, Construction Phase, Basic RNNs in TensorFlow, Tying Weights, Training One Autoencoder at a Time, TensorFlow Implementation, TensorFlow Implementation-TensorFlow Implementation tf.matrix_inverse(), Linear Regression with TensorFlow tf.maximum(), Modularity, Sharing Variables-Sharing Variables, Nonsaturating Activation Functions tf.multinomial(), Neural Network Policies, Policy Gradients tf.name_scope(), Name Scopes, Modularity-Sharing Variables, Construction Phase, Construction Phase-Construction Phase, Training One Autoencoder at a Time-Training One Autoencoder at a Time tf.nn.conv2d(), TensorFlow Implementation-TensorFlow Implementation tf.nn.dynamic_rnn(), Static Unrolling Through Time-Dynamic Unrolling Through Time, Training a Sequence Classifier, Training to Predict Time Series, Training to Predict Time Series, Deep RNNs-Applying Dropout, An Encoder–Decoder Network for Machine Translation-Exercises, ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialization of the QA pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "# QA system\n",
        "def answer_question(query, context):\n",
        "    inputs = {\n",
        "        'question': query,\n",
        "        'context': context\n",
        "    }\n",
        "    result = qa_pipeline(inputs)\n",
        "    return result['answer']\n",
        "\n",
        "# Example query and response generation\n",
        "query = \"What's Difference between Linear Regression and Neural Network?.\"\n",
        "retrieved_content = rag_system(query, tree_indexes)\n",
        "context = \" \".join(retrieved_content)\n",
        "answer = answer_question(query, context)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIEzUHpYsQLx",
        "outputId": "184c385f-9aee-4a4d-fbcf-38a9b5b50394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Internal Covariate Shift problem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query2=\" Activation functions? \"\n",
        "retrieved_content2 = rag_system(query2, tree_indexes)\n",
        "context2 = \" \".join(retrieved_content2)\n",
        "answer2 = answer_question(query2, context2)\n",
        "print(\"Answer:\", answer2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnW7YL4is5E-",
        "outputId": "dfd3d140-cb88-43aa-a18f-7760809fdc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Nonsaturating\n"
          ]
        }
      ]
    }
  ]
}